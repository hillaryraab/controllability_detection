---
title: "Detection of Controllability"
author: "Hillary Raab"
date: "October 14, 2020"
output: 
  html_document:
      toc: yes
      toc_float:
        collapsed: false
        smooth_scroll: true
---

```{r load packages, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
#load packages
library(tidyverse)
library(dplyr)
library(tidyr)
library(doBy)
library(afex)
library(ggplot2)
library(pander)
require(lmtest)
library(psych) #sample descriptives
library(cowplot) #side by side plots
library(ggbeeswarm)
```


```{r set working directory, include=FALSE}
#set working directory
setwd("/Users/hillaryraab/Box Sync/HartleyLab_Shared/1_Studies/MonCon_HillaryKaterina/Analyses/Hillary/")

baseDir <- '/Users/hillaryraab/Box Sync/HartleyLab_Shared/1_Studies/MonCon_HillaryKaterina/'
dataDir <- 'Analyses/Hillary/n_90/'
wmDir <- 'DATA/workingMemoryTask/n_90/'
qDir <- 'DATA/qualtricsQuestionnaires/n_90/'
```

```{r load data, include=FALSE}
#load data and add headers
dataAllSubjs <- read.csv(file.path(baseDir, dataDir, "predictionAllSubjs_n90.csv"), header = FALSE)
colnames(dataAllSubjs)<- c("SubjID","Run","globalPredictiveTrialNumWPractice","globalPredictiveTrialNum","globalPredictivePairNum","predictiveTrialNum", "predictiveTrialPair","streak","reversalNum","Condition","noise1","noise2","noise3","firstOrSecondPredictiveTrial","last_explor_state","resp_choice1","hyp_LR","resp_side","resp_RT","resp_choice2","correct_resp","resp_acc","feedback","trial_onset","resp_onset","post_onset","post_offset","post_jitter","state")

dataAllSubjs$SubjID<-as.factor(dataAllSubjs$SubjID)


#load age data
Age<- read.csv(file.path(baseDir, dataDir,"Age_n90.csv"),header=FALSE)
colnames(Age)<-c("SubjID","Gender","Age","AgeGroup")
Age$SubjID<-as.factor(Age$SubjID)

#z-score age and age^2
Age$z_age<-scale(Age$Age,center=TRUE,scale=TRUE)
Age$z_ageSq<-Age[,"z_age"]^2

#merge dataframes
dataAllSubjs  <- merge(dataAllSubjs,Age,by="SubjID")

#sort and rename categorical age groups
dataAllSubjs$AgeGroup_sorted <- factor(dataAllSubjs$AgeGroup, levels=c('Child','Teen','Adult')) #order by age
levels(dataAllSubjs$AgeGroup_sorted) <- c("Children","Adolescents","Adults") #rename
```

```{r identify diagnostic and confirmatory trials}
#subsetting different trial types to use later
#subset so only using the prediction that allows for a diagnostic output
diagnosticStatePredictions <- dataAllSubjs[ which((dataAllSubjs$state=='1' & dataAllSubjs$hyp_LR == '1') | (dataAllSubjs$state=='2' & dataAllSubjs$hyp_LR == '2') | (dataAllSubjs$state=='3' & dataAllSubjs$hyp_LR == '1')), ]

#subset so only using the prediction that allows for a confirmatory output
confirmatoryStatePredictions <- dataAllSubjs[ which((dataAllSubjs$state=='1' & dataAllSubjs$hyp_LR == '2') | (dataAllSubjs$state=='2' & dataAllSubjs$hyp_LR == '1') | (dataAllSubjs$state=='3' & dataAllSubjs$hyp_LR == '2')), ]

#create trial num for learning plots and analyses
uncon_trials <- dataAllSubjs[dataAllSubjs$Condition == 1,]
numTrials <- uncon_trials %>% group_by(SubjID) %>% summarise(num_rows = length(SubjID))
uncon_trials$num_trials <- rep(1:numTrials$num_rows[1],times=length(numTrials$SubjID))

con_trials <- dataAllSubjs[dataAllSubjs$Condition == 2,]
numTrials <- con_trials %>% group_by(SubjID) %>% summarise(num_rows = length(SubjID))
con_trials$num_trials <- rep(1:numTrials$num_rows[1],times=length(numTrials$SubjID))

dataAllSubjs_learning <- rbind(uncon_trials, con_trials)

diagnosticStatePredictions_learning <- dataAllSubjs_learning[ which((dataAllSubjs_learning$state=='1' & dataAllSubjs_learning$hyp_LR == '1') | (dataAllSubjs_learning$state=='2' & dataAllSubjs_learning$hyp_LR == '2') | (dataAllSubjs_learning$state=='3' & dataAllSubjs_learning$hyp_LR == '1')), ]

#subset so only using the prediction that allows for a confirmatory output
confirmatoryStatePredictions_learning <- dataAllSubjs_learning[ which((dataAllSubjs_learning$state=='1' & dataAllSubjs_learning$hyp_LR == '2') | (dataAllSubjs_learning$state=='2' & dataAllSubjs_learning$hyp_LR == '1') | (dataAllSubjs_learning$state=='3' & dataAllSubjs_learning$hyp_LR == '2')), ]
```

#Descriptive Statistics of Participants
```{r descriptive stats}
describeBy(Age,group="AgeGroup")
AgeGenderStats <- count(Age, AgeGroup,Gender)

#gender distribution
pander(count(Age, AgeGroup,Gender))
```

*Histogram of Participants*
```{r historgram of ages}
#histogram of age and gender distribution (still need to fix it so that each bin is 1 year from 8.0 to 9.0)
ageHistogram <- ggplot(Age, aes(x = floor(Age), fill = Gender)) + geom_bar() +#geom_histogram(position="stack",bins = 18) + 
  ylab("Participant Count") + xlab("Age") + guides(fill=guide_legend(title="Gender")) +
  geom_vline(xintercept=12.5, linetype="dashed", color = "black") + #line at chance
  geom_vline(xintercept=17.5, linetype="dashed", color = "black") #line at chance
plot(ageHistogram)

#ggsave(filename="/Users/hillaryraab/Box Sync/HartleyLab_SHARED/1_STUDIES/MonCon_HillaryKaterina/Analyses/Hillary/figures/talks/participant_histogram.png", plot=ageHistogram, dpi=300, height = 5, width = 7, units="in")
```


#State Prediction Trials
```{r state prediction trials set up}
#convert data to numeric and factor
#dataAllSubjs$resp_acc<-as.numeric(dataAllSubjs$resp_acc)#incorrect: 0 and correct: 1
dataAllSubjs$resp_RT<-as.numeric(dataAllSubjs$resp_RT)

#overall mean accuracy for each participant and per condition
meanAccParticipant <- dataAllSubjs %>% group_by(SubjID) %>% summarize(meanAcc = mean(resp_acc, na.rm = TRUE), sdAcc = sd(resp_acc, na.rm = TRUE))
meanAccCondition <- dataAllSubjs %>% group_by(Condition) %>% summarize(meanAcc = mean(resp_acc, na.rm = TRUE), sdAcc = sd(resp_acc, na.rm = TRUE))

#accuracy by condition, by participant, 1 = uncontrollable, 2 = controllable
meanAccs <- dataAllSubjs %>% group_by(Condition, SubjID) %>% summarize(meanAcc = mean(resp_acc, na.rm = TRUE), sdAcc = sd(resp_acc, na.rm = TRUE))

#add age
meanAccs  <- merge(meanAccs,Age,by="SubjID")
meanAccParticipant <- merge(meanAccParticipant,Age,by="SubjID")
names(meanAccParticipant)[names(meanAccParticipant)=="meanAcc"]<-"stateMeanAcc"


#accuracy by condition and age group
meanAccsByAgeBin <- meanAccs %>% group_by(Condition, AgeGroup) %>% summarise(N = n(), meanAcc = mean(meanAcc, na.rm = TRUE), sdAcc = sd(meanAcc, na.rm = TRUE), seAcc = sdAcc/(sqrt(N)))
```

##Figures

*Sig. effect of condition and age*
```{r accuracy as a fxn of condition, separate graph for children, adolescents, adults}
###### plot accuracy as a fxn of condition for each subject, with a separate graph for children, adolescents, adults
meanAccs$Condition<- as.numeric(meanAccs$Condition)
meanAccsByAgeBin$Condition<- as.numeric(meanAccsByAgeBin$Condition)

#to rename and sort by from youngest to oldest
meanAccs$Condition<- as.numeric(meanAccs$Condition)
meanAccs$AgeGroup_sorted <- factor(meanAccs$AgeGroup, levels=c('Child','Teen','Adult')) #order by age
levels(meanAccs$AgeGroup_sorted) <- c("Children","Adolescents","Adults") #rename

meanAccsByAgeBin$Condition<- as.numeric(meanAccsByAgeBin$Condition)
meanAccsByAgeBin$AgeGroup_sorted <- factor(meanAccsByAgeBin$AgeGroup, levels=c('Child','Teen','Adult')) #order by age
levels(meanAccsByAgeBin$AgeGroup_sorted) <- c("Children","Adolescents","Adults") #rename

acc_AgeBin <- ggplot(meanAccsByAgeBin, aes(x = Condition, y=meanAcc)) +
  geom_point(data=data.frame(meanAccs),aes(x=Condition,y=meanAcc,group=SubjID,color=AgeGroup)) +
  geom_line(data=data.frame(meanAccs),aes(group=SubjID,color=AgeGroup),size =1,alpha=.5) +
  geom_line(stat = "identity", aes(color=AgeGroup,x=Condition,y=meanAcc),size=2,color="Black") +
  facet_wrap(~AgeGroup_sorted) +
  geom_hline(yintercept=.33, linetype="dashed", color = "black") + #line at chance
  labs(y="Accuracy") + scale_x_discrete(limits=c("UNCON", "CON")) + #label x axis and y-axis
  theme_classic() +
  theme(axis.text=element_text(size=16), axis.title=element_text(size=26), legend.text=element_text(size=16), legend.title=element_text(size=20), legend.position = "None") + #change theme
  scale_color_manual(values = c("steelblue4", "steelblue2", "steelblue3"))
plot(acc_AgeBin)
#ggsave(filename="Fig Acc~Condition + Binned Age.png", plot=acc_AgeBin, dpi=300, height = 5, width = 9, units="in")
```


*Sig. effect of condition and age*
```{r accuracy by continuous age linear}
meanAccs$Condition<- as.factor(meanAccs$Condition)
meanAccs$Condition_sorted <- meanAccs$Condition
meanAccs$Condition_sorted <- factor(meanAccs$Condition_sorted, levels=rev(levels(meanAccs$Condition_sorted)))


condition_acc_plot<-ggplot(data=meanAccs, aes(x=Age, y=meanAcc , color=Condition_sorted)) + geom_point() + #uncontrollable: 1 and controllable: 2
  geom_smooth(fullrange = TRUE, method = "glm",formula = y ~ poly(x, 1), aes(color=Condition, fill=Condition_sorted), alpha=.6,size=2) + geom_point() +
  labs(y="State Prediction Accuracy") + #label y-axis and legends
  geom_hline(yintercept=.33, linetype="dashed", color = "black") + #line at chance
  #ylim(0,1) +
  coord_cartesian(ylim=c(0,1.0)) +
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=26), legend.text=element_text(size=16), legend.position = "None") +
scale_color_manual(values=c('#559CAD', '#3D5A80'),name="Condition") + scale_fill_manual(values=c('#559CAD', '#3D5A80'),name="Condition")

plot(condition_acc_plot) 
  
#alternative colors: deepskyblue3 and darkorange1
#ggsave(filename="/Users/hillaryraab/Box Sync/HartleyLab_SHARED/1_STUDIES/MonCon_HillaryKaterina/Analyses/Hillary/figures/manuscript/conditionAccuracy.png", plot=condition_acc_plot, dpi=300, height = 5, width = 7, units="in")
```

*Accuracy by continuous age, quadratic*
```{r accuracy by continuous age quadratic, eval = FALSE}
meanAccs$Condition<- as.factor(meanAccs$Condition)

q<-ggplot(data=meanAccs, aes(x=Age, y=meanAcc , color=Condition)) + geom_point() + #uncontrollable: 1 and controllable: 2
  geom_smooth(method = "glm",formula = y ~ poly(x, 2), aes(color=Condition, fill=Condition), alpha=.4) + geom_point() +
  labs(y="Accuracy") + #label y-axis and legends
  geom_hline(yintercept=.33, linetype="dashed", color = "black") + #line at chance
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=22), legend.title=element_blank(), legend.position="top") +
  scale_color_manual(values=c('#7CB9D8', '#2960C3'),name="Condition", labels=c("Uncontrollable", "Controllable")) + scale_fill_manual(values=c('#7CB9D8', '#2960C3'),name="Condition", labels=c("Uncontrollable", "Controllable")) 

  plot(q) 
#  ggsave(filename="/Users/hillaryraab/Box Sync/Hartley Lab/Conferences/SANS 2019/posterFigures/Fig State Prediction Acc~AgeSq_blue.png", plot=q, dpi=300, height = 5, width = 8, units="in")


  #blue and orange
  #  scale_color_manual(values=c('deepskyblue3', 'darkorange1'),name="Condition", labels=c("Uncontrollable", "Controllable")) + scale_fill_manual(values=c('deepskyblue3', 'darkorange1'),name="Condition", labels=c("Uncontrollable", "Controllable")) 
#legend.position="none")
```

##Stats

*Effects of Age and Condition in mixed models*
```{r logistic regression of accuracy, include=FALSE}
########### LOGISTIC REGRESSIONS OF ACCURACY ##############
#convert condition to factor
dataAllSubjs$Condition<- as.factor(dataAllSubjs$Condition)
dataAllSubjs$state<- as.factor(dataAllSubjs$state)
dataAllSubjs$resp_acc_fac <- as.factor(dataAllSubjs$resp_acc)

#logistic regression models for accuracy with condition and subject as random effect
m1_condition_noAge <- mixed(resp_acc_fac~Condition+(Condition|SubjID),data=dataAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
m2_condition_linAge <- mixed(resp_acc_fac~Condition*z_age+(Condition|SubjID),data=dataAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
m3_condition_sqAge <- mixed(resp_acc_fac~Condition*(z_age+z_ageSq)+(Condition|SubjID),data=dataAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

#logistic regression models for accuracy with only subject as random effect
m1b_noAge <- mixed(resp_acc_fac~Condition+(1|SubjID),data=dataAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
m2b_linAge <- mixed(resp_acc_fac~Condition*z_age+(1|SubjID),data=dataAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
m3b_sqAge <- mixed(resp_acc_fac~Condition*(z_age+z_ageSq)+(1|SubjID),data=dataAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

#logistic regression models for accuracy with only subject as random effect
##state refers to which island/pair of plane combo they are seeing
#m1c_noAge <- mixed(resp_acc_fac~Condition+(1|SubjID) + (1|state),data=dataAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
#m2c_linAge <- mixed(resp_acc_fac~Condition*z_age+(1|SubjID) + (1|state),data=dataAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
#m3c_sqAge <- mixed(resp_acc_fac~Condition*(z_age+z_ageSq)+(1|SubjID) + (1|state),data=dataAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
```

```{r test for best model for accuracy, cache=FALSE}
#test the different models
#lrtest(m1_noAge$full_model,m2_linAge$full_model,m3_sqAge$full_model)
#lrtest(m1b_noAge$full_model,m2b_linAge$full_model,m3b_sqAge$full_model)
#anova(m1b_noAge,m2b_linAge,m3b_sqAge)
#lrtest(m1c_noAge$full_model,m2c_linAge$full_model,m3c_sqAge$full_model)

#summary(m2b_linAge)

anova(m1_condition_noAge,m2_condition_linAge,m3_condition_sqAge)
summary(m2_condition_linAge)

#compare model w/ random intercept and slope or just random intercept, full model fits better! 
anova(m2b_linAge,m2_condition_linAge)
```


*Effects of age in linear model*
```{r linear model }
#z score age and age^2
#meanAccs$z_age<-scale(meanAccs$Age,center=TRUE,scale=TRUE) # age as continuous variable, mean centered and scaled
#meanAccs$z_ageSq<-scale(meanAccs$AgeSq,center=TRUE,scale=TRUE) #age squared as continuous variable, mean centered and scaled

#linear model, rather than mixed effect models as above
acc_m1 <- lm(meanAcc~Condition,data=meanAccs)
acc_m2 <- lm(meanAcc~Condition*z_age,data=meanAccs)
acc_m3 <- lm(meanAcc~Condition*(z_age+z_ageSq),data=meanAccs)

#model comparison
#lrtest(acc_m1,acc_m2,acc_m3)
anova(acc_m1,acc_m2)
anova(acc_m2,acc_m3)

summary(acc_m2)
```


# State Prediction Diagnostic Trials
*These are the prediction trials that are diagnostic as to condition.*
```{r state prediction diagnostic trials mean accuracy}
#subsetted above in the first code section

#accuracy by condition, by participant, 1 = uncontrollable, 2 = controllable
meanDiagAccs <- diagnosticStatePredictions %>% group_by(Condition, SubjID) %>% summarize(meanAcc = mean(resp_acc, na.rm = TRUE), sdAcc = sd(resp_acc, na.rm = TRUE))

#add age
meanDiagAccs  <- merge(meanDiagAccs,Age,by="SubjID")

#accuracy by condition and age group
meanDiagAccsByAgeBin <- meanDiagAccs %>% group_by(Condition, AgeGroup) %>% summarise(N = n(), meanAcc = mean(meanAcc, na.rm = TRUE), sdAcc = sd(meanAcc, na.rm = TRUE), seAcc = sdAcc/(sqrt(N)))
```

##Figures

*Sig. effect of condition and age*
```{r diagnostic accuracy plots}
meanDiagAccs$Condition<- as.numeric(meanDiagAccs$Condition)
meanDiagAccsByAgeBin$Condition<- as.numeric(meanDiagAccsByAgeBin$Condition)

#to rename and sort by from youngest to oldest
meanDiagAccs$Condition<- as.numeric(meanDiagAccs$Condition)
meanDiagAccs$AgeGroup_sorted <- factor(meanDiagAccs$AgeGroup, levels=c('Child','Teen','Adult')) #order by age
levels(meanDiagAccs$AgeGroup_sorted) <- c("Children","Adolescents","Adults") #rename

meanDiagAccsByAgeBin$Condition<- as.numeric(meanDiagAccsByAgeBin$Condition)
meanDiagAccsByAgeBin$AgeGroup_sorted <- factor(meanDiagAccsByAgeBin$AgeGroup, levels=c('Child','Teen','Adult')) #order by age
levels(meanDiagAccsByAgeBin$AgeGroup_sorted) <- c("Children","Adolescents","Adults") #rename

acc_AgeBin <- ggplot(meanDiagAccsByAgeBin, aes(x = Condition, y=meanAcc)) +
  geom_point(data=data.frame(meanDiagAccs),aes(x=Condition,y=meanAcc,group=SubjID,color=AgeGroup)) +
  geom_line(data=data.frame(meanDiagAccs),aes(group=SubjID,color=AgeGroup),size =1,alpha=.5) +
  geom_line(stat = "identity", aes(color=AgeGroup,x=Condition,y=meanAcc),size=2,color="Black") +
  facet_wrap(~AgeGroup_sorted) +
  geom_hline(yintercept=.33, linetype="dashed", color = "black") + #line at chance
  labs(y="Diagnostic Accuracy") + scale_x_discrete(limits=c("UNCON", "CON")) + #label x axis and y-axis
  theme_classic() +
  theme(axis.text=element_text(size=16), axis.title=element_text(size=26), legend.text=element_text(size=16), legend.title=element_text(size=20), legend.position = "None") + #change theme
  scale_color_manual(values = c("steelblue4", "steelblue2", "steelblue3"))
plot(acc_AgeBin)


#by continuous age
meanDiagAccs$Condition<- as.factor(meanDiagAccs$Condition)

l4<-ggplot(data=meanDiagAccs, aes(x=Age, y=meanAcc , color=Condition)) + geom_point() + #uncontrollable: 1 and controllable: 2
  geom_smooth(method = "glm",formula = y ~ poly(x, 2), aes(color=Condition, fill=Condition), alpha=.6) + geom_point() +
  labs(y="Diagnostic Accuracy") + #label y-axis and legends
  geom_hline(yintercept=.33, linetype="dashed", color = "black") + #line at chance
  ylim(0,1) +
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=24),  legend.title=element_blank(), legend.position="top") +
scale_color_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) + scale_fill_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) 

plot(l4) 
```



## Stats
*Effects of age in linear model*
```{r diagnostic accuracy linear regression}

#linear model
acc_m1 <- lm(meanAcc~Condition*z_age,data=meanDiagAccs)
acc_m2 <- lm(meanAcc~Condition*(z_age+z_ageSq),data=meanDiagAccs)

#model comparison
anova(acc_m1,acc_m2)

summary(acc_m2)
```


# State Prediction Confirmatory Trials
*These are the prediction trials that are confirmatory as to condition. They serve as a sanity check.*
```{r confirmatory trials accuracy}
#subset above in first code section

#accuracy by condition, by participant, 1 = uncontrollable, 2 = controllable
meanConfAccs <- confirmatoryStatePredictions %>% group_by(Condition, SubjID) %>% summarize(meanAcc = mean(resp_acc, na.rm = TRUE), sdAcc = sd(resp_acc, na.rm = TRUE))

#add age
meanConfAccs  <- merge(meanConfAccs,Age,by="SubjID")

#accuracy by condition and age group
meanConfAccsByAgeBin <- meanConfAccs %>% group_by(Condition, AgeGroup) %>% summarise(N = n(), meanAcc = mean(meanAcc, na.rm = TRUE), sdAcc = sd(meanAcc, na.rm = TRUE), seAcc = sdAcc/(sqrt(N)))
```

##Figures

*Sig. effect of condition and age*
```{r confirmatory accuracy graphs}
meanConfAccs$Condition<- as.numeric(meanConfAccs$Condition)
meanConfAccsByAgeBin$Condition<- as.numeric(meanConfAccsByAgeBin$Condition)

#to rename and sort by from youngest to oldest
meanConfAccs$Condition<- as.numeric(meanConfAccs$Condition)
meanConfAccs$AgeGroup_sorted <- factor(meanConfAccs$AgeGroup, levels=c('Child','Teen','Adult')) #order by age
levels(meanConfAccs$AgeGroup_sorted) <- c("Children","Adolescents","Adults") #rename

meanConfAccsByAgeBin$Condition<- as.numeric(meanConfAccsByAgeBin$Condition)
meanConfAccsByAgeBin$AgeGroup_sorted <- factor(meanConfAccsByAgeBin$AgeGroup, levels=c('Child','Teen','Adult')) #order by age
levels(meanConfAccsByAgeBin$AgeGroup_sorted) <- c("Children","Adolescents","Adults") #rename

acc_AgeBin <- ggplot(meanConfAccsByAgeBin, aes(x = Condition, y=meanAcc)) +
  geom_point(data=data.frame(meanConfAccs),aes(x=Condition,y=meanAcc,group=SubjID,color=AgeGroup)) +
  geom_line(data=data.frame(meanConfAccs),aes(group=SubjID,color=AgeGroup),size =1,alpha=.5) +
  geom_line(stat = "identity", aes(color=AgeGroup,x=Condition,y=meanAcc),size=2,color="Black") +
  facet_wrap(~AgeGroup_sorted) +
  geom_hline(yintercept=.33, linetype="dashed", color = "black") + #line at chance
  labs(y="Confirmatory Accuracy") + scale_x_discrete(limits=c("UNCON", "CON")) + #label x axis and y-axis
  theme_classic() +
  theme(axis.text=element_text(size=16), axis.title=element_text(size=26), legend.text=element_text(size=16), legend.title=element_text(size=20), legend.position = "None") + #change theme
  scale_color_manual(values = c("steelblue4", "steelblue2", "steelblue3"))
plot(acc_AgeBin)


#by continuous age
meanConfAccs$Condition<- as.factor(meanConfAccs$Condition)

l4<-ggplot(data=meanConfAccs, aes(x=Age, y=meanAcc , color=Condition)) + geom_point() + #uncontrollable: 1 and controllable: 2
  geom_smooth(method = "glm",formula = y ~ poly(x, 1), aes(color=Condition, fill=Condition), alpha=.6) + geom_point() +
  labs(y="Confirmatory Accuracy") + #label y-axis and legends
  geom_hline(yintercept=.33, linetype="dashed", color = "black") + #line at chance
  ylim(0,1.05) +
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=24),  legend.title=element_blank(), legend.position="top") +
scale_color_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) + scale_fill_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) 

plot(l4) 
```

## Stats
*Effects of age in linear model*
```{r confirmatory mean accuracy linear regression}

#linear model
acc_m1 <- lm(meanAcc~Condition*z_age,data=meanConfAccs)
acc_m2 <- lm(meanAcc~Condition*(z_age+z_ageSq),data=meanConfAccs)

#model comparison
anova(acc_m1,acc_m2)

summary(acc_m1)
```


```{r diff between Diag and Conf accuracy}
#diagnostic accuracy by condition, by participant, 1 = uncontrollable, 2 = controllable
meanDiagAccs_par <- diagnosticStatePredictions %>% group_by(SubjID) %>% summarize(diagMeanAcc = mean(resp_acc, na.rm = TRUE), diagSdAcc = sd(resp_acc, na.rm = TRUE))

#add age
meanAccParticipant  <- merge(meanAccParticipant,meanDiagAccs_par,by="SubjID")

#confirmatory accuracy by condition, by participant, 1 = uncontrollable, 2 = controllable
meanConfAccs_par <- confirmatoryStatePredictions %>% group_by(SubjID) %>% summarize(confMeanAcc = mean(resp_acc, na.rm = TRUE), confSdAcc = sd(resp_acc, na.rm = TRUE))

#add age
meanAccParticipant  <- merge(meanAccParticipant,meanConfAccs_par,by="SubjID")

### plot difference between diagnostic and confirmatory accuracy
acc_diff<-ggplot(data=meanAccParticipant, aes(x=Age, y=(diagMeanAcc-confMeanAcc))) + geom_point() +
  geom_smooth(method = "glm",formula = y ~ poly(x, 2), color="black") + geom_point() +
  labs(y="Diff Diag-Conf Accuracy") + #label y-axis and legends
  geom_hline(yintercept=.0, linetype="dashed", color = "black") + #line at chance
  #ylim(0,1) +
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=24),  legend.title=element_blank()) 
plot(acc_diff) 

acc_diff1 <- lm((diagMeanAcc-confMeanAcc)~z_age,data=meanAccParticipant)
acc_diff2 <- lm((diagMeanAcc-confMeanAcc)~z_age*z_ageSq,data=meanAccParticipant)
anova(acc_diff1,acc_diff2)
summary(acc_diff2)
```


#Condition Prediction Trials
```{r initialize condition prediction trials, include=FALSE}
#set working directory
setwd("/Users/hillaryraab/Box Sync/HartleyLab_Shared/1_Studies/MonCon_HillaryKaterina/Analyses/Hillary/")

#load data
pilotPredictionAllSubjs <- read.csv(file.path(baseDir,dataDir,'pilotPredictionAllSubjs_n90.csv') ,header=FALSE) 

#add headers
colnames(pilotPredictionAllSubjs)<- c("SubjID","Run","globalPredictiveTrialNumWPractice","globalPredictiveTrialNum","pilotPredictionNum","pilotPredictionNum2","streak","reversalNum","Condition","state","resp_choice1","resp_side","resp_RT","resp_choice2","correct_resp","resp_acc","feedback","trial_onset","resp_onset","post_onset","post_offset")

#load age data and merge
#setwd('..')
#Age<- read.csv("Age_n90.csv",header=FALSE)
#colnames(Age)<-c("SubjID","Gender","DOB","StudyDate","Age","AgeGroup")

#z score age and age^2
#Age$z_age<-scale(Age$Age,center=TRUE,scale=TRUE) # age as continuous variable, mean centered and scaled
#Age$z_ageSq<-Age[,"z_age"]^2

pilotPredictionAllSubjs$SubjID<-as.factor(pilotPredictionAllSubjs$SubjID)

#merge age and accuracy data
pilotPredictionAllSubjs  <- merge(pilotPredictionAllSubjs,Age,by="SubjID")

#convert data to numeric and factor
pilotPredictionAllSubjs$resp_acc<-as.numeric(pilotPredictionAllSubjs$resp_acc)#incorrect: 0 and correct: 1
pilotPredictionAllSubjs$resp_RT<-as.numeric(pilotPredictionAllSubjs$resp_RT)

#overall mean accuracy for each participant and per condition
meanAccParticipant_Pilot <- pilotPredictionAllSubjs %>% group_by(SubjID) %>% summarize(meanAcc = mean(resp_acc, na.rm = TRUE), sdAcc = sd(resp_acc, na.rm = TRUE))
meanAccCondition_Pilot <- pilotPredictionAllSubjs %>% group_by(Condition) %>% summarize(meanAcc = mean(resp_acc, na.rm = TRUE), sdAcc = sd(resp_acc, na.rm = TRUE))

#accuracy by condition, by participant, 1 = uncontrollable, 2 = controllable
meanAccs_Pilot <- pilotPredictionAllSubjs %>% group_by(Condition, SubjID) %>% summarize(meanAcc = mean(resp_acc, na.rm = TRUE), sdAcc = sd(resp_acc, na.rm = TRUE))

#add age
meanAccs_Pilot  <- merge(meanAccs_Pilot,Age,by="SubjID")

#accuracy by condition and age group
meanAccs_PilotByAgeBin <- meanAccs_Pilot %>% group_by(Condition, AgeGroup) %>% summarise(N = n(), meanAcc = mean(meanAcc, na.rm = TRUE), sdAcc = sd(meanAcc, na.rm = TRUE), seAcc = sdAcc/(sqrt(N)))

selections_per_condition <- pilotPredictionAllSubjs %>% group_by(SubjID, Age, z_age) %>% count(resp_choice1, na.rm = TRUE)
```

##Figures

*Sig. effect of age*
```{r condition predictions accuracy by age group}
###### plot accuracy as a fxn of condition for each subject, with a separate graph for children, adolescents, adults
meanAccs_Pilot$Condition<- as.numeric(meanAccs_Pilot$Condition)
meanAccs_PilotByAgeBin$Condition<- as.numeric(meanAccs_PilotByAgeBin$Condition)

#to rename and sort by from youngest to oldest
meanAccs_Pilot$AgeGroup_sorted <- factor(meanAccs$AgeGroup, levels=c('Child','Teen','Adult')) #order by age
levels(meanAccs_Pilot$AgeGroup_sorted) <- c("Children","Adolescents","Adults") #rename

meanAccs_PilotByAgeBin$Condition<- as.numeric(meanAccs_PilotByAgeBin$Condition)
meanAccs_PilotByAgeBin$AgeGroup_sorted <- factor(meanAccs_PilotByAgeBin$AgeGroup, levels=c('Child','Teen','Adult')) #order by age
levels(meanAccs_PilotByAgeBin$AgeGroup_sorted) <- c("Children","Adolescents","Adults") #rename

accPilot_AgeBin <- ggplot(meanAccs_PilotByAgeBin, aes(x = Condition, y=meanAcc)) +
  geom_point(data=data.frame(meanAccs_Pilot),aes(x=Condition,y=meanAcc,group=SubjID,color=AgeGroup)) +
  geom_line(data=data.frame(meanAccs_Pilot),aes(group=SubjID,color=AgeGroup),size =1,alpha=.5) +
  geom_line(stat = "identity", aes(color=AgeGroup,x=Condition,y=meanAcc),size=2,color="Black") +
  facet_wrap(~AgeGroup_sorted) +
  geom_hline(yintercept=.5, linetype="dashed", color = "black") + #line at chance
  labs(y="Accuracy") + scale_x_discrete(limits=c("UNCON", "CON")) + #label x axis and y-axis
  theme_classic() +
  theme(axis.text=element_text(size=16), axis.title=element_text(size=26), legend.text=element_text(size=16), legend.title=element_text(size=20), legend.position = "None") + #change theme
  scale_color_manual(values = c("steelblue4", "steelblue2", "steelblue3"))
plot(accPilot_AgeBin)

#ggsave(filename="Fig Pilot Acc~Condition + Binned Age.png", plot=accPilot_AgeBin, dpi=300, height = 5, width = 9, units="in")
```


*Sig. effect of age*
```{r condition predictions by continuous age}
###### age on x, accuracy on y, condition color
meanAccs_Pilot$Condition<- as.factor(meanAccs_Pilot$Condition)
w<-ggplot(data=meanAccs_Pilot, aes(x=Age, y=meanAcc , color=Condition)) + geom_point() + #uncontrollable: 1 and controllable: 2
  geom_smooth(method="lm", aes(color=Condition,fill=Condition),alpha=.4) + geom_point() +
  labs(y="Accuracy") +  #label y-axis and legends
  geom_hline(yintercept=.5, linetype="dashed", color = "black") + #line at chance
  ylim(0,1) +
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=24), legend.title=element_blank(), legend.position="top") +
  scale_color_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) + scale_fill_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) 
plot(w) 

#ggsave(filename="/Users/hillaryraab/Box Sync/Hartley Lab/Conferences/SANS 2019/posterFigures/Fig Pilot Prediction Acc~Age_blue.png", plot=w, dpi=300, height = 5, width = 8, units="in")

#blue and orange
#  scale_color_manual(values=c('deepskyblue3', 'darkorange1'),name="Condition", labels=c("Uncontrollable", "Controllable")) + #scale_fill_manual(values=c('deepskyblue3', 'darkorange1'),name="Condition", labels=c("Uncontrollable", "Controllable")) 

#Making the legend for the graphs
#legend_blue<-ggplot(data=meanAccs_Pilot, aes(x=Age, y=meanAcc , color=Condition)) + geom_point() + #uncontrollable: 1 and controllable: 2
#  geom_point(size=8) +
#  theme_classic()+ scale_color_manual(values=c('#7CB9D8', '#2960C3'),name="Condition", labels=c("Uncontrollable", "Controllable")) +
#  theme(legend.title=element_blank(), legend.position="top", legend.text=element_text(size=24), legend.spacing.x=unit(.3,'cm'))
#  plot(legend_blue)
#ggsave(filename="/Users/hillaryraab/Box Sync/Hartley Lab/Conferences/SANS 2019/posterFigures/legend_blue.png", plot=legend_blue, dpi=300, height = 5, width = 8, units="in")
```


##Stats
*Effects of Age and Condition*
```{r include=FALSE}

#Regression with Condition and Subject as random effects
m1_condition_noAge_pilot <- mixed(resp_acc~Condition+(Condition|SubjID),data=pilotPredictionAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
m2_condition_linAge_pilot <- mixed(resp_acc~Condition*z_age+(Condition|SubjID),data=pilotPredictionAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
m3_condition_sqAge_pilot <- mixed(resp_acc~Condition*(z_age+z_ageSq)+(Condition|SubjID),data=pilotPredictionAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

#Regression with Subject as random effects
m1b_noAge_pilot <- mixed(resp_acc~Condition+(1|SubjID),data=pilotPredictionAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
m2b_linAge_pilot <- mixed(resp_acc~Condition*z_age+(1|SubjID),data=pilotPredictionAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
m3b_sqAge_pilot <- mixed(resp_acc~Condition*(z_age+z_ageSq)+(1|SubjID),data=pilotPredictionAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

#Regression with State and Subject as random effects
#m1c_noAge_pilot <- mixed(resp_acc~Condition+(1|SubjID) + (1|state),data=pilotPredictionAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
#m2c_linAge_pilot <- mixed(resp_acc~Condition*z_age+(1|SubjID) + (1|state),data=pilotPredictionAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
#m3c_sqAge_pilot <- mixed(resp_acc~Condition*(z_age+z_ageSq)+(1|SubjID) + (1|state),data=pilotPredictionAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
```

```{r test for best model for condition prediction accuracy, cache=TRUE}
#test the different models
#lrtest(m1_noAge_pilot$full_model,m2_linAge_pilot$full_model,m3_sqAge_pilot$full_model)
#anova(m1b_noAge_pilot,m2b_linAge_pilot,m3b_sqAge_pilot)
#summary(m2b_linAge_pilot)

anova(m1_condition_noAge_pilot,m2_condition_linAge_pilot,m3_condition_sqAge_pilot)
summary(m2_condition_linAge_pilot)


#compare model w/ random intercept and slope or just random intercept, full model fits better! 
anova(m2b_linAge_pilot,m2_condition_linAge_pilot)
#lrtest(m1c_noAge_pilot$full_model,m2c_linAge_pilot$full_model,m3c_sqAge_pilot$full_model)
```

*Effects of age in linear model*
```{r condition prediction accuracy linear regression}
#linear model, rather than mixed effect models as above
acc_m1_pilot <- lm(meanAcc~Condition,data=meanAccs_Pilot)
acc_m2_pilot <- lm(meanAcc~Condition*z_age,data=meanAccs_Pilot)
acc_m3_pilot <- lm(meanAcc~Condition*(z_age+z_ageSq),data=meanAccs_Pilot)

#model comparison
anova(acc_m1_pilot,acc_m2_pilot)
anova(acc_m2_pilot,acc_m3_pilot)

#statistics from best model
summary(acc_m2_pilot)
```

#Correlation between State and Condition Accuracy

##Figures - State pred
```{r rlnsp bn state & prediction}
names(meanAccParticipant_Pilot)[names(meanAccParticipant_Pilot)=="meanAcc"]<-"pilotMeanAcc"
meanAccParticipant  <- merge(meanAccParticipant,meanAccParticipant_Pilot,by="SubjID")

###### plot condition accuracy as a fxn of state accuracy for each subject
acc_state_condition<-ggplot(data=meanAccParticipant, aes(x=stateMeanAcc, y=pilotMeanAcc)) + geom_point() + #uncontrollable: 1 and controllable: 2
  geom_smooth(method="lm", aes(),alpha=.4,color="black") + geom_point() +
  coord_fixed(ratio=1, ylim = c(.2, 1.01), xlim = c(.2, 1.01), expand=FALSE) +
  labs(x="State Accuracy", y="Condition Accuracy") +  #label y-axis and legends
  geom_hline(yintercept=.5, linetype="dashed", color = "black") + #line at chance
  geom_vline(xintercept=.33, linetype="dashed", color = "black") + #line at chance
theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=30), legend.text=element_text(size=24))
plot(acc_state_condition) 

###### plot condition accuracy as a fxn of state accuracy for each subject, with a separate graph for children, adolescents, adults
#to rename and sort by from youngest to oldest
meanAccParticipant$AgeGroup_sorted <- factor(meanAccParticipant$AgeGroup, levels=c('Child','Teen','Adult')) #order by age
levels(meanAccParticipant$AgeGroup_sorted) <- c("Children","Adolescents","Adults") #rename

#meanAccsByAgeBin$Condition<- as.numeric(meanAccsByAgeBin$Condition)
#meanAccsByAgeBin$AgeGroup_sorted <- factor(meanAccsByAgeBin$AgeGroup, levels=c('Child','Teen','Adult')) #order by age
#levels(meanAccsByAgeBin$AgeGroup_sorted) <- c("Children","Adolescents","Adults") #rename

acc_state_condition_AgeBin <- ggplot(meanAccParticipant, aes(x = stateMeanAcc, y=pilotMeanAcc)) +
    geom_smooth(method="lm", aes(),alpha=.4,color="black") +
    geom_point(data=data.frame(meanAccParticipant),aes(x=stateMeanAcc,y=pilotMeanAcc,color=AgeGroup),size=3) +
  #geom_line(data=data.frame(meanAccParticipant),aes(color=AgeGroup),size =1,alpha=.5) +
  #geom_line(stat = "identity", aes(color=AgeGroup,x=stateMeanAcc,y=pilotMeanAcc),size=2,color="Black") +
 
  facet_wrap(~AgeGroup_sorted) +
  coord_fixed(ratio=1, ylim = c(.3, 1.01), xlim = c(.3, 1.01), expand=FALSE) +
  geom_hline(yintercept=.5, linetype="dashed", color = "black") + #line at chance
  geom_vline(xintercept=.33, linetype="dashed", color = "black") + #line at chance
  labs(x="State Accuracy", y="Condition Accuracy") +  #label x axis and y-axis
  theme_classic() + theme(axis.text=element_text(size=16), axis.title=element_text(size=26), legend.text=element_text(size=16), legend.title=element_text(size=20), legend.position = "None") + #change theme
  scale_color_manual(values = c("steelblue4", "steelblue2", "steelblue3"))
plot(acc_state_condition_AgeBin)
```

##Stats - State pred
*Positive relationship between state predictions and condition predictions*
```{r}

#linear model, rather than mixed effect models as above
acc_sc_m1 <- lm(pilotMeanAcc~stateMeanAcc,data=meanAccParticipant)
acc_sc_m2 <- lm(pilotMeanAcc~stateMeanAcc*z_age,data=meanAccParticipant)
acc_sc_m3 <- lm(pilotMeanAcc~stateMeanAcc*(z_age+z_ageSq),data=meanAccParticipant)

#model comparison
anova(acc_sc_m1,acc_sc_m2,acc_sc_m3)

summary(acc_sc_m1)
```


## Figures-Diagnostic Prediction 
```{r rlnsp bn diagnostic state & prediction}

###### plot condition accuracy as a fxn of state accuracy for each subject
diag_state_condition<-ggplot(data=meanAccParticipant, aes(x=diagMeanAcc, y=pilotMeanAcc)) + geom_point() + #uncontrollable: 1 and controllable: 2
  geom_smooth(method="lm", aes(),alpha=.4,color="black") + geom_point() +
  coord_fixed(ratio=1, ylim = c(.2, 1.01), xlim = c(.2, 1.01), expand=FALSE) +
  labs(x="Diagnostic Accuracy", y="Condition Accuracy") +  #label y-axis and legends
  geom_hline(yintercept=.5, linetype="dashed", color = "black") + #line at chance
  geom_vline(xintercept=.33, linetype="dashed", color = "black") + #line at chance
theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=30), legend.text=element_text(size=24))
plot(diag_state_condition) 

###### plot condition accuracy as a fxn of state accuracy for each subject, with a separate graph for children, adolescents, adults
#to rename and sort by from youngest to oldest
meanAccParticipant$AgeGroup_sorted <- factor(meanAccParticipant$AgeGroup, levels=c('Child','Teen','Adult')) #order by age
levels(meanAccParticipant$AgeGroup_sorted) <- c("Children","Adolescents","Adults") #rename


acc_diag_condition_AgeBin <- ggplot(meanAccParticipant, aes(x = diagMeanAcc, y=pilotMeanAcc)) +
    geom_smooth(method="lm", aes(),alpha=.4,color="black") +
    geom_point(aes(x=diagMeanAcc,y=pilotMeanAcc,color=AgeGroup)) +
  facet_wrap(~AgeGroup_sorted) +
  coord_fixed(ratio=1, ylim = c(.3, 1.01), xlim = c(.3, 1.01), expand=FALSE) +
  geom_hline(yintercept=.5, linetype="dashed", color = "black") + #line at chance
  geom_vline(xintercept=.33, linetype="dashed", color = "black") + #line at chance
  labs(x="Diagnostic Accuracy", y="Condition Accuracy") +  #label x axis and y-axis
  theme_classic() + theme(axis.text=element_text(size=16), axis.title=element_text(size=26), legend.text=element_text(size=16), legend.title=element_text(size=20), legend.position = "None") + #change theme
  scale_color_manual(values = c("steelblue4", "steelblue2", "steelblue3"))
plot(acc_diag_condition_AgeBin)
```

##Stats-Diagnostic Prediction 
*Mixed-effects model for diagnostic state and condition prediction trials*
```{r mixed effects for state and prediction}
diagnosticStatePredictions$pilot_acc <- pilotPredictionAllSubjs$resp_acc

mixed_state_condition_predictions.m <- mixed(pilot_acc~resp_acc*z_age+(1|SubjID),data=diagnosticStatePredictions,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

mixed_state_condition_predictions_age2.m <-mixed(pilot_acc~resp_acc*(z_age+z_ageSq)+(1|SubjID),data=diagnosticStatePredictions,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

anova(mixed_state_condition_predictions.m,mixed_state_condition_predictions_age2.m)
summary(mixed_state_condition_predictions.m)


#maximal model
mixed_state_condition_predictions_max.m <- mixed(pilot_acc~resp_acc*z_age+(resp_acc|SubjID),data=diagnosticStatePredictions,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

mixed_state_condition_predictions_age2_max.m <-mixed(pilot_acc~resp_acc*(z_age+z_ageSq)+(resp_acc|SubjID),data=diagnosticStatePredictions,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

anova(mixed_state_condition_predictions_max.m,mixed_state_condition_predictions_age2_max.m)
summary(mixed_state_condition_predictions.m)
```

# Bias in Prediction

How often are participants choosing the option indicating controllability (no matter if it's accurate)?
```{r bias in diagnostic predictions}
num_diagnosticChoices <- 60

controllableChoices <- diagnosticStatePredictions[ which((diagnosticStatePredictions$state=='1' & diagnosticStatePredictions$hyp_LR == '1' & diagnosticStatePredictions$resp_choice1 == '3') | (diagnosticStatePredictions$state=='2' & diagnosticStatePredictions$hyp_LR == '2' & diagnosticStatePredictions$resp_choice1 == '1') | (diagnosticStatePredictions$state=='3' & diagnosticStatePredictions$hyp_LR == '1' & diagnosticStatePredictions$resp_choice1 == '2')), ]


#number choices that were aligned with controllable option regardless of accuracy
n_controllableChoices <- controllableChoices %>% group_by(SubjID) %>% dplyr::count(resp_acc)
n_controllableChoices <- plyr::ddply(n_controllableChoices, ("SubjID"), summarise, n_controlChoices=sum(n))
n_controllableChoices$prop_controlChoices <- n_controllableChoices$n_controlChoices/num_diagnosticChoices

meanAccParticipant <- merge(meanAccParticipant,n_controllableChoices, by ="SubjID")



#plot proportion selected controllable condition
#closer to 1 is greater number of controllable choices
prop_select_control <-ggplot(data=meanAccParticipant, aes(x=Age, y=prop_controlChoices)) + geom_point() +
  geom_smooth(method="lm",alpha=.4, color="black") +
  labs(y="Proportion Diagnostic Controllable Choices") +  #label y-axis and legends
  geom_hline(yintercept=.5, linetype="dashed", color = "black") + #line at chance
  ylim(0,1) +
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22)) 
plot(prop_select_control) 

prop_control <- lm(n_controlChoices~z_age,data=meanAccParticipant)
summary(prop_control)
```

How often are participants choosing each pilot (no matter if it's accurate)?
```{r bias in pilot predictions}
totalTrials <- 60

#plot proportion selected controllable condition
prop_select_control <-ggplot(data=subset(selections_per_condition, resp_choice1 == "2"), aes(x=Age, y=n/totalTrials)) + geom_point() + #uncontrollable: 1 and controllable: 2
  geom_smooth(method="lm",alpha=.4, color="black") +
  labs(y="Proportion Controllable Choices") +  #label y-axis and legends
  geom_hline(yintercept=.5, linetype="dashed", color = "black") + #line at chance
  ylim(0,1) +
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22)) 
plot(prop_select_control) 

selections_age <- lm((n/totalTrials)~z_age,data=subset(selections_per_condition, resp_choice1 == "2"))
summary(selections_age)
```

#Learning
##Figures-State Pred

```{r state prediction learning plot}
dataAllSubjs_learning$Condition <- as.factor(dataAllSubjs_learning$Condition)
levels(dataAllSubjs_learning$Condition) <- c("Uncontrollable","Controllable")
dataAllSubjs_learning$Condition<- factor(dataAllSubjs_learning$Condition, levels = c("Uncontrollable", "Controllable"))

dataAllSubjs_learning$Condition_sorted <- dataAllSubjs_learning$Condition
dataAllSubjs_learning$Condition_sorted <- factor(dataAllSubjs_learning$Condition_sorted, levels=rev(levels(dataAllSubjs_learning$Condition_sorted)))


## plot accuracy as of a function of trial number for each condition
learning_conditions <- dataAllSubjs_learning %>% group_by(num_trials,Condition) %>% summarise(N = n(), meanAcc = mean(resp_acc, na.rm = TRUE), sdAcc = sd(resp_acc, na.rm = TRUE), seAcc = sdAcc/(sqrt(N)))

learning_cond_plot <- ggplot(learning_conditions, aes(x = num_trials, y=meanAcc, color=Condition)) +
    geom_line() + 
    geom_smooth(method="lm", aes(fill=Condition),alpha=.4,size=2) +
    labs(x="Prediction Trial Number", y="State Prediction Accuracy") +
    ylim(0,1) +
    geom_hline(yintercept=.33, linetype="dashed", color = "black") + #line at chance
    theme_classic() + theme(axis.text=element_text(size=16), axis.title=element_text(size=26), legend.text=element_text(size=16),  legend.title=element_text(size=18), legend.position="right") +
    scale_color_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) +          scale_fill_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) 
plot(learning_cond_plot)


## plot accuracy as of a function of trial number for each condition, with separate panels per age group
learning_conditions_ages <- dataAllSubjs_learning %>% group_by(num_trials,Condition_sorted,AgeGroup_sorted) %>% summarise(N = n(), meanAcc = mean(resp_acc, na.rm = TRUE), sdAcc = sd(resp_acc, na.rm = TRUE), seAcc = sdAcc/(sqrt(N)))

stateAcc_learning_cond_age_plot <- ggplot(learning_conditions_ages, aes(x = num_trials, y=meanAcc, color=Condition_sorted)) +
    geom_line(alpha=.5) + 
    facet_wrap(~AgeGroup_sorted) +
    geom_smooth(method="lm", aes(fill=Condition_sorted),alpha=.4,size=1.5) +
    labs(x="Trial Number", y="State Prediction Accuracy") +
    ylim(0,1) +
    geom_hline(yintercept=.33, linetype="dashed", color = "black") + #line at chance
    theme_classic(base_size=14) + theme(legend.position="none") + 
    #theme(axis.text=element_text(size=16), axis.title=element_text(size=26), legend.text=element_text(size=16),  legend.title=element_text(size=18), legend.position = c(0.85, 0.25),strip.text.x = element_text(size=16)) +
    scale_color_manual(values=c('#559CAD', '#3D5A80'),name="Condition") + scale_fill_manual(values=c('#559CAD', '#3D5A80'),name="Condition") 
plot(stateAcc_learning_cond_age_plot)

#ggsave(filename="/Users/hillaryraab/Box Sync/HartleyLab_SHARED/1_STUDIES/MonCon_HillaryKaterina/Analyses/Hillary/figures/manuscript/learningCurves.png", plot=learning_cond_age_plot, dpi=300, height = 5, width = 8, units="in")

```

##Stats-State Pred
Accuracy improves across the task. 
```{r trial, warnings=FALSE,message=FALSE}
dataAllSubjs$globalPredictiveTrialNum <- as.numeric(dataAllSubjs$globalPredictiveTrialNum)
dataAllSubjs$z_globalPredictiveTrialNum<-scale(dataAllSubjs$globalPredictiveTrialNum,center=TRUE,scale=TRUE) # trial num as continuous variable, mean centered and scaled

#does accuracy improve across the task?
accuracyTrial_noAge.m <- mixed(resp_acc~z_globalPredictiveTrialNum+(1|SubjID),data=dataAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
accuracyTrial_linAge.m <- mixed(resp_acc~z_globalPredictiveTrialNum*z_age+(1|SubjID),data=dataAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
accuracyTrial_sqAge.m <- mixed(resp_acc~z_globalPredictiveTrialNum*(z_age+z_ageSq)+(1|SubjID),data=dataAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

#test for best model
anova(accuracyTrial_noAge.m,accuracyTrial_linAge.m,accuracyTrial_sqAge.m)

#best model
summary(accuracyTrial_linAge.m)
```

Overall trials for all state predictions.
There are sig. effects of trial, condition, age and trial*condition interaction on state prediction accuracy.
```{r trial*condition, warnings=FALSE,message=FALSE}
dataAllSubjs_learning$globalPredictiveTrialNum <- as.numeric(dataAllSubjs_learning$globalPredictiveTrialNum)
dataAllSubjs_learning$z_globalPredictiveTrialNum<-scale(dataAllSubjs_learning$globalPredictiveTrialNum,center=TRUE,scale=TRUE)

#does accuracy differ across the task by condition?
#use below regression that includes condition and trial as random slopes
#accuracyTrialCon_linAge.m <- mixed(resp_acc~z_globalPredictiveTrialNum*Condition*z_age+(1|SubjID),data=dataAllSubjs,control=lmerControl(optCtrl=list(maxfun=100000)),method="LRT") #doesn't converge if maximal; including condition as random slope returns same results
#accuracyTrialCon_sqAge.m <- mixed(resp_acc~z_globalPredictiveTrialNum*Condition*(z_age+z_ageSq)+(1|SubjID),data=dataAllSubjs,control=lmerControl(optCtrl=list(maxfun=100000)),method="LRT")

#test for best model
#anova(accuracyTrialCon_linAge.m,accuracyTrialCon_sqAge.m)

#best model
#summary(accuracyTrialCon_linAge.m)

## Including random slopes
#does accuracy differ across the task by condition?
accuracyTrialCon_linAge_randomslopes.m <- mixed(resp_acc~z_globalPredictiveTrialNum*Condition*z_age+(1+z_globalPredictiveTrialNum*Condition|SubjID),data=dataAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT") 
accuracyTrialCon_sqAge_randomslopes.m <- mixed(resp_acc~z_globalPredictiveTrialNum*Condition*(z_age+z_ageSq)+(1+z_globalPredictiveTrialNum*Condition|SubjID),data=dataAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

#test for best model
#takes a while to run so commented out for now b/c other model provides better fit
anova(accuracyTrialCon_linAge_randomslopes.m,accuracyTrialCon_sqAge_randomslopes.m)

#best model
summary(accuracyTrialCon_linAge_randomslopes.m)
```


```{r number trials, eval = FALSE}
#want to use overall trial numbers rather than trials per condition
dataAllSubjs_learning$z_num_trials <- scale(dataAllSubjs_learning$num_trials,center=TRUE,scale=TRUE)
accuracyTrialPerCon_linAge_trialnumcondition.m <- mixed(resp_acc~z_num_trials*Condition*z_age+(1|SubjID),data=dataAllSubjs_learning,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
summary(accuracyTrialPerCon_linAge_trialnumcondition.m)
```

##Figures-Diagnostic Pred
```{r diagnostic prediction learning plot}
diagnosticStatePredictions_learning$Condition <- as.factor(diagnosticStatePredictions_learning$Condition)
levels(diagnosticStatePredictions_learning$Condition) <- c("Uncontrollable","Controllable")

## plot accuracy as of a function of trial number for each condition, with separate panels per age group
diagLearning_conditions_ages <- diagnosticStatePredictions_learning %>% group_by(num_trials,Condition,AgeGroup_sorted) %>% summarise(N = n(), meanAcc = mean(resp_acc, na.rm = TRUE), sdAcc = sd(resp_acc, na.rm = TRUE), seAcc = sdAcc/(sqrt(N)))

learning_cond_age_plot <- ggplot(diagLearning_conditions_ages, aes(x = num_trials, y=meanAcc, color=Condition)) +
    geom_line() + 
    facet_wrap(~AgeGroup_sorted) +
    geom_smooth(method="lm", aes(fill=Condition),alpha=.4,size=2,color="black") +
    labs(x="Trial Number", y="Diag Prediction Accuracy") +
    ylim(.3,1) +
    geom_hline(yintercept=.33, linetype="dashed", color = "black") + #line at chance
    theme_classic() +
    scale_color_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) +          scale_fill_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) 
plot(learning_cond_age_plot)
```

##Stats-Diagnostic Pred
```{r diagnostic prediction learning regressions}
diagnosticStatePredictions_learning$globalPredictiveTrialNum <- as.numeric(diagnosticStatePredictions_learning$globalPredictiveTrialNum)
diagnosticStatePredictions_learning$z_globalPredictiveTrialNum<-scale(diagnosticStatePredictions_learning$globalPredictiveTrialNum,center=TRUE,scale=TRUE)

## Including random slopes
#does accuracy differ across the task by condition?
accuracyTrialCon_linAge_randomslopes.m <- mixed(resp_acc~z_globalPredictiveTrialNum*Condition*z_age+(1+z_globalPredictiveTrialNum*Condition|SubjID),data=diagnosticStatePredictions_learning,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT") 
#model takes a long time and simpler model provides better fit
#accuracyTrialCon_sqAge_randomslopes.m <- mixed(resp_acc~z_globalPredictiveTrialNum*Condition*(z_age+z_ageSq)+(1+z_globalPredictiveTrialNum*Condition|SubjID),data=diagnosticStatePredictions_learning,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

#test for best model
#anova(accuracyTrialCon_linAge_randomslopes.m,accuracyTrialCon_sqAge_randomslopes.m)

#best model
summary(accuracyTrialCon_linAge_randomslopes.m)
```

##Figures-Confirmatory Pred
```{r confirmatory prediction learning plot}
confirmatoryStatePredictions_learning$Condition <- as.factor(confirmatoryStatePredictions_learning$Condition)
levels(confirmatoryStatePredictions_learning$Condition) <- c("Uncontrollable","Controllable")

## plot accuracy as of a function of trial number for each condition, with separate panels per age group
confLearning_conditions_ages <- confirmatoryStatePredictions_learning %>% group_by(num_trials,Condition,AgeGroup_sorted) %>% summarise(N = n(), meanAcc = mean(resp_acc, na.rm = TRUE), sdAcc = sd(resp_acc, na.rm = TRUE), seAcc = sdAcc/(sqrt(N)))

learning_cond_age_plot <- ggplot(confLearning_conditions_ages, aes(x = num_trials, y=meanAcc, color=Condition)) +
    geom_line() + 
    facet_wrap(~AgeGroup_sorted) +
    geom_smooth(method="lm", aes(fill=Condition),alpha=.4,size=2,color="black") +
    labs(x="Trial Number", y="Confirmatory Prediction Accuracy") +
    ylim(.3,1) +
    geom_hline(yintercept=.33, linetype="dashed", color = "black") + #line at chance
    theme_classic() +
    scale_color_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) +          scale_fill_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) 
plot(learning_cond_age_plot)
```

*Note: maximal model wouldn't converge so took out condition from mixed-effects model*
```{r confirmatory prediction learning regressions}
confirmatoryStatePredictions_learning$globalPredictiveTrialNum <- as.numeric(confirmatoryStatePredictions_learning$globalPredictiveTrialNum)
confirmatoryStatePredictions_learning$z_globalPredictiveTrialNum<-scale(confirmatoryStatePredictions_learning$globalPredictiveTrialNum,center=TRUE,scale=TRUE)

## Including random slopes
#does accuracy differ across the task by condition?
accuracyTrialCon_linAge_randomslopes.m <- mixed(resp_acc~z_globalPredictiveTrialNum*Condition*z_age+(1+z_globalPredictiveTrialNum|SubjID),data=confirmatoryStatePredictions_learning,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT") #doesn't converge if maximal; including condition as random slope returns same results
#models take a while to run and simpler is better so commenting out this model
#accuracyTrialCon_sqAge_randomslopes.m <- mixed(resp_acc~z_globalPredictiveTrialNum*Condition*(z_age+z_ageSq)+(1+z_globalPredictiveTrialNum|SubjID),data=confirmatoryStatePredictions_learning,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

#test for best model
#anova(accuracyTrialCon_linAge_randomslopes.m,accuracyTrialCon_sqAge_randomslopes.m)

#best model
summary(accuracyTrialCon_linAge_randomslopes.m)
```
##Figures-Condition Pred
```{r condition prediction learning plot}
pilotPredictionAllSubjs$Condition <- as.factor(pilotPredictionAllSubjs$Condition) 
levels(pilotPredictionAllSubjs$Condition) <- c("Uncontrollable","Controllable")

pilotLearning <- pilotPredictionAllSubjs %>% group_by(globalPredictiveTrialNum) %>% summarise(N = n(), meanAcc = mean(resp_acc, na.rm = TRUE), sdAcc = sd(resp_acc, na.rm = TRUE), seAcc = sdAcc/(sqrt(N)))

pilotLearning_plot <- ggplot(pilotLearning, aes(x = globalPredictiveTrialNum, y=meanAcc)) +
    geom_line() + 
    geom_smooth(method="lm", aes(),alpha=.4,size=2,color="black") +
    theme_classic() + 
    ylim(0,1) +
    labs(x="Trial Number", y="Condition Prediction Accuracy")
plot(pilotLearning_plot)


pilotLearning_conditions <- pilotPredictionAllSubjs %>% group_by(globalPredictiveTrialNum,Condition) %>% summarise(N = n(), meanAcc = mean(resp_acc, na.rm = TRUE), sdAcc = sd(resp_acc, na.rm = TRUE), seAcc = sdAcc/(sqrt(N)))

pilotLearning_cond_plot <- ggplot(pilotLearning_conditions, aes(x = globalPredictiveTrialNum, y=meanAcc, color=Condition)) +
    geom_line() + 
    geom_smooth(method="lm", aes(fill=Condition),alpha=.4,size=2,color="black") +
    labs(x="Trial Number", y="Condition Prediction Accuracy") +
    ylim(0,1) +
    theme_classic() + 
    scale_color_manual(values=c('#559CAD', '#3D5A80'),name="Condition") +          
    scale_fill_manual(values=c('#559CAD', '#3D5A80'),name="Condition")
plot(pilotLearning_cond_plot)
```

##Stats-Condition Pred
Accuracy improves across the task. 
```{r condition prediction learning stats, warnings=FALSE,message=FALSE}
pilotPredictionAllSubjs$globalPredictiveTrialNum <- as.numeric((pilotPredictionAllSubjs$globalPredictiveTrialNum)/2)
pilotPredictionAllSubjs$z_globalPredictiveTrialNum<-scale(pilotPredictionAllSubjs$globalPredictiveTrialNum,center=TRUE,scale=TRUE) # trial num as continuous variable, mean centered and scaled
pilotPredictionAllSubjs$resp_acc <- as.numeric(pilotPredictionAllSubjs$resp_acc)

#does accuracy improve across the task?
accuracyTrial_linAge.m <- mixed(resp_acc~z_globalPredictiveTrialNum*z_age+(1|SubjID),data=pilotPredictionAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
accuracyTrial_sqAge.m <- mixed(resp_acc~z_globalPredictiveTrialNum*(z_age+z_ageSq)+(1|SubjID),data=pilotPredictionAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

#test for best model
anova(accuracyTrial_linAge.m,accuracyTrial_sqAge.m)

#best model
summary(accuracyTrial_linAge.m)
```

There is a sig. effect of trial and age on accuracy on condition prediction trials.
```{r trial*condition on condition prediction, warnings=FALSE,message=FALSE}
#does accuracy differ across the task by condition?
#these do not converge even when removing correlations between random intercepts and random slopes and random slopes for the interaction effects
#accuracyTrialCon_linAge_fac.m <- mixed(resp_acc~z_globalPredictiveTrialNum*Condition*z_age+(1+Condition+z_globalPredictiveTrialNum||SubjID),data=pilotPredictionAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT")
#accuracyTrialCon_sqAge_fac.m <- mixed(resp_acc~z_globalPredictiveTrialNum*Condition*(z_age+z_ageSq)+(1+Condition+z_globalPredictiveTrialNum||SubjID),data=pilotPredictionAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

#test for best model
#anova(accuracyTrialCon_linAge.m,accuracyTrialCon_sqAge.m)

#best model
#summary(accuracyTrialCon_linAge.m)
```
#Trials since reversal
##Figures

*State Prediction accuracy since reversals*
```{r accuracy since reversal plot}
#accuracy on state prediction trials by condition and age group
streakCondition_all <- dataAllSubjs %>% group_by(Condition, streak) %>% summarise(N = n(), meanAcc = mean(resp_acc, na.rm = TRUE), sdAcc = sd(resp_acc, na.rm = TRUE), seAcc = sdAcc/(sqrt(N)))

```

```{r accuracy since reversal}
streakCondition_all$Condition <- as.factor(streakCondition_all$Condition)
levels(streakCondition_all$Condition) <- c("Uncon","Con")

streak_all_plot <- ggplot(data=streakCondition_all, aes(x=streak/6, y=meanAcc, color = Condition)) + geom_point() +
  geom_line() +
  labs(x= "Trials since reversal", y="State Prediction Trial Accuracy") +
  ylim(0,1) +
  theme_classic() +
  scale_color_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) +          scale_fill_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) 
plot(streak_all_plot)
```

*Diagnostic accuracy since reversals*
```{r accuracy since reversals}
#accuracy on diagnostic trials by condition and age group
streakCondition <- diagnosticStatePredictions %>% group_by(Condition, streak) %>% summarise(N = n(), meanAcc = mean(resp_acc, na.rm = TRUE), sdAcc = sd(resp_acc, na.rm = TRUE), seAcc = sdAcc/(sqrt(N)))

#accuracy on confirmatory trials by condition and age group
streakCondition_conf <- confirmatoryStatePredictions %>% group_by(Condition, streak) %>% summarise(N = n(), meanAcc = mean(resp_acc, na.rm = TRUE), sdAcc = sd(resp_acc, na.rm = TRUE), seAcc = sdAcc/(sqrt(N)))
```

```{r diagnostic accuracy since reversal}
streakCondition$Condition <- as.factor(streakCondition$Condition)
levels(streakCondition$Condition) <- c("Uncon","Con")

streak_diag_plot <- ggplot(data=streakCondition, aes(x=streak/6, y=meanAcc, color = Condition)) + geom_point() +
  geom_line() +
  labs(x= "Trials since reversal", y="Diagnostic Prediction Trial Accuracy") +
  theme_classic() +
  ylim(0,1) +
  scale_color_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) +          scale_fill_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) 
plot(streak_diag_plot)
```

*Confirmatory accuracy since reversals*
```{r confirmatory accuracy since reversal}
streakCondition_conf$Condition <- as.factor(streakCondition_conf$Condition)
levels(streakCondition_conf$Condition) <- c("Uncon","Con")

streak_conf_plot <- ggplot(data=streakCondition_conf, aes(x=streak/6, y=meanAcc, color = Condition)) + geom_point() +
  geom_line() +
  labs(x= "Trials since reversal", y="Confirmatory Prediction Trial Accuracy") +
  theme_classic() +
  ylim(0,1) +
  scale_color_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) +          scale_fill_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) 
plot(streak_conf_plot)
```

##Stats
*Accuracy Following Reversals*
Effect of age on accuracy
Effect of age, condition, and age*condition on accuracy
```{r accuracy reversals, warnings=FALSE,message=FALSE}
dataAllSubjs$z_streak<- scale(dataAllSubjs$streak,center=TRUE,scale=TRUE)

dataAllSubjs$Condition<- as.factor(dataAllSubjs$Condition)
dataAllSubjs$state<- as.factor(dataAllSubjs$state)
#dataAllSubjs$resp_acc <- as.numeric(dataAllSubjs$resp_acc)


accuracyFollowingReversal_linAge.m <- mixed(resp_acc~z_streak*z_age+(1+z_streak|SubjID),data=dataAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
accuracyFollowingReversal_sqAge.m <- mixed(resp_acc~z_streak*(z_age+z_ageSq)+(1+z_streak|SubjID),data=dataAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

#test for best model
anova(accuracyFollowingReversal_linAge.m,accuracyFollowingReversal_sqAge.m)

#best model
summary(accuracyFollowingReversal_linAge.m)


#accuracy following reversals by condition
accuracyConFollowingReversal_linAge.m <- mixed(resp_acc~z_streak*Condition*z_age+(1+Condition|SubjID),data=dataAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
accuracyConFollowingReversal_sqAge.m <- mixed(resp_acc~z_streak*Condition*(z_age+z_ageSq)+(1+Condition|SubjID),data=dataAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

#test for best model
anova(accuracyConFollowingReversal_linAge.m,accuracyConFollowingReversal_sqAge.m)

#best model
summary(accuracyConFollowingReversal_linAge.m)
```

*Diagnostic Accuracy Following Reversals*
Effect of age on diagnostic accuracy
```{r diagnostic reversals, warnings=FALSE,message=FALSE}
diagnosticStatePredictions$z_streak<- scale(diagnosticStatePredictions$streak/6,center=TRUE,scale=TRUE)

diagAccuracyFollowingReversal_linAge.m <- mixed(resp_acc~z_streak*Condition*z_age+(1+z_streak|SubjID),data=diagnosticStatePredictions,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
diagAccuracyFollowingReversal_sqAge.m <- mixed(resp_acc~z_streak*Condition*(z_age+z_ageSq)+(1+z_streak|SubjID),data=diagnosticStatePredictions,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

#test for best model
anova(diagAccuracyFollowingReversal_linAge.m,diagAccuracyFollowingReversal_sqAge.m)

#best model
summary(diagAccuracyFollowingReversal_linAge.m)
```

*Confirmatory Accuracy Following Reversals*
Effect of streak and age on confirmatory accuracy
```{r confirmatory reversals, warnings=FALSE,message=FALSE}
confirmatoryStatePredictions$z_streak<- scale(confirmatoryStatePredictions$streak/6,center=TRUE,scale=TRUE)

#maximal models did not converge
confirmAccuracyFollowingReversal_linAge.m <- mixed(resp_acc~z_streak*z_age+(1|SubjID),data=confirmatoryStatePredictions,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
confirmAccuracyFollowingReversal_sqAge.m <- mixed(resp_acc~z_streak*(z_age+z_ageSq)+(1|SubjID),data=confirmatoryStatePredictions,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

#test for best model
anova(confirmAccuracyFollowingReversal_linAge.m,confirmAccuracyFollowingReversal_sqAge.m)

#best model
summary(confirmAccuracyFollowingReversal_linAge.m)
```


```{r previous condition type on accuracy, include=FALSE}
#Effects of previous condition type on accuracy
#library(useful)
#using the condition type the participant experienced during the previous round to predict accuracy
#prevCondition <- shift.column(data = dataAllSubjs,columns="Condition",newNames="prevCondition", len=1, up=FALSE)
#prevCondition <- prevCondition[!prevCondition$globalPredictiveTrialNum=="1",]


#logistic regression models for effects of previous condition on accuracy
#m3_sqAge_prevCondition <- mixed(resp_acc~prevCondition*Condition*(z_age+z_ageSq)+(1|SubjID),data=prevCondition,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

#does this fit better than the model with just condition and accuracy?
#these are different size so can't compare
#lrtest(m3b_sqAge$full_model,m3_sqAge_prevCondition$full_model)

#results for logistic regression predicting accuracy
#previous condition type is a significant predictor of accuracy (n=71)
#summary(m2_linAge_prevCondition)
```

#Exploratory Trials
```{r initialize exploratory trials}
setwd("/Users/hillaryraab/Box Sync/HartleyLab_Shared/1_Studies/MonCon_HillaryKaterina/Analyses/Hillary/")

#load data
exploreAllSubjs <- read.csv(file.path(baseDir,dataDir,'exploreAllSubjs_n90.csv') ,header=FALSE) 

#add headers
colnames(exploreAllSubjs)<- c("SubjID","Run","globalNumWPractice","globalTrialNum","runTrialNum","streak","reversalNum","Condition","noise1","noise2","noise3","state","snext","smax","violation","side","resp_side","resp_RT","resp_choice","trial_onset","resp_onset")

exploreAllSubjs$SubjID <- as.factor(exploreAllSubjs$SubjID)

#add age
exploreAllSubjs <- merge(exploreAllSubjs,Age,by="SubjID")



#proportion optimal choice during exploratory trials
#recode all choices to either 1) optimal 0)not optimal
#optimal choices
exploreAllSubjs$optimalChoice[exploreAllSubjs$state==1 & exploreAllSubjs$resp_choice==1] <- 1
exploreAllSubjs$optimalChoice[exploreAllSubjs$state==2 & exploreAllSubjs$resp_choice==3] <- 1
exploreAllSubjs$optimalChoice[exploreAllSubjs$state==3 & exploreAllSubjs$resp_choice==2] <- 1


#not optimal choices
exploreAllSubjs$optimalChoice[exploreAllSubjs$state==1 & exploreAllSubjs$resp_choice==2] <- 0
exploreAllSubjs$optimalChoice[exploreAllSubjs$state==2 & exploreAllSubjs$resp_choice==1] <- 0
exploreAllSubjs$optimalChoice[exploreAllSubjs$state==3 & exploreAllSubjs$resp_choice==3] <- 0

#proportion optimal choices for each participant
optimalChoice <- exploreAllSubjs %>% group_by(SubjID) %>% summarize(total_optimalChoice = sum(optimalChoice, na.rm = TRUE), optimalChoice = mean(optimalChoice, na.rm = TRUE))

#merge with accuracy
meanAccParticipant <- merge(meanAccParticipant,optimalChoice,by="SubjID")
meanAccParticipant$z_optimalChoice <- scale(meanAccParticipant$optimalChoice,center=TRUE,scale=TRUE)

#optimalChoice <- merge(meanAccParticipant,optimalChoice,by="SubjID")
```

##Figures
*Exploration by age*
```{r optimal choice by age}
#plot age on x, optimal choice on y
#participants make slightly more optimal choices with age (not sig.)
graphOptimalChoicebyAge <- ggplot(data=meanAccParticipant, aes(x=Age, y=optimalChoice)) + geom_point(size=3) +
geom_smooth(method="lm",formula = y ~ poly(x, 2),alpha=.4,size=2, color = "black") +
theme_classic() + labs(y="Optimal Exploratory Choice") + 
geom_hline(yintercept=.5, linetype="dashed", color = "black") + #line at chance
  theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=16), legend.title=element_text(size=20)) #change theme
plot(graphOptimalChoicebyAge)

#ggsave(filename="/Users/hillaryraab/Box Sync/Hartley Lab/Conferences/SANS 2019/posterFigures/Fig OptChoice~Age.png", plot=graphOptimalChoicebyAge, dpi=300, height = 5, width = 8, units="in")
#ggsave(filename="Fig OptChoice~Age.png", plot=graphOptimalChoicebyAge, dpi=300, height = 5, width = 8, units="in")
#ggsave(filename="/Users/hillaryraab/Box Sync/HartleyLab_SHARED/1_STUDIES/MonCon_HillaryKaterina/Analyses/Hillary/figures/manuscript/optimalChoice.png", plot=graphOptimalChoicebyAge, dpi=300, height = 5, width = 7, units="in")
```

*Exploration by accuracy*
```{r Optimal choice by accuracy}
graphOptimalChoicebyAcc <- ggplot(data=meanAccParticipant, aes(x=optimalChoice, y=stateMeanAcc)) + geom_point(size=3) +
  geom_smooth(method="lm",alpha=.4,size=3, color = "black") +
  theme_classic() + labs(x="Optimal Exploratory Choice", y = "State Prediction Accuracy") +
  geom_hline(yintercept=.33, linetype="dashed", color = "black") + #line at chance
  geom_vline(xintercept=.5, linetype="dashed", color = "black") + 
  coord_cartesian(ylim = c(.25, 1)) +
  theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=16), legend.title=element_text(size=20)) #change theme
plot(graphOptimalChoicebyAcc)

#ggsave(filename="/Users/hillaryraab/Box Sync/Hartley Lab/Conferences/SANS 2019/posterFigures/Fig Acc~OptChoice.png", plot=graphOptimalChoicebyAcc, dpi=300, height = 5, width = 8, units="in")

```

```{r Optimal choice by diagnostic accuracy}
graphOptimalChoicebyAcc <- ggplot(data=meanAccParticipant, aes(x=optimalChoice, y=diagMeanAcc)) + geom_point(size=3) +
  geom_smooth(method="lm",alpha=.4,size=3, color = "black") +
  theme_classic() + labs(x="Optimal Exploratory Choice", y = "Diagnostic Prediction Accuracy") +
  geom_hline(yintercept=.33, linetype="dashed", color = "black") + #line at chance
  geom_vline(xintercept=.5, linetype="dashed", color = "black") + 
  coord_cartesian(ylim = c(.25, 1)) +
  theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=16), legend.title=element_text(size=20)) #change theme
plot(graphOptimalChoicebyAcc)

#ggsave(filename="/Users/hillaryraab/Box Sync/Hartley Lab/Conferences/SANS 2019/posterFigures/Fig Acc~OptChoice.png", plot=graphOptimalChoicebyAcc, dpi=300, height = 5, width = 8, units="in")

```
How does exploration differ across groups? Took 95% CI around chance performance on exploratory trials and looked at performance above (optimal) and below (suboptimal) chance performance (random). Only in the optimal group does exploratory choice relate to accurate state predictions.
```{r exploratory groups}
#calculate 95% CI around chance performance on exploratory trials
confIntBinom = binom.test(180, 360, p =.5, alternative ="two.sided", conf.level = .95)

meanAccParticipant$optimalChoice_group[meanAccParticipant$optimalChoice<confIntBinom$conf.int[1]] <- "Suboptimal"
meanAccParticipant$optimalChoice_group[meanAccParticipant$optimalChoice>=confIntBinom$conf.int[1] & meanAccParticipant$optimalChoice<=confIntBinom$conf.int[2]] <- "Random"
meanAccParticipant$optimalChoice_group[meanAccParticipant$optimalChoice>confIntBinom$conf.int[2]] <- "Optimal"


explo_groups <- ggplot(meanAccParticipant, aes(x = optimalChoice, y=stateMeanAcc, color=optimalChoice_group, fill=optimalChoice_group )) +
  geom_point() +
  geom_smooth(method="lm",aes(color=optimalChoice_group, fill=optimalChoice_group), alpha=.4,size=2) +
  labs(x="Optimal Exploratory Choice", y = "State Prediction Accuracy") +
  theme(axis.text=element_text(size=16), axis.title=element_text(size=26), legend.text=element_text(size=16), legend.title=element_text(size=20)) + #change theme
   coord_cartesian(ylim = c(.3, 1)) +
  scale_color_manual(name = "Explore Group", values = c("#A7A5C6", "#2F9C95", "#6A687A")) +
  scale_fill_manual(name = "Explore Group", values = c("#A7A5C6", "#2F9C95", "#6A687A"))
plot(explo_groups)

#ggsave(filename="/Users/hillaryraab/Box Sync/HartleyLab_SHARED/1_STUDIES/MonCon_HillaryKaterina/Analyses/Hillary/figures/manuscript/exploGroups.png", plot=explo_groups, dpi=300, height = 5, width = 8, units="in")

suboptimal_age.m <- lm(stateMeanAcc ~ z_optimalChoice*z_age,data=subset(meanAccParticipant, optimalChoice<confIntBinom$conf.int[1]))
random_age.m <- lm(stateMeanAcc ~z_optimalChoice*z_age,data=subset(meanAccParticipant, optimalChoice>=confIntBinom$conf.int[1] & optimalChoice <= confIntBinom$conf.int[2]))
optimal_age.m <- lm(stateMeanAcc ~z_optimalChoice*z_age,data=subset(meanAccParticipant, optimalChoice>confIntBinom$conf.int[2]))

summary(suboptimal_age.m)
summary(random_age.m)
summary(optimal_age.m)
```

##Stats
*age-squared effect on optimal choice?*
```{r, cache=FALSE}

#does age predict optimal choice
optimalChoiceExplor_age <- lm(optimalChoice~z_age,data=meanAccParticipant)
optimalChoiceExplor_ageSq <- lm(optimalChoice~z_age+z_ageSq,data=meanAccParticipant)

anova(optimalChoiceExplor_age,optimalChoiceExplor_ageSq)
summary(optimalChoiceExplor_ageSq)
```

*Effects of optimal choice on state prediction accuracy*
Effects of optimal choice and age on state prediction accuracy
```{r effects optimal choice on state prediction accuracy}
#does optimal choice predict accuracy
statePred_optimal.m <- lm(stateMeanAcc~z_optimalChoice,data=meanAccParticipant)
statePred_optimal_age.m <- lm(stateMeanAcc~z_optimalChoice*z_age,data=meanAccParticipant)
statePred_optimal_ageSq.m <- lm(stateMeanAcc~z_optimalChoice*(z_age+z_ageSq),data=meanAccParticipant)

anova(statePred_optimal.m,statePred_optimal_age.m,statePred_optimal_ageSq.m)
summary(statePred_optimal_age.m)
```

Effects of optimal choice and age on diagnostic state prediction accuracy
```{r effects optimal choice on diagnostic state prediction accuracy}
#does optimal choice predict diagnostic accuracy
diagStatePred_optimal.m <- lm(diagMeanAcc~z_optimalChoice,data=meanAccParticipant)
diagStatePred_optimal_age.m <- lm(diagMeanAcc~z_optimalChoice*z_age,data=meanAccParticipant)
diagStatePred_optimal_ageSq.m <- lm(diagMeanAcc~z_optimalChoice*(z_age+z_ageSq),data=meanAccParticipant)

anova(diagStatePred_optimal.m,diagStatePred_optimal_age.m,diagStatePred_optimal_ageSq.m)
summary(diagStatePred_optimal_age.m)
```

*Effects of optimal choice on condition prediction accuracy*
Effects of optimal choice and age on condition prediction accuracy
```{r effects optimal choice on condition prediction accuracy}
#does optimal choice predict accuracy
pilotPred_optimal.m <- lm(pilotMeanAcc~z_optimalChoice,data=meanAccParticipant)
pilotPred_optimal_age.m <- lm(pilotMeanAcc~z_optimalChoice*z_age,data=meanAccParticipant)
pilotPred_optimal_ageSq.m <- lm(pilotMeanAcc~z_optimalChoice*(z_age+z_ageSq),data=meanAccParticipant)

anova(pilotPred_optimal.m,pilotPred_optimal_age.m,pilotPred_optimal_ageSq.m)
summary(pilotPred_optimal_age.m)
```

#Exploratory Trials by Condition
```{r initialize exploratory trials by condition}
#proportion optimal choices for each participant by condition
optimalChoiceByCondition <- exploreAllSubjs %>% group_by(SubjID,Condition) %>% summarize(optimalChoiceByCondition = mean(optimalChoice, na.rm = TRUE))

optimalChoiceByCondition$SubjID <- as.factor(optimalChoiceByCondition$SubjID)
optimalChoiceByCondition$Condition <- as.factor(optimalChoiceByCondition$Condition)
levels(optimalChoiceByCondition$Condition) <- c("Uncontrollable","Controllable")

levels(meanAccs$Condition) <- c("Uncontrollable","Controllable")

meanAccs <- merge(meanAccs,optimalChoiceByCondition,by=c("SubjID","Condition"))

#scale and center age
#optimalChoiceByCondition$z_age<-scale(optimalChoiceByCondition$Age,center=TRUE,scale=TRUE) # age as continuous variable, mean centered and scaled
#optimalChoiceByCondition$z_ageSq<-scale(optimalChoiceByCondition$AgeSq,center=TRUE,scale=TRUE) #age squared as continuous variable, mean centered and scaled
```


##Figures
*Age by Optimal Choice*
```{r age optimal choice}
###### age on x, accuracy on y, condition color
#participants make slightly more optimal choices in the uncontrollable condition and with age
#optimalChoiceByCondition$Condition<- as.factor(optimalChoiceByCondition$Condition)
x<-ggplot(data=meanAccs, aes(x=Age, y=optimalChoiceByCondition , color=Condition)) + geom_point() + #uncontrollable: 1 and controllable: 2
  geom_smooth(method="lm", aes(color=Condition, fill=Condition), alpha=.4, size = 3) + geom_point(size=3) +
  labs(y="Proportion Optimal Choice during Exploration") + #label y-axis and legends
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=20), legend.text=element_text(size=20), legend.title=element_text(size=20), legend.position="top") +
  scale_color_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) + scale_fill_manual(values=c('#559CAD', '#3D5A80'),name="Condition", labels=c("Uncontrollable", "Controllable")) 
#legend.position="none")
plot(x) 
```

*Optimal Choice by Accuracy*
```{r optimal choice accuracy, message=FALSE, warning=FALSE}
###### optimal exploratory performance on x, accuracy on y, age color
#Controllable and uncontrollable plots side by side

#q<-ggplot(data=subset(optimalChoiceByCondition, Condition ==1), aes(x=optimalChoiceByCondition, y=meanAcc , color=Age)) + geom_point() + #uncontrollable: 1 and controllable: 2
#  geom_smooth(method="lm", aes(color=Age, fill=Age), alpha=.4, size = 2,color="black") + geom_point(size=2)  +
#  coord_fixed(ratio=1, ylim = c(0, 1.01), xlim = c(0, 1.01), expand=FALSE) +
#  labs(x="Proportion Optimal Choice during Exploration",y="Accuracy on State Prediction", title="Uncontrollable")  #label y-axis and legends

#r<-ggplot(data=subset(optimalChoiceByCondition, Condition ==2), aes(x=optimalChoiceByCondition, y=meanAcc , color=Age)) + #geom_point() + #uncontrollable: 1 and controllable: 2
#  geom_smooth(method="lm", aes(color=Age, fill=Age), alpha=.4, size = 2,color="black") + geom_point(size=2)  +
#  coord_fixed(ratio=1, ylim = c(0, 1.01), xlim = c(0, 1.01), expand=FALSE) +
#  labs(x="Proportion Optimal Choice during Exploration",y="Accuracy on State Prediction", title="Controllable")  #label y-axis and legends

#library(cowplot)
#plot_grid(q,r)


#optimalChoiceByCondition$Condition <- as.factor(optimalChoiceByCondition$Condition)
#levels(optimalChoiceByCondition$Condition) <- c("Uncontrollable","Controllable")


s<-ggplot(data=meanAccs, aes(x=optimalChoiceByCondition, y=meanAcc , color=Age)) + geom_point() + #uncontrollable: 1 and controllable: 2
  geom_smooth(method="lm", aes(color=Age, fill=Age), alpha=.4, size = 2,color="black") + geom_point(size=2)  +
  facet_grid(~Condition) +
  coord_fixed(ratio=1, ylim = c(0, 1.01), xlim = c(0, 1.01), expand=FALSE) +
  labs(x="Proportion Optimal Choice during Exploration",y="Accuracy on State Prediction")  #label y-axis and legends
plot(s)

```


*Optimal Choice following reversals*
```{r reversals}
#optimal choice following reversals

#proportion optimal choices for each participant
optimalChoiceFollowingReversal <- exploreAllSubjs %>% group_by(AgeGroup, streak) %>% summarize(optimalChoice = mean(optimalChoice, na.rm = TRUE))

optimalChoiceFollowingReversalPar <- exploreAllSubjs %>% group_by(SubjID, Age, streak) %>% summarize(optimalChoice = mean(optimalChoice, na.rm = TRUE))

#rename and sort age groups
optimalChoiceFollowingReversal$AgeGroup_sorted <- factor(optimalChoiceFollowingReversal$AgeGroup, levels=c('Child','Teen','Adult')) #order by age
levels(optimalChoiceFollowingReversal$AgeGroup_sorted) <- c("Children","Adolescents","Adults") #rename


#plot optimal choice by number reversals
ggplot(data=optimalChoiceFollowingReversal, aes(x=streak,y=optimalChoice,color=AgeGroup_sorted)) + geom_point() +
  geom_smooth(method="lm", aes() + geom_point(size=3)) +
  labs(y="Proportion Optimal Choice",x="Trials since reversal") +
  ylim(0,1) +
  scale_color_manual(name = "Age Group", values = c("#A7A5C6", "#2F9C95", "#6A687A")) +
  scale_fill_manual(name = "Age Group", values = c("#A7A5C6", "#2F9C95", "#6A687A"))

```


##Stats
*Age and Age squared predict optimal choice*
```{r}
##do age, condition, or age*condition predict optimal choice?
optimalChoiceExplorCond_age <- lm(optimalChoiceByCondition~z_age*Condition,data=meanAccs)
optimalChoiceExplorCond_ageSq <- lm(optimalChoiceByCondition~(z_age+z_ageSq)*Condition,data=meanAccs)

#model comparison
anova(optimalChoiceExplorCond_age,optimalChoiceExplorCond_ageSq)

summary(optimalChoiceExplorCond_ageSq)
```

*Effects of condition, age, and optimal choice on mean accuracy*
*Optimal choice, age, and condition predict mean accuracy*
```{r}
##do optimal choice per condition, age*condition, age*optimalChoice per condition * condition predict accuracy on prediction trials?
meanAccs$z_optimalChoiceByCondition<-scale(meanAccs$optimalChoiceByCondition,center=TRUE,scale=TRUE) #age squared as continuous variable, mean centered and scaled


optimalChoiceByConditionExplor <- lm(meanAcc~z_optimalChoiceByCondition*Condition,data=meanAccs)
optimalChoiceByConditionExplor_age <- lm(meanAcc~z_age*z_optimalChoiceByCondition*Condition,data=meanAccs)
optimalChoiceByConditionExplor_ageSq <- lm(meanAcc~(z_age+z_ageSq)*z_optimalChoiceByCondition*Condition,data=meanAccs)

#model comparison
anova(optimalChoiceByConditionExplor,optimalChoiceByConditionExplor_age,optimalChoiceByConditionExplor_ageSq)

summary(optimalChoiceByConditionExplor_age)
```

*Effects of condition, age, and optimal choice on diagnostic state accuracy*
*Optimal choice, age, and condition predict diagnostic accuracy*
```{r diagnostic prediction by condition, age, optimal choice}
##do optimal choice per condition, age*condition, age*optimalChoice per condition * condition predict accuracy on prediction trials?

diagnosticStatePredictions$Condition <- as.factor(diagnosticStatePredictions$Condition)
levels(diagnosticStatePredictions$Condition) <- c("Uncontrollable","Controllable")

diagAccCondition <- diagnosticStatePredictions %>% group_by(SubjID,Condition) %>% summarize(diagAcc = mean(resp_acc, na.rm = TRUE))

#levels(meanAccs$Condition) <- c("Uncontrollable","Controllable")

meanAccs <- merge(meanAccs, diagAccCondition, by = c("SubjID", "Condition"))
#meanAccs <- merge(meanAccs,optimalChoiceByCondition, by=c("SubjID", "Condition"))


optimalChoiceByConditionExplor <- lm(diagAcc~z_optimalChoiceByCondition*Condition,data=meanAccs)
optimalChoiceByConditionExplor_age <- lm(diagAcc~z_age*z_optimalChoiceByCondition*Condition,data=meanAccs)
optimalChoiceByConditionExplor_ageSq <- lm(diagAcc~(z_age+z_ageSq)*z_optimalChoiceByCondition*Condition,data=meanAccs)

#model comparison
anova(optimalChoiceByConditionExplor,optimalChoiceByConditionExplor_age,optimalChoiceByConditionExplor_ageSq)

summary(optimalChoiceByConditionExplor_age)
```

*Optimal Choice Following Reversals*
Main effect of streak on optimal choice
```{r, warnings=FALSE,message=FALSE}
exploreAllSubjs$z_streak<- scale(exploreAllSubjs$streak,center=TRUE,scale=TRUE)

optimalChoiceFollowingReversal.m <- mixed(optimalChoice~z_streak*z_age+(1+z_streak|SubjID),data=exploreAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
summary(optimalChoiceFollowingReversal.m)
```

#Learning to explore
```{r learning during exploratory trials}
exploreAllSubjs$globalTrialNum <- as.numeric(exploreAllSubjs$globalTrialNum)
exploreAllSubjs$z_globalTrialNum<-scale(exploreAllSubjs$globalTrialNum,center=TRUE,scale=TRUE) # trial num as continuous variable, mean centered and scaled

optimalChoiceLearning_age.m <- mixed(optimalChoice~z_globalTrialNum*z_age+(1+z_globalTrialNum|SubjID),data=exploreAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")
optimalChoiceLearning_ageSq.m <- mixed(optimalChoice~z_globalTrialNum*(z_age+z_ageSq)+(1+z_globalTrialNum|SubjID),data=exploreAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=100000)),family="binomial",method="LRT")

anova(optimalChoiceLearning_age.m,optimalChoiceLearning_ageSq.m)
summary(optimalChoiceLearning_ageSq.m)


#Examine effects of condition, age, trial on optimal exploratory choice
exploreAllSubjs$Condition_factor <- as.factor(exploreAllSubjs$Condition)

optimalChoiceLearningCond1_age.m <- mixed(optimalChoice~z_globalTrialNum*z_age*Condition_factor+(1+Condition_factor*z_globalTrialNum|SubjID),data=exploreAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT")

optimalChoiceLearningCond1_ageSq.m <- mixed(optimalChoice~z_globalTrialNum*(z_age+z_ageSq)*Condition_factor+(1+Condition_factor*z_globalTrialNum|SubjID),data=exploreAllSubjs,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT")

anova(optimalChoiceLearningCond1_age.m,optimalChoiceLearningCond1_ageSq.m)
summary(optimalChoiceLearningCond1_ageSq.m)

library(sjPlot)
tab_model(optimalChoiceLearningCond1_ageSq.m, show.se = TRUE, show.stat = TRUE)


#create trial num for learning plots and analyses
uncon_explo_trials <- exploreAllSubjs[exploreAllSubjs$Condition == 1,]
numTrials <- uncon_explo_trials %>% group_by(SubjID) %>% summarise(num_rows = length(SubjID))
uncon_explo_trials$num_trials <- rep(1:numTrials$num_rows[1],times=length(numTrials$SubjID))


con_explo_trials <- exploreAllSubjs[exploreAllSubjs$Condition == 2,]
numTrials <- con_explo_trials %>% group_by(SubjID) %>% summarise(num_rows = length(SubjID))
con_explo_trials$num_trials <- rep(1:numTrials$num_rows[1],times=length(numTrials$SubjID))

exploreAllSubjs_learning <- rbind(uncon_explo_trials, con_explo_trials)

exploreAllSubjs_learning$Condition <- as.factor(exploreAllSubjs_learning$Condition)
levels(exploreAllSubjs_learning$Condition) <- c("Uncontrollable","Controllable")

exploreAllSubjs_learning$AgeGroup_sorted <- factor(exploreAllSubjs_learning$AgeGroup, levels=c('Child','Teen','Adult')) #order by age
levels(exploreAllSubjs_learning$AgeGroup_sorted) <- c("Children","Adolescents","Adults") #rename



## plot optimal choice as of a function of trial number for each condition, with separate panels per age group
exploLearning_conditions_ages <- exploreAllSubjs_learning %>% group_by(num_trials,Condition,AgeGroup_sorted) %>% summarise(N = n(), optChoice = mean(optimalChoice, na.rm = TRUE), sdOptChoice = sd(optimalChoice, na.rm = TRUE), seOptChoice = sdOptChoice/(sqrt(N)))

exploLearning_conditions_ages$Condition_sorted <- exploLearning_conditions_ages$Condition
exploLearning_conditions_ages$Condition_sorted <- factor(exploLearning_conditions_ages$Condition_sorted, levels=rev(levels(exploLearning_conditions_ages$Condition_sorted)))

learning_cond_age_plot <- ggplot(exploLearning_conditions_ages, aes(x = num_trials, y=optChoice, color=Condition_sorted)) +
    geom_line(size=.5, alpha =.5) + 
    facet_wrap(~AgeGroup_sorted) +
    geom_smooth(method="lm", aes(fill=Condition_sorted),alpha=.4,size=1.5) +
    labs(x="Trial Number", y="Optimal Exploratory Choice") +
    ylim(0,1) +
    geom_hline(yintercept=.5, linetype="dashed", color = "black") + #line at chance
    theme_classic(base_size = 14) + theme(legend.position="right") +
    #theme(axis.text=element_text(size=16), axis.title=element_text(size=26), legend.text=element_text(size=16),       
    #legend.title=element_text(size=18), strip.text.x = element_text(size=16)) +
    scale_color_manual(values=c('#559CAD', '#3D5A80'),name="Condition") +          
  scale_fill_manual(values=c('#559CAD', '#3D5A80'),name="Condition") 
plot(learning_cond_age_plot)
```


```{r figure 2}
fig2 <- plot_grid(stateAcc_learning_cond_age_plot, learning_cond_age_plot, align="h", axis = "bt",labels = c('a','b'), rel_widths = c(1,1.4))
plot(fig2)
#ggsave(filename="/Users/hillaryraab/Box Sync/HartleyLab_SHARED/1_STUDIES/MonCon_HillaryKaterina/Analyses/Hillary/figures/manuscript/Raab_etal_fig2.png", plot=fig3, dpi=300, height = 4, width = 10, units="in")
```


# What type of errors are they making on state predictions?
```{r state prediction errors}
#OVERALL TRIALS
#select incorrect choices
incorrect <- dataAllSubjs[ which(dataAllSubjs$resp_acc=='0') ,]

#count incorrect choices per subj
n_incorrect <- incorrect %>% dplyr::count(SubjID)
names(n_incorrect)[names(n_incorrect) == 'n'] <- 'n_errors'

#what kind of mistake
#suboptimal: neither true in controllable nor uncontrollable condition; always least likely choice
suboptimal_mistake <- incorrect[ which((incorrect$state=='1' & incorrect$resp_choice1 == '1') | (incorrect$state=='2' & incorrect$resp_choice1 == '2' ) | (incorrect$state=='3' & incorrect$resp_choice1 == '3')), ]

n_suboptimal_mistake <- suboptimal_mistake %>% dplyr::count(SubjID)
names(n_suboptimal_mistake)[names(n_suboptimal_mistake) == 'n'] <- 'n_errors_subopt'

n_incorrect <- merge(n_incorrect,n_suboptimal_mistake,by="SubjID",all = TRUE)
n_incorrect[is.na(n_incorrect)] <- 0

#proportion of errors that were second best choice
n_incorrect$errors_propOpt <- 1 - (n_incorrect$n_errors_subopt/n_incorrect$n_errors)
remove(n_suboptimal_mistake, incorrect)


#DIAGNOSTIC TRIALS
incorrect_diagnostic <- diagnosticStatePredictions[which(diagnosticStatePredictions$resp_acc=='0'),]

#count incorrect choices per subj
n_incorrect_diagnostic <- incorrect_diagnostic %>% dplyr::count(SubjID)
names(n_incorrect_diagnostic)[names(n_incorrect_diagnostic) == 'n'] <- 'n_diag_errors'

#suboptimal: neither true in controllable nor uncontrollable condition; always least likely choice
suboptimal_diag_error <- incorrect_diagnostic[ which((incorrect_diagnostic$state=='1' & incorrect_diagnostic$resp_choice1 == '1') | (incorrect_diagnostic$state=='2' & incorrect_diagnostic$resp_choice1 == '2' ) | (incorrect_diagnostic$state=='3' & incorrect_diagnostic$resp_choice1 == '3')), ]

n_suboptimal_diag_error <- suboptimal_diag_error %>% dplyr::count(SubjID)
names(n_suboptimal_diag_error)[names(n_suboptimal_diag_error) == 'n'] <- 'n_diag_errors_subopt'

n_incorrect_diagnostic <- merge(n_incorrect_diagnostic,n_suboptimal_diag_error,by="SubjID",all = TRUE)
n_incorrect_diagnostic[is.na(n_incorrect_diagnostic)] <- 0


#proportion of errors that were second best choice
n_incorrect_diagnostic$diag_errors_propOpt <- 1 - (n_incorrect_diagnostic$n_diag_errors_subopt/n_incorrect_diagnostic$n_diag_errors)
remove(n_suboptimal_diag_error, incorrect_diagnostic)


#CONFIRMATORY TRIALS
incorrect_confirmatory <- confirmatoryStatePredictions[which(confirmatoryStatePredictions$resp_acc=='0'),]

#count incorrect choices per subj
n_incorrect_confirmatory <- incorrect_confirmatory %>% dplyr::count(SubjID)
names(n_incorrect_confirmatory)[names(n_incorrect_confirmatory) == 'n'] <- 'n_conf_errors'

#suboptimal: neither true in controllable nor uncontrollable condition; always least likely choice
suboptimal_conf_error <- incorrect_confirmatory[ which((incorrect_confirmatory$state=='1' & incorrect_confirmatory$resp_choice1 == '1') | (incorrect_confirmatory$state=='2' & incorrect_confirmatory$resp_choice1 == '2' ) | (incorrect_confirmatory$state=='3' & incorrect_confirmatory$resp_choice1 == '3')), ]

n_suboptimal_conf_error <- suboptimal_conf_error %>% dplyr::count(SubjID)
names(n_suboptimal_conf_error)[names(n_suboptimal_conf_error) == 'n'] <- 'n_conf_errors_subopt'

n_incorrect_confirmatory <- merge(n_incorrect_confirmatory,n_suboptimal_conf_error,by="SubjID",all = TRUE)
n_incorrect_confirmatory[is.na(n_incorrect_confirmatory)] <- 0


#proportion of errors that were second best choice
n_incorrect_confirmatory$conf_errors_propOpt <- 1 - (n_incorrect_confirmatory$n_conf_errors_subopt/n_incorrect_confirmatory$n_conf_errors)
remove(n_suboptimal_conf_error, incorrect_confirmatory)


n_incorrect <- merge(n_incorrect,n_incorrect_diagnostic,by="SubjID",all = TRUE)
n_incorrect <- merge(n_incorrect,n_incorrect_confirmatory,by="SubjID",all = TRUE)

remove(n_incorrect_confirmatory,n_incorrect_diagnostic)

n_incorrect$prop_diag_errors <- n_incorrect$n_diag_errors/n_incorrect$n_errors

meanAccParticipant <- merge(meanAccParticipant, n_incorrect[, c("SubjID","errors_propOpt","diag_errors_propOpt","conf_errors_propOpt","prop_diag_errors")], by ="SubjID", all.x=TRUE)
```

*Note that two people are not included as they didn't make any errors throughout the entire game*
Which types of trials are individuals making more mistakes on?
Of all errors, adults are making a greater proportion of errors on diagnostic trials, as compared to younger individuals.
```{r proportion errors on diagnostic trials}
#errors on confirmatory trials
errors_plot<-ggplot(data=meanAccParticipant, aes(x=Age, y=prop_diag_errors)) + geom_point() +
  geom_smooth(method="lm", aes() + geom_point(), color = "black") +
  labs(y="Diagnostic Errors/Total Errors") +  #label y-axis and legends
  ylim(0,1) +
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=24)) 
plot(errors_plot) 

##does age predict errors on confirmatory prediction trials?
errors_age <- lm(prop_diag_errors~z_age,data=meanAccParticipant)
errors_ageSq <- lm(prop_diag_errors~z_age+z_ageSq,data=meanAccParticipant)
#model comparison
anova(errors_age,errors_ageSq)
#best model
summary(errors_age)
```

## Does the type of trials that individuals are making more mistakes on change from the first to second half of the task?
```{r mistakes on which type of prediction trial - by block}
#OVERALL TRIALS

#label blocks
dataAllSubjs$Block<-ifelse(dataAllSubjs$globalPredictiveTrialNum<61,'first_block',
		ifelse(dataAllSubjs$globalPredictiveTrialNum>60, 'second_block', 'NA'))

#count incorrect choices per subj, remove total trials correct, and rename column
n_incorrect_block <- dataAllSubjs %>% dplyr::count(SubjID,Block,resp_acc)
n_incorrect_block <- n_incorrect_block[n_incorrect_block$resp_acc!=1 ,]
names(n_incorrect_block)[names(n_incorrect_block) == 'n'] <- 'n_total_errors' 


#DIAGNOSTIC TRIALS
#label blocks
diagnosticStatePredictions$Block<-ifelse(diagnosticStatePredictions$globalPredictiveTrialNum<61,'first_block',
		ifelse(diagnosticStatePredictions$globalPredictiveTrialNum>60, 'second_block', 'NA'))

#count incorrect choices per subj, remove total trials correct, and rename column
n_incorrect_block_diag <- diagnosticStatePredictions %>% dplyr::count(SubjID,Block,resp_acc)
n_incorrect_block_diag <- n_incorrect_block_diag[n_incorrect_block_diag$resp_acc!=1 ,]
names(n_incorrect_block_diag)[names(n_incorrect_block_diag) == 'n'] <- 'n_diag_errors'

n_incorrect_block <- merge(n_incorrect_block, n_incorrect_block_diag[,c("SubjID","Block","n_diag_errors")], by=c("SubjID","Block"), all.x=TRUE)

n_incorrect_block$prop_diag_errors <- n_incorrect_block$n_diag_errors/n_incorrect_block$n_total_errors

n_incorrect_block <- merge(n_incorrect_block, meanAccParticipant[,c("SubjID","Age","AgeGroup_sorted","z_age","z_ageSq")], by=c("SubjID"), all.y=TRUE)

##does block predict proportion of errors on diagnostic prediction trials?
block_errors_age <- lm(prop_diag_errors~z_age*Block,data=n_incorrect_block, na.action=na.exclude)
block_errors_ageSq <- lm(prop_diag_errors~(z_age+z_ageSq)*Block,data=n_incorrect_block, na.action=na.exclude)
#model comparison
anova(block_errors_age,block_errors_ageSq)
#best model
summary(block_errors_age)
```

```{r plot of change in proportion of errors on diagnostic predictions by block}
errors_plot<-ggplot(data=n_incorrect_block, aes(x=Age, y=prop_diag_errors)) + geom_point() +
  geom_smooth(method="lm", aes() + geom_point(), color = "black") +
  facet_wrap(~Block) +
  labs(y="Errors on Diagnostic Predictions/Total Errors") +  #label y-axis and legends
  ylim(0,1) +
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=24)) 
plot(errors_plot) 
```




What types of mistakes are individuals making and how does that change with age?
With increasing age, individuals are making more of the optimal error types (suggesting they believe they are in the other controllability condition). This effect is mainly driven by the diagnostic prediction trials.
```{r error plots}
#overall errors
errors_plot<-ggplot(data=meanAccParticipant, aes(x=Age, y=errors_propOpt)) + geom_point() +
  geom_smooth(method="lm", aes() + geom_point(), color = "black") +
  labs(y="Prop. Optimal Errors") +  #label y-axis and legends
  ylim(0,1) +
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=24)) 
plot(errors_plot) 

##does age predict errors on state prediction trials?
errors_age <- lm(errors_propOpt~z_age,data=meanAccParticipant)
errors_ageSq <- lm(errors_propOpt~z_age+z_ageSq,data=meanAccParticipant)
#model comparison
anova(errors_age,errors_ageSq)
#best model
summary(errors_age)


#errors on diagnostic trials
errors_plot<-ggplot(data=meanAccParticipant, aes(x=Age, y=diag_errors_propOpt)) + geom_point() +
  geom_smooth(method="lm", aes() + geom_point(), color = "black") +
  labs(y="Prop. Optimal Diagnostic Errors") +  #label y-axis and legends
  ylim(0,1) +
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=24)) 
plot(errors_plot) 

##does age predict errors on diagnostic prediction trials?
errors_age <- lm(diag_errors_propOpt~z_age,data=meanAccParticipant)
errors_ageSq <- lm(diag_errors_propOpt~z_age+z_ageSq,data=meanAccParticipant)
#model comparison
anova(errors_age,errors_ageSq)
#best model
summary(errors_age)
```

*and 11 people aren't included in confirmatory prediction errors b/c they either made no errors or only diagnostic errors*
On confirmatory trials, people are making the same types of mistakes with age.
```{r confirmatory error plots}
#errors on confirmatory trials
errors_plot<-ggplot(data=meanAccParticipant, aes(x=Age, y=conf_errors_propOpt)) + geom_point() +
  geom_smooth(method="lm", aes() + geom_point(), color = "black") +
  labs(y="Prop. Optimal Confirmatory Errors") +  #label y-axis and legends
  ylim(0,1) +
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=24)) 
plot(errors_plot) 

##does age predict errors on confirmatory prediction trials?
errors_age <- lm(conf_errors_propOpt~z_age,data=meanAccParticipant)
errors_ageSq <- lm(conf_errors_propOpt~z_age+z_ageSq,data=meanAccParticipant)
#model comparison
anova(errors_age,errors_ageSq)
#best model
summary(errors_age)
```


```{r errors during state predictions, eval = FALSE}
#load the output from the matlab script errorCalculation
errors <- read.csv("/Users/hillaryraab/Box Sync/HartleyLab_Shared/1_Studies/MonCon_HillaryKaterina/Analyses/Hillary/n_90/MonCon_errors.csv" ,header=FALSE) 

#name the columns. errors refers to total errors. condition errors refers to when people choose the wrong island because they are picking the island associated with the other condition. Stim mistakes are when participants are picking the island that is also being asked about. This is the island least likely to transition to and also makes it seem like they haven't learned the transition properties of the game.
colnames(errors) <- c("errors","conditionErrors","stimErrors")

#merge with meanAccParticipant df
meanAccParticipant <- cbind(meanAccParticipant,errors)

#calculate the proportion of errors made that were condition errors
meanAccParticipant$propConditionErrors <- meanAccParticipant$conditionErrors/meanAccParticipant$errors

errors_plot<-ggplot(data=meanAccParticipant, aes(x=Age, y=propConditionErrors)) + geom_point() +
  geom_smooth(method="lm", aes() + geom_point(size=3), color = "black") +
  labs(y="Condition Errors/Total Errors") +  #label y-axis and legends
  ylim(0,1) +
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=24)) 
plot(errors_plot) 
```


#Errors in 1 vs 2 half
Do children understand the structure of the task?
```{r errors during state predictions in 1st vs 2nd half}
#load the output from the matlab script errorCalculation
errors_byHalf <- read.csv("/Users/hillaryraab/Box Sync/HartleyLab_Shared/1_Studies/MonCon_HillaryKaterina/Analyses/Hillary/n_90/MonCon_errors_byHalf.csv" ,header=FALSE) 

#name the columns. errors refers to total errors. condition errors refers to when people choose the wrong island because they are picking the island associated with the other condition. Stim mistakes are when participants are picking the island that is also being asked about. This is the island least likely to transition to and also makes it seem like they haven't learned the transition properties of the game.
colnames(errors_byHalf) <- c("errors_1st","errors_2nd","conditionErrors_1st","conditionErrors_2nd","stimErrors_1st","stimErrors_2nd")

#merge with meanAccParticipant df
meanAccParticipant <- cbind(meanAccParticipant,errors_byHalf)

#calculate the proportion of errors made that were condition errors
meanAccParticipant$propConditionErrors_1st <- meanAccParticipant$conditionErrors_1st/meanAccParticipant$errors_1st
meanAccParticipant$propConditionErrors_2nd <- meanAccParticipant$conditionErrors_2nd/meanAccParticipant$errors_2nd


errors_plot_byHalf1<-ggplot(data=meanAccParticipant, aes(x=Age, y=propConditionErrors_1st)) + geom_point() +
  geom_smooth(method="lm", aes() + geom_point(size=3), color = "black") +
  ggtitle('First half of task') +
  labs(y="Condition Errors/Total Errors") +  #label y-axis and legends
  ylim(0,1) +
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=24)) 

errors_plot_byHalf2<-ggplot(data=meanAccParticipant, aes(x=Age, y=propConditionErrors_2nd)) + geom_point() +
  geom_smooth(method="lm", aes() + geom_point(size=3), color = "black") +
  ggtitle('Second half of task') +
  labs(y="Condition Errors/Total Errors") +  #label y-axis and legends
  ylim(0,1) +
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=24)) 

plot_grid(errors_plot_byHalf1,errors_plot_byHalf2)
```

Does the proportion of condition errors change from block 1 to block 2?
*No, it seems that participants do not make a greater proportion of condition errors (the optimal type of error) from the first half to second half of the task.*
```{r}
#create new dataframe in long format w/ block 1 and block 2 of task
blocked_Errors <- gather(meanAccParticipant[c("SubjID","Age","AgeGroup_sorted","z_age","z_ageSq","propConditionErrors_1st","propConditionErrors_2nd")], block, propConditionErrors, propConditionErrors_1st:propConditionErrors_2nd, factor_key = TRUE)
                               
##does block predict errors?
block_errors_age <- lm(propConditionErrors~z_age*block,data=blocked_Errors, na.action=na.exclude)
block_errors_ageSq <- lm(propConditionErrors~(z_age+z_ageSq)*block,data=blocked_Errors, na.action=na.exclude)
#model comparison
anova(block_errors_age,block_errors_ageSq)
#best model
summary(block_errors_age)
```

# How do errors relate to exploration?
```{r errors and exploration}
##does optimal exploration (controlling for age) predict the proportion of errors on discriminatory/total state predictions?
errors_explo_age <- lm(prop_diag_errors~z_age + z_optimalChoice,data=meanAccParticipant)
errors_explo_ageSq <- lm(prop_diag_errors~(z_age+z_ageSq) * z_optimalChoice,data=meanAccParticipant)
#model comparison
anova(errors_explo_age,errors_explo_ageSq)
#best model
summary(errors_explo_age)

##does optimal exploration (controlling for age) predict the proportion of optimal errors during all state prediction trials?
Opterrors_explo_age <- lm(errors_propOpt~z_age + z_optimalChoice,data=meanAccParticipant)
Opterrors_explo_ageSq <- lm(errors_propOpt~(z_age+z_ageSq) * z_optimalChoice,data=meanAccParticipant)
#model comparison
anova(Opterrors_explo_age,Opterrors_explo_ageSq)
#best model
summary(Opterrors_explo_age)
```


# Mutual Information
Mutual information is 0 if two conditions are indepedent of one another. Greater MI reflects the more information you know about X, the more information you know about Y.

## Mutual Information - explo trials only
```{r MI w/ age explo}
MI <- read.csv("/Users/hillaryraab/Box Sync/HartleyLab_Shared/1_Studies/MonCon_HillaryKaterina/Analyses/MutualInformation/MI_90_onlyexploretrials.csv" ,header=FALSE) 

colnames(MI) <- c("MI")

meanAccParticipant$MI_explo <- MI$MI
meanAccParticipant$z_MI_explo <- scale(meanAccParticipant$MI_explo,center=TRUE,scale=TRUE)


MI_age_plot<-ggplot(data=meanAccParticipant, aes(x=Age, y=MI_explo)) + geom_point() +
  geom_smooth(method="lm", aes() + geom_point(size=3), color = "black") +
  labs(y="Mutual Information Explo (bits)") +  #label y-axis and legends
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=24), legend.title=element_blank(), legend.position="top") 
plot(MI_age_plot) 


MI_age.m <- lm(MI_explo~z_age,data=meanAccParticipant)
MI_agePlusAgeSq.m <-lm(MI_explo~z_age+z_ageSq,data=meanAccParticipant)
anova(MI_age.m,MI_agePlusAgeSq.m)
summary(MI_age.m)
```

##State Predictions
```{r MI accuracy explo}
MI_acc_plot<-ggplot(data=meanAccParticipant, aes(x=MI_explo, y=stateMeanAcc)) + geom_point(size=2) +
  geom_smooth(method="lm", aes() + geom_point(size=3), color = "black") +
  labs(x="Mutual Information Explo (bits)", y="Accuracy State Predictions") +  #label y-axis and legends
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=24), legend.title=element_blank(), legend.position="top") 
plot(MI_acc_plot) 


MI_acc_age.m <- lm(stateMeanAcc~z_MI_explo*z_age,data=meanAccParticipant)
MI_acc_agePlusAgeSq.m <-lm(stateMeanAcc~z_MI_explo*(z_age+z_ageSq),data=meanAccParticipant)
anova(MI_acc_age.m,MI_acc_agePlusAgeSq.m)
summary(MI_acc_agePlusAgeSq.m)
```


```{r MI acc age plot explo}

MI_acc_AgeBin <- ggplot(meanAccParticipant, aes(x = MI_explo, y=stateMeanAcc,color=AgeGroup_sorted,fill=AgeGroup_sorted)) +
  geom_point() +
  geom_smooth(fullrange= TRUE, method="lm", aes(color=AgeGroup_sorted,fill=AgeGroup_sorted),alpha=.4,size=2) +
  labs(x="Mutual Information (bits)", y="State Prediction Accuracy") + 
  #ylim(.3,1.05) +
  coord_cartesian(ylim=c(0.3,1.0)) +
  theme(axis.text=element_text(size=16), axis.title=element_text(size=26), legend.text=element_text(size=16), legend.title=element_text(size=18)) + #change theme
  scale_color_manual(name = "Age Group", values = c("#A7A5C6", "#2F9C95", "#6A687A")) +
  scale_fill_manual(name = "Age Group", values = c("#A7A5C6", "#2F9C95", "#6A687A"))

plot(MI_acc_AgeBin)

#ggsave(filename="/Users/hillaryraab/Box Sync/HartleyLab_SHARED/1_STUDIES/MonCon_HillaryKaterina/Analyses/Hillary/figures/manuscript/MIacc.png", plot=MI_acc_AgeBin, dpi=300, height = 5, width = 8, units="in")
```

##Diagnostic State Predictions
```{r MI diag acc explo}
MI_diagacc_plot<-ggplot(data=meanAccParticipant, aes(x=MI_explo, y=diagMeanAcc)) + geom_point() +
  geom_smooth(method="lm", aes() + geom_point(size=3), color = "black") +
  ylim(0,1.05) +
  labs(x="Mutual Information Explo (bits)", y="Diag Accuracy State Predictions") +  #label y-axis and legends
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=24), legend.title=element_blank(), legend.position="top") 
plot(MI_diagacc_plot) 


MI_diagacc_age.m <- lm(diagMeanAcc~z_MI_explo*z_age,data=meanAccParticipant)
MI_diagacc_agePlusAgeSq.m <-lm(diagMeanAcc~z_MI_explo*(z_age+z_ageSq),data=meanAccParticipant)
anova(MI_diagacc_age.m,MI_diagacc_agePlusAgeSq.m)
summary(MI_diagacc_agePlusAgeSq.m)
```

```{r MI diag acc age plot explo}
diagacc_AgeBin <- ggplot(meanAccParticipant, aes(x = MI_explo,y=diagMeanAcc,color=AgeGroup_sorted,fill=AgeGroup_sorted)) +
  geom_point() +
  geom_smooth(fullrange = TRUE, method="lm",alpha=.4,size=3) +
  labs(x="Mutual Information (bits)", y="Diag State Prediction Accuracy") + 
  theme(axis.text=element_text(size=16), axis.title=element_text(size=26), legend.text=element_text(size=16), legend.title=element_text(size=20)) + #change theme
  #ylim(0.3,1.15) +
  coord_cartesian(ylim=c(0.25,1.05)) +
  scale_color_manual(name = "Age Group", values = c("#A7A5C6", "#2F9C95", "#6A687A")) +
  scale_fill_manual(name = "Age Group", values = c("#A7A5C6", "#2F9C95", "#6A687A"))

plot(diagacc_AgeBin)
```

##Condition Predictions
```{r MI condition accuracy explo}
MI_pilotAcc_plot<-ggplot(data=meanAccParticipant, aes(x=MI_explo, y=pilotMeanAcc)) + geom_point() +
  geom_smooth(method="lm", aes() + geom_point(size=3), color = "black") +
  labs(x="Mutual Information Explo (bits)", y="Accuracy Condition Predictions") +  #label y-axis and legends
  theme_classic() +theme(axis.text=element_text(size=16), axis.title=element_text(size=22), legend.text=element_text(size=24), legend.title=element_blank(), legend.position="top") 
plot(MI_pilotAcc_plot) 


MI_pilotAcc_age.m <- lm(pilotMeanAcc~z_MI_explo*z_age,data=meanAccParticipant)
MI_pilotAcc_agePlusAgeSq.m <-lm(pilotMeanAcc~z_MI_explo*(z_age+z_ageSq),data=meanAccParticipant)
anova(MI_pilotAcc_age.m,MI_pilotAcc_agePlusAgeSq.m)
summary(MI_pilotAcc_agePlusAgeSq.m)
```


```{r MI and exploratory choice explo}
MI_optChoice_plot<-ggplot(data=meanAccParticipant, aes(x=MI_explo, y=optimalChoice,color=Age)) + geom_point(size=3, alpha = .8) +
  #geom_smooth(method="lm", aes() + geom_point(), color = "black") +
  labs(x="Mutual Information Explo (bits)", y="Optimal Choice") +  #label y-axis and legends
  theme_classic(base_size=16) +theme(axis.text=element_text(), axis.title=element_text(), legend.text=element_text()) 

plot(MI_optChoice_plot) 
```

# Working Memory 
## Working Memory and age

Working memory should be normalized for age, that way age accounts for age and WM is an individual difference measure
```{r working memory initialization}
#note did not collect WM scores from handful of first participants so missing some data
WorkingMemory <- read.csv(file.path(baseDir, wmDir, "2019-06-18 13.25.50 Assessment Scores.csv"), header = TRUE)

#rename columns
WorkingMemory <- WorkingMemory %>% rename(SubjID= PIN)

#Removes word "monCon"
WorkingMemory <- WorkingMemory %>% mutate(SubjID = str_remove_all(SubjID, "MonCon"))
WorkingMemory <- WorkingMemory %>% mutate(SubjID = str_remove_all(SubjID, "Moncon"))

#get rid of :
WorkingMemory<- WorkingMemory %>% dplyr::select(-c(DeviceID, Assessment.Name, Inst,Theta, TScore, SE, ItmCnt, Column1, Column2, Column3, Column4, Column5, Language, DateFinished, App.Version, iPad.Version, Firmware.Version,Computed.Score,National.Percentile..age.adjusted., Fully.Corrected.T.score, InstrumentBreakoff,InstrumentStatus2, InstrumentRCReason,InstrumentRCReasonOther))

#only select participants who completed the task
meanAccParticipant <- meanAccParticipant[!(is.na(meanAccParticipant$stateMeanAcc)),]

#merge with task data
meanAccParticipant  <- merge(meanAccParticipant,WorkingMemory,by="SubjID", all.x = TRUE)

meanAccParticipant$z_wm_score <- scale(meanAccParticipant$Age.Corrected.Standard.Score,center=TRUE,scale=TRUE)
```

*No effect of age on corrected working memory (sanity check!)*
```{r working memory age plot}
#Working Memory Corrected for Age
r<-ggplot(data=meanAccParticipant, aes(x=Age, y= Age.Corrected.Standard.Score)) +
 geom_point() +
  geom_smooth(method="lm", alpha=.6, color="black") +
  theme_classic() +
  labs(y="Age-normed Working Memory") + labs(x="Age")
plot(r)
```


```{r}
wm_AgeBin <- ggplot(meanAccParticipant, aes(x = Age.Corrected.Standard.Score, y=stateMeanAcc,color=AgeGroup_sorted,fill=AgeGroup_sorted)) +
  geom_point() +
  geom_smooth(fullrange = TRUE, method="lm", aes(color=AgeGroup_sorted,fill=AgeGroup_sorted),alpha=.4,size=3) +
  labs(x="Working Memory (age-normed)", y="State Prediction Accuracy") + 
  theme(axis.text=element_text(size=16), axis.title=element_text(size=26), legend.text=element_text(size=16), legend.title=element_text(size=20)) + #change theme
  coord_cartesian(ylim=c(.3,1.0)) +
  scale_color_manual(name = "Age Group", values = c("#A7A5C6", "#2F9C95", "#6A687A")) +
  scale_fill_manual(name = "Age Group", values = c("#A7A5C6", "#2F9C95", "#6A687A"))

plot(wm_AgeBin)
```


```{r lm Corrected WM Age}
#age vs. age-squared models
cWM_age.m <- lm(Age.Corrected.Standard.Score~z_age,data=meanAccParticipant)
cWM_agesq.m <- lm(Age.Corrected.Standard.Score~z_age + z_ageSq,data=meanAccParticipant)

anova(cWM_age.m,cWM_agesq.m)

summary(cWM_age.m)
```

## Working Memory, age, and accuracy - State Predictions
*Effect of age and corrected working memory on state predictions*
```{r accuracy working memory plot}
s<-ggplot(data=meanAccParticipant, aes(x=Age.Corrected.Standard.Score, y=stateMeanAcc)) +
 geom_point() +
  geom_smooth(method="lm", alpha=.6, color="black") +
  theme_classic()+ #change theme
  labs(x="Corrected Working Memory") + labs(y="State Prediction Accuracy") #label x axis and y-axis
plot(s)
```

```{r accuracy age and WM lm}
#age vs. age-squared models
acc_WMage.m <- lm(stateMeanAcc~z_wm_score*z_age,data=meanAccParticipant)
acc_WMageSq.m <- lm(stateMeanAcc~z_wm_score*(z_age + z_ageSq),data=meanAccParticipant)

anova(acc_WMage.m,acc_WMageSq.m)

summary(acc_WMage.m)
```


```{r accuracy by condition WM lm}
#add wm to accuracy by condition
meanAccs  <- merge(meanAccs,meanAccParticipant[c("SubjID","Age.Corrected.Standard.Score","z_wm_score")],by="SubjID", all.x = TRUE)

#age vs. age-squared models
acc_WMConditionage.m <- lm(meanAcc~z_age*z_wm_score*Condition,data=meanAccs)
acc_WMConditionageSq.m <- lm(meanAcc~(z_age + z_ageSq)*z_wm_score*Condition,data=meanAccs)

anova(acc_WMConditionage.m,acc_WMConditionageSq.m)

summary(acc_WMConditionage.m)
```

diagnostic accuracy
```{r diagnostic accuracy}
#age vs. age-squared models
diagAcc_WMConditionage.m <- lm(diagAcc~z_age*z_wm_score*Condition,data=meanAccs)
diagAcc_WMConditionageSq.m <- lm(diagAcc~(z_age + z_ageSq)*z_wm_score*Condition,data=meanAccs)

anova(diagAcc_WMConditionage.m,diagAcc_WMConditionageSq.m)

summary(diagAcc_WMConditionageSq.m)
```

```{r working memory by condition and age bin}
wm_AgeBin <- ggplot(meanAccs, aes(x = Age.Corrected.Standard.Score, y=meanAcc,color=Condition_sorted,fill=Condition_sorted)) +
  geom_point() +
  geom_smooth(fullrange = TRUE, method="lm", aes(color=Condition_sorted,fill=Condition_sorted),alpha=.4,size=3) +
  facet_wrap(~AgeGroup_sorted) +
  labs(x="Working Memory (age-normed)", y="State Prediction Accuracy") + 
  theme_classic() +
  theme(axis.text=element_text(size=16), axis.title=element_text(size=26), legend.text=element_text(size=16), legend.title=element_text(size=20),strip.text.x = element_text(size=16)) + #change theme
  coord_cartesian(ylim=c(.3,1.0)) +
  scale_color_manual(name = "Condition", values = c('#559CAD', '#3D5A80')) +
  scale_fill_manual(name = "Condition", values = c('#559CAD', '#3D5A80'))

plot(wm_AgeBin)

#ggsave(filename="/Users/hillaryraab/Box Sync/HartleyLab_SHARED/1_STUDIES/MonCon_HillaryKaterina/Analyses/Hillary/figures/manuscript/workingMemory.png", plot=wm_AgeBin, dpi=300, height = 5, width = 9, units="in")

```

## Working Memory, age, and accuracy - Condition Predictions
*Effect of age and corrected working memory on state predictions*
```{r condition accuracy working memory plot}
pilot_wm<-ggplot(data=meanAccParticipant, aes(x=Age.Corrected.Standard.Score, y=pilotMeanAcc)) +
 geom_point() +
  geom_smooth(method="lm", alpha=.6, color="black") +
  theme_classic()+ #change theme
  labs(x="Corrected Working Memory") + labs(y="Condition Prediction Accuracy") #label x axis and y-axis
plot(pilot_wm)
```

```{r condition accuracy age and WM lm}
#age vs. age-squared models
pilotAcc_WMage.m <- lm(pilotMeanAcc~z_wm_score*z_age,data=meanAccParticipant)
pilotAcc_WMageSq.m <- lm(pilotMeanAcc~z_wm_score*(z_age + z_ageSq),data=meanAccParticipant)

anova(pilotAcc_WMage.m,pilotAcc_WMageSq.m)

summary(pilotAcc_WMage.m)
```


```{r condition accuracy by condition WM lm}
#add wm to accuracy by condition
names(meanAccs_Pilot)[names(meanAccs_Pilot) == "meanAcc"] <- "pilotMeanAcc"
names(meanAccs_Pilot)[names(meanAccs_Pilot) == "sdAcc"] <- "pilotSdAcc"
levels(meanAccs_Pilot$Condition) <- c("Uncontrollable","Controllable")

meanAccs  <- merge(meanAccs,meanAccs_Pilot[c("SubjID","Condition","pilotMeanAcc","pilotSdAcc")],by=c("SubjID","Condition"), all.x = TRUE)

#age vs. age-squared models
pilotAcc_WMConditionage.m <- lm(pilotMeanAcc~z_age*z_wm_score*Condition,data=meanAccs)
pilotAcc_WMConditionageSq.m <- lm(pilotMeanAcc~(z_age + z_ageSq)*z_wm_score*Condition,data=meanAccs)

anova(pilotAcc_WMConditionage.m,pilotAcc_WMConditionageSq.m)

summary(pilotAcc_WMConditionage.m)
```

## Working memory, age, and errors
```{r errors and exploration}
##does optimal exploration (controlling for age) predict the proportion of errors on discriminatory/total state predictions?
errors_wm_age <- lm(prop_diag_errors~z_age + z_wm_score,data=meanAccParticipant)
errors_wm_ageSq <- lm(prop_diag_errors~(z_age+z_ageSq) * z_wm_score,data=meanAccParticipant)
#model comparison
anova(errors_wm_age,errors_wm_ageSq)
#best model
summary(errors_wm_age)

##does optimal exploration (controlling for age) predict the proportion of optimal errors during all state prediction trials?
Opterrors_wm_age <- lm(errors_propOpt~z_age + z_wm_score,data=meanAccParticipant)
Opterrors_wm_ageSq <- lm(errors_propOpt~(z_age+z_ageSq) * z_wm_score,data=meanAccParticipant)
#model comparison
anova(Opterrors_wm_age,Opterrors_wm_ageSq)
#best model
summary(Opterrors_wm_age)
```

#Explicit Task Knowledge
```{r explicit knowledge questions}
#note did not collect WM scores from handful of first participants so missing some data
explicitKnowledge <- read.csv(file.path(baseDir, qDir, "MonConPostTask Q_n90.csv"), header = TRUE)

#don't change parenthesis, Delete all of () items
explicitKnowledge<- explicitKnowledge %>% dplyr::select(-c(StartDate, EndDate, Status, IPAddress, Progress, Duration..in.seconds., Finished, RecordedDate,ResponseId,RecipientLastName, RecipientFirstName, RecipientEmail,ExternalReference,LocationLatitude,LocationLongitude,DistributionChannel,UserLanguage))

#Deletes rows 1 and 2, only answers visable
explicitKnowledge<- slice(explicitKnowledge,-c(1:2))

#add column names
colnames(explicitKnowledge)<- c("SubjID","C_green","C_orange","C_pink","U_LH","U_vol", "U_PT","easierYN","easierCondition","strategy","stragey_MC","difficulty","engaging")

explicitKnowledge <- droplevels(explicitKnowledge)

#change to characters; below transformations won't work otherwise
explicitKnowledge[, ] <- lapply(explicitKnowledge[, ], as.character)

explicitKnowledge <- explicitKnowledge %>% mutate(SubjID = str_remove_all(SubjID, "MonCon"))
explicitKnowledge$SubjID <- as.factor(explicitKnowledge$SubjID)

#sum controllable total
explicitKnowledge$C_green[explicitKnowledge$C_green == 'IM_5byiwnyUq5SkLdP']<-1
explicitKnowledge$C_green[explicitKnowledge$C_green != 1]<-0
explicitKnowledge$C_green<- as.numeric(explicitKnowledge$C_green)

explicitKnowledge$C_orange[explicitKnowledge$C_orange == 'IM_cGSlDZHr9rAvI1v']<-1
explicitKnowledge$C_orange[explicitKnowledge$C_orange != 1]<-0
explicitKnowledge$C_orange<- as.numeric(explicitKnowledge$C_orange)

explicitKnowledge$C_pink[explicitKnowledge$C_pink == 'IM_20tjmbukTsjjNNX']<-1
explicitKnowledge$C_pink[explicitKnowledge$C_pink != 1]<-0
explicitKnowledge$C_pink<- as.numeric(explicitKnowledge$C_pink)


#sum uncontrollable total
explicitKnowledge$U_LH[explicitKnowledge$U_LH == 'IM_20tjmbukTsjjNNX']<-1
explicitKnowledge$U_LH[explicitKnowledge$U_LH != 1]<-0
explicitKnowledge$U_LH<- as.numeric(explicitKnowledge$U_LH)

explicitKnowledge$U_vol[explicitKnowledge$U_vol == 'IM_3lYM1VFNuPNWWwJ']<-1
explicitKnowledge$U_vol[explicitKnowledge$U_vol != 1]<-0
explicitKnowledge$U_vol<- as.numeric(explicitKnowledge$U_vol)

explicitKnowledge$U_PT[explicitKnowledge$U_PT == 'IM_4ZoANqBWGZ4sYXX']<-1
explicitKnowledge$U_PT[explicitKnowledge$U_PT != 1]<-0
explicitKnowledge$U_PT<- as.numeric(explicitKnowledge$U_PT)

explicitKnowledge$easierCondition[explicitKnowledge$easierCondition == 'IM_eQaHAXU7QfllDs9']<-'Uncontrollable'
explicitKnowledge$easierCondition[explicitKnowledge$easierCondition == 'IM_8wCDeTdgCWcZdL7']<-'Controllable'

explicitKnowledge$C_explicitKnowledge <- rowSums(explicitKnowledge[2:4])
explicitKnowledge$U_explicitKnowledge <- rowSums(explicitKnowledge[5:7])
explicitKnowledge$Total_explicitKnowledge <- rowSums(explicitKnowledge[14:15])

explicitKnowledge <- select(explicitKnowledge,"SubjID","easierYN","easierCondition","C_explicitKnowledge","U_explicitKnowledge","Total_explicitKnowledge")


explicitKnowledge$easierCondition <-as.factor(explicitKnowledge$easierCondition)

#merge with task data
meanAccParticipant  <- merge(meanAccParticipant,explicitKnowledge,by="SubjID", all.x = TRUE)
```


```{r histogram of explicit knowledge by age group}
explicitKnowledge_hist <- ggplot(meanAccParticipant, aes(Total_explicitKnowledge)) + geom_histogram(binwidth = 1) +
  facet_wrap(~AgeGroup_sorted) + labs(x = "Explicit Knowledge", y="Count")
plot(explicitKnowledge_hist)

explicitKnowledge_hist <- ggplot(meanAccParticipant, aes(C_explicitKnowledge)) + geom_histogram(binwidth = 1)+
  facet_wrap(~AgeGroup_sorted) + labs(x = "Controllable Explicit Knowledge", y="Count")
plot(explicitKnowledge_hist)

explicitKnowledge_hist <- ggplot(meanAccParticipant, aes(U_explicitKnowledge)) + geom_histogram(binwidth = 1)+
  facet_wrap(~AgeGroup_sorted) + labs(x = "Unontrollable Explicit Knowledge", y="Count")
plot(explicitKnowledge_hist)

#chi-squared test to see if proportion of correct responses differ by age group
#no difference across age groups
chisq.test(meanAccParticipant$AgeGroup, meanAccParticipant$Total_explicitKnowledge, correct = FALSE)
fisher.test(meanAccParticipant$AgeGroup, meanAccParticipant$Total_explicitKnowledge)
```

```{r histogram of explicit knowledge all correct vs not by age group}
meanAccParticipant$Total_explicitKnowledge_AllCorrect <- ifelse(meanAccParticipant$Total_explicitKnowledge == '6', c("Yes"), c("No")) 
meanAccParticipant$Total_explicitKnowledge_AllCorrect <- as.factor(meanAccParticipant$Total_explicitKnowledge_AllCorrect)

explicitKnowledge_hist_allCorrect <- ggplot(meanAccParticipant, aes(Total_explicitKnowledge_AllCorrect)) + geom_histogram(stat="count") + facet_wrap(~AgeGroup_sorted) + labs(x = "All Correct?", y="Count") + theme_classic() 
plot(explicitKnowledge_hist_allCorrect)

#chi-squared test to see if proportion of correct responses differ by age group
chisq.test(meanAccParticipant$AgeGroup_sorted,meanAccParticipant$Total_explicitKnowledge_AllCorrect,correct=FALSE)
fisher.test(meanAccParticipant$AgeGroup_sorted,meanAccParticipant$Total_explicitKnowledge_AllCorrect)


#test children vs. adults
chisq.test(meanAccParticipant$AgeGroup_sorted[meanAccParticipant$AgeGroup_sorted != 'Adolescents'],meanAccParticipant$Total_explicitKnowledge_AllCorrect[meanAccParticipant$AgeGroup_sorted != 'Adolescents'],correct=FALSE)

#test teens vs. adults
chisq.test(meanAccParticipant$AgeGroup_sorted[meanAccParticipant$AgeGroup_sorted != 'Children'],meanAccParticipant$Total_explicitKnowledge_AllCorrect[meanAccParticipant$AgeGroup_sorted != 'Children'],correct=FALSE)

#test children vs. teens
chisq.test(meanAccParticipant$AgeGroup_sorted[meanAccParticipant$AgeGroup_sorted != 'Adults'],meanAccParticipant$Total_explicitKnowledge_AllCorrect[meanAccParticipant$AgeGroup_sorted != 'Adults'],correct=FALSE)
```

```{r histogram which condition easier by age group}
explicitKnowledge_hist <- ggplot(meanAccParticipant, aes(easierYN)) + geom_histogram(stat="count") +
  facet_wrap(~AgeGroup_sorted) + labs(x = "Easier Condition?", y="Count")
plot(explicitKnowledge_hist)

chisq.test(meanAccParticipant$AgeGroup, meanAccParticipant$easierYN, correct = FALSE)

explicitKnowledge_hist <- ggplot(data=subset(meanAccParticipant,easierCondition=="Controllable" |  easierCondition=="Uncontrollable") , aes(easierCondition)) + geom_histogram(stat="count") +
  facet_wrap(~AgeGroup_sorted) + labs(x = "Which Condition?", y="Count")
plot(explicitKnowledge_hist)

chisq.test(meanAccParticipant$AgeGroup, meanAccParticipant$easierCondition, correct = FALSE)
```


# Locus Of Control
This is a questionnaire that assess internal perception of control. Higher scores indicate a higher perception of external
control, and lower scores indicate a higher perception of control. 
NOTE: BECAUSE OF AN ERROR, WE DID NOT COLLECT QUESTION 7 AND SO IT'S NOT SCORED IN THIS QUESTIONNAIRE!

```{r initialize LOC}
#NEED TO RUN LOC SCORING CODE BEFORE
#load child data
LocusOfControl_Child <- read.csv(file.path(baseDir,qDir, "LocusOfControl_Child_Scored_n90.csv"), header = TRUE)

#delete first column
LocusOfControl_Child<- LocusOfControl_Child %>% dplyr::select(-c(X))

#load adult data
LocusOfControl_Adult<- read.csv(file.path(baseDir,qDir,"LocusOfControl_Adult_Scored_n90.csv"), header=TRUE) 
                                
#delete first column
LocusOfControl_Adult<- LocusOfControl_Adult %>% dplyr::select(-c(X))

#merge child and adult data together
LocusOfControl <- dplyr::bind_rows(LocusOfControl_Adult, LocusOfControl_Child)

remove(LocusOfControl_Child,LocusOfControl_Adult)

#merge with task data
LocusOfControl$SubjID <- as.factor(LocusOfControl$SubjID)
meanAccParticipant  <- merge(meanAccParticipant,LocusOfControl,by="SubjID", all = TRUE)

#only select participants who completed the task
meanAccParticipant <- meanAccParticipant[!(is.na(meanAccParticipant$stateMeanAcc)),]

remove(LocusOfControl)
```

```{r LOC vs age}
Control_Age<-ggplot(data=meanAccParticipant, aes(x=Age, y=LOCTotal)) +
  geom_point() +
  geom_smooth(method="lm", alpha=.6, color = "black") +
  theme_classic() +
  labs(y="Locus of control") + labs(x="Age") #label x axis and y-axis
plot(Control_Age)
```

*No effect of age on LOC (sanity check)*
```{r lm LOC Age}
#age vs. age-squared models
LOC_age.m <- lm(LOCTotal~z_age,data=meanAccParticipant)
LOC_agesq.m <- lm(LOCTotal~z_age + z_ageSq,data=meanAccParticipant)

anova(LOC_age.m,LOC_agesq.m)

pander(LOC_age.m)
```


## LOC, age, and accuracy
```{r LOC accuracy plot}
t<-ggplot(data=meanAccParticipant, aes(x=LOCTotal, y=stateMeanAcc)) +
 geom_point() +
  geom_smooth(method="lm", alpha=.6, color="black") +
  theme_classic()+ #change theme
  labs(x="Locus of control") + labs(y="State Prediction Accuracy") #label x axis and y-axis
plot(t)
```

*Sig age-squared and LOC intxn on state predictions*
```{r age group: accuracy and LOC plot}

LOC_agebin <- ggplot(meanAccParticipant, aes(x = LOCTotal, y=stateMeanAcc,color=AgeGroup_sorted,fill=AgeGroup_sorted)) +
  geom_point() +
  geom_smooth(method="lm", aes(color=AgeGroup_sorted,fill=AgeGroup_sorted),alpha=.4) +
  facet_wrap(~AgeGroup_sorted) +
  labs(x="Locus of Control", y="State Prediction Acc") + 
  theme_classic() +
  theme(axis.text=element_text(size=16), axis.title=element_text(size=26), legend.text=element_text(size=16), legend.title=element_text(size=20)) + #change theme
  scale_color_manual(name = "Age Group", values = c("#A7A5C6", "#2F9C95", "#6A687A")) +
  scale_fill_manual(name = "Age Group", values = c("#A7A5C6", "#2F9C95", "#6A687A"))

plot(LOC_agebin)
```

```{r accuracy age and LOC lm}
#age vs. age-squared models
acc_LOCage.m <- lm(stateMeanAcc~LOCTotal*z_age,data=meanAccParticipant)
acc_LOCageSq.m <- lm(stateMeanAcc~LOCTotal*(z_age + z_ageSq),data=meanAccParticipant)

anova(acc_LOCage.m,acc_LOCageSq.m)

pander(acc_LOCageSq.m)
```

## LOC, age, and errors
```{r errors and exploration}
##does optimal exploration (controlling for age) predict the proportion of errors on discriminatory/total state predictions?
errors_loc_age <- lm(prop_diag_errors~z_age + LOCTotal,data=meanAccParticipant)
errors_loc_ageSq <- lm(prop_diag_errors~(z_age+z_ageSq) * LOCTotal,data=meanAccParticipant)
#model comparison
anova(errors_loc_age,errors_loc_ageSq)
#best model
summary(errors_loc_age)

##does optimal exploration (controlling for age) predict the proportion of optimal errors during all state prediction trials?
Opterrors_loc_age <- lm(errors_propOpt~z_age + LOCTotal,data=meanAccParticipant)
Opterrors_loc_ageSq <- lm(errors_propOpt~(z_age+z_ageSq) * LOCTotal,data=meanAccParticipant)
#model comparison
anova(Opterrors_loc_age,Opterrors_loc_ageSq)
#best model
summary(Opterrors_loc_age)
```

# WASI
```{r initialize WASI}
#load subject log
WASI <- read.csv(file.path(baseDir, dataDir, "WASIscores.csv"),header=FALSE) 

colnames(WASI)<- c("SubjID","Verbal","MR","IQ", "Raw_MR")

#Removes word "monCon"
WASI <- WASI %>% mutate(SubjID = str_remove_all(SubjID, "MonCon"))

meanAccParticipant <- merge(meanAccParticipant,WASI,by="SubjID", all = TRUE)
remove(WASI)
```

*No effect of age on WASI (sanity check)*
```{r WASI and age}
wasi_plot <-ggplot(data=meanAccParticipant, aes(x=Age, y=IQ)) +
  geom_point() +
  geom_smooth(method="lm", alpha=.6, color = "black") +
  theme_classic() +
  labs(y="IQ") + labs(x="Age") #label x axis and y-axis
plot(wasi_plot)
```

```{r lm IQ and age}
#age vs. age-squared models
IQ_age.m <- lm(IQ~z_age,data=meanAccParticipant)
IQ_agesq.m <- lm(IQ~z_age + z_ageSq,data=meanAccParticipant)

anova(IQ_age.m,IQ_agesq.m)

summary(IQ_age.m)

meanAccParticipant$z_IQ <-scale(meanAccParticipant$IQ,center=TRUE,scale=TRUE) # continuous variable, mean centered and scaled
IQ_age.m <- lm(IQ~z_age,data=meanAccParticipant)
z_IQ_age.m <- lm(z_IQ~z_age,data=meanAccParticipant)
Rsq1 = summary(z_IQ_age.m) $r.squared
(Rsq1)/(1-Rsq1)
```


## IQ, age, and accuracy
*Sig effect of IQ on task performance (but no intxn w/ age)*
```{r}
wasi_acc_plot <-ggplot(data=meanAccParticipant, aes(x=IQ, y=stateMeanAcc)) +
 geom_point() +
  geom_smooth(method="lm", alpha=.6, color = "black") +
  theme_classic() +
  labs(y="State Prediction Accuracy") + labs(x="IQ") #label x axis and y-axis
plot(wasi_acc_plot)
```


```{r accuracy age and IQ lm}
#age vs. age-squared models
acc_IQage.m <- lm(stateMeanAcc~IQ*z_age,data=meanAccParticipant)
acc_IQageSq.m <- lm(stateMeanAcc~IQ*(z_age + z_ageSq),data=meanAccParticipant)

anova(acc_IQage.m,acc_IQageSq.m)

pander(acc_IQage.m)
```


#Model-based Analyses
```{r initialize model-based analysis}
#how does the mean arbitration parameter from the full model change w/ age?
#not free parameter but mean estimate from across experiment
#arbitrator should be .75 for the task b/c .5 would be combo of SS and SAS and 1 would be SAS matrix
#those who closer to 1 are relying more on SAS
arbitration <- read.csv(file.path(baseDir, dataDir, "model_arbitration_values.csv"), header=FALSE)
names(arbitration)[1] <- "mb_arbitration"

phiFitted <- read.csv(file.path(baseDir, dataDir, "phiFitted.csv"), header=FALSE)
colnames(phiFitted)<- c("InvTemp","InvTemp_omega","Bias_omega")

thetaFitted <- read.csv(file.path(baseDir, dataDir, "thetaFitted.csv"), header=FALSE)
colnames(thetaFitted)<- c("alpha","alpha_omega")

phiFitted <- cbind(thetaFitted,phiFitted)
meanAccParticipant <- cbind(meanAccParticipant,phiFitted)

meanAccParticipant$mb_arbitration <- arbitration$mb_arbitration
```

```{r old model-based linear regressions, eval = FALSE}
#alpha
estimate_age.m <- lm(alpha~z_age,data=meanAccParticipant)
estimate_ageSq.m <- lm(alpha~(z_age + z_ageSq),data=meanAccParticipant)
anova(estimate_age.m,estimate_ageSq.m)
summary(estimate_age.m)

#alpha_omega
estimate_age.m <- lm(alpha_omega~z_age,data=meanAccParticipant)
estimate_ageSq.m <- lm(alpha_omega~(z_age + z_ageSq),data=meanAccParticipant)
anova(estimate_age.m,estimate_ageSq.m)
summary(estimate_age.m)

#Inverse Temperature
estimate_age.m <- lm(InvTemp~z_age,data=meanAccParticipant)
estimate_ageSq.m <- lm(InvTemp~(z_age + z_ageSq),data=meanAccParticipant)
anova(estimate_age.m,estimate_ageSq.m)
summary(estimate_age.m)

#Inverse Temperature omega
estimate_age.m <- lm(InvTemp_omega~z_age,data=meanAccParticipant)
estimate_ageSq.m <- lm(InvTemp_omega~(z_age + z_ageSq),data=meanAccParticipant)
anova(estimate_age.m,estimate_ageSq.m)
summary(estimate_age.m)

#Bias omega
estimate_age.m <- lm(Bias_omega~z_age,data=meanAccParticipant)
estimate_ageSq.m <- lm(Bias_omega~(z_age + z_ageSq),data=meanAccParticipant)
anova(estimate_age.m,estimate_ageSq.m)
summary(estimate_age.m)

#arbitration
acc_arbage.m <- lm(mb_arbitration~z_age,data=meanAccParticipant)
acc_arbageSq.m <- lm(mb_arbitration~(z_age + z_ageSq),data=meanAccParticipant)
anova(acc_arbage.m,acc_arbageSq.m)
summary(acc_arbage.m)
```

```{r mb_arbitration plot}
mb_arb_age_plot <-ggplot(data=meanAccParticipant, aes(x=Age, y=mb_arbitration)) +
  geom_point() +
  geom_smooth(method = "glm",formula = y ~ poly(x, 1), alpha=.6, color = "black") +
  theme_classic() +
  labs(y="MB Arbitration") + labs(x="Age") #label x axis and y-axis
plot(mb_arb_age_plot)
```

```{r modelbased arbitration and WM scores}
#age vs. age-squared models
mb_arb_WMage.m <- lm(mb_arbitration~z_wm_score*z_age,data=meanAccParticipant)
mb_arb_WMageSq.m <- lm(mb_arbitration~z_wm_score*(z_age + z_ageSq),data=meanAccParticipant)

anova(mb_arb_WMage.m,mb_arb_WMageSq.m)

summary(mb_arb_WMage.m)
```

## Task Set relation to Working Memory
```{r task set and working memory}
#load data from csv and add to main dataframe
TSvOMBIC <- read.csv(file.path(baseDir, dataDir, "TaskSetvsOmegaBIC.csv"), header=FALSE)
names(TSvOMBIC)[1] <- "TSvOM_BIC"
meanAccParticipant$TSvOM_BIC <- TSvOMBIC$TSvOM_BIC

#plot diff in model fit as a function of age-normed working memory score
wm_modelfit_plot <-ggplot(data=meanAccParticipant, aes(x=Age.Corrected.Standard.Score, y=TSvOM_BIC)) +
  geom_point() +
  geom_smooth(method = "glm",formula = y ~ poly(x, 1), alpha=.6, color = "black") +
  theme_classic() +
  labs(y="Task Set-Omega BIC") + labs(x="Working Memory") #label x axis and y-axis
plot(wm_modelfit_plot)

#effects of working memory on model fit across age
modelFit_WMage.m <- lm(TSvOM_BIC~z_wm_score*z_age,data=meanAccParticipant)
modelFit_WMageSq.m <- lm(TSvOM_BIC~z_wm_score*(z_age + z_ageSq),data=meanAccParticipant)

anova(modelFit_WMage.m,modelFit_WMageSq.m)

summary(modelFit_WMage.m)
```


```{r mediation age wm delta BIC}
library("mediation")
set.seed(2021)
test  <- meanAccParticipant[1:90,]

#Is there a main effect of age on delta BIC TS-LTS?
total.fit <- lm(TSvOM_BIC ~ Age, data = test)

#Is there a relationship between age and working memory? YES
med.fit <- lm(RawScore ~ Age, data = test)

#Is there a relationship between working memory and delta BIC (TS-LTS), while controlling for age? NO
out.fit <- lm(TSvOM_BIC ~ RawScore + Age, data = test)

#Does working memory mediate that relationship? NO
#mediation model for non-parametric bootstrap with 1000 simulations
med.out <- mediate(med.fit, out.fit, treat = "Age", mediator = "RawScore",
                   boot = TRUE)
summary(med.out)
plot(med.out)
```

```{r WM mediation b/n age and state and pilot accuracy}
#include only the 84 participants with WM scores
meanAccParticipant_n84 <- test[!(is.na(test$RawScore)),]

meanAccParticipant_n84$z_Age_n84 <- as.vector(scale(meanAccParticipant_n84$Age,center=TRUE,scale=TRUE))
meanAccParticipant_n84$z_RawScore_n84 <- as.vector(scale(meanAccParticipant_n84$RawScore,center=TRUE,scale=TRUE))
meanAccParticipant_n84$z_stateMeanAcc_n84 <- as.vector(scale(meanAccParticipant_n84$stateMeanAcc,center=TRUE,scale=TRUE))
meanAccParticipant_n84$z_pilotMeanAcc_n84 <- as.vector(scale(meanAccParticipant_n84$pilotMeanAcc,center=TRUE,scale=TRUE))


#Is there a main effect of age on state prediction accuracy?
total.fit <- lm(z_stateMeanAcc_n84 ~ z_Age_n84, data = meanAccParticipant_n84)
summary(total.fit)
#Is there a relationship between age and working memory?
med.fit <- lm(z_RawScore_n84 ~ z_Age_n84, data = meanAccParticipant_n84)
summary(med.fit)
#Is there a relationship between working memory and state prediction accuracy, while controlling for age?
out.fit <- lm(z_stateMeanAcc_n84 ~ z_RawScore_n84 + z_Age_n84, data = meanAccParticipant_n84)
summary(out.fit)
#Does working memory mediate that relationship? Yes
#mediation model for non-parametric bootstrap with 10000 simulations
med.out <- mediate(med.fit, out.fit, treat = "z_Age_n84", mediator = "z_RawScore_n84",
                   boot = TRUE, sims = 10000)
summary(med.out)
plot(med.out)


#Is there a main effect of age on pilot prediction accuracy?
total.fit <- lm(z_pilotMeanAcc_n84 ~ z_Age_n84, data = meanAccParticipant_n84)
summary(total.fit)
#Is there a relationship between age and working memory?
med.fit <- lm(z_RawScore_n84 ~ z_Age_n84, data = meanAccParticipant_n84)
summary(med.fit)
#Is there a relationship between working memory and pilot prediction accuracy, while controlling for age?
out.fit <- lm(z_pilotMeanAcc_n84 ~ z_RawScore_n84 + z_Age_n84, data = meanAccParticipant_n84)
summary(out.fit)
#Does working memory mediate that relationship? Yes
#mediation model for non-parametric bootstrap with 10000 simulations
med.out <- mediate(med.fit, out.fit, treat = "z_Age_n84", mediator = "z_RawScore_n84",
                   boot = TRUE, sims = 10000)
summary(med.out)
```


```{r mediation MR on deltaBIC}
test <- merge(test,WASI[c('SubjID','Raw_MR')],by="SubjID", all = TRUE)

#Is there a main effect of age on delta BIC TS-LTS?
total.fit <- lm(TSvOM_BIC ~ Age, data = test)

#Is there a relationship between age and matrix reasoning? YES
med.fit <- lm(Raw_MR ~ Age, data = test)

#Is there a relationship between matrix reasoning and delta BIC (TS-LTS), while controlling for age? yes
out.fit <- lm(TSvOM_BIC ~ Raw_MR + Age, data = test)

#Does matrix reasoning mediate that relationship? YES
#mediation model for non-parametric bootstrap with 1000 simulations
med.out <- mediate(med.fit, out.fit, treat = "Age", mediator = "Raw_MR",
                   boot = TRUE)
summary(med.out)
plot(med.out)
```



# Variables from Computational Modeling
```{r load data from romain}
#load data from csv to create figures
df <- read.csv(file.path(baseDir, "DATA/Measures_SASSS_Dev.csv"), header=TRUE, skip = 1)
df$SubjID <- df$id
df$SubjID <- factor(df$SubjID)

meanAccParticipant <- merge(meanAccParticipant, df[,c("SubjID","AlphaOM","InvTemp","SlopeOM","BiasOM","Mean.Arb","Mean.Omega","BIC_SS","BIC_SAS","BIC_MB","BIC_TS")], by=c("SubjID"), all=TRUE)
```

```{r mediation}
#test <- merge(test, df[,c("SubjID","BIC_SS","BIC_SAS","BIC_MB","BIC_TS")], by=c("SubjID"), all.x=TRUE)
#meanAccParticipant_n84$TSvSAS_BIC <- meanAccParticipant_n84$BIC_TS - meanAccParticipant_n84$BIC_SAS
meanAccParticipant_n84$TSvSS_BIC <- meanAccParticipant_n84$BIC_TS - meanAccParticipant_n84$BIC_SS
meanAccParticipant_n84$SASvSS_BIC <- meanAccParticipant_n84$BIC_SAS - meanAccParticipant_n84$BIC_SS
meanAccParticipant_n84$LTSvSS_BIC <- meanAccParticipant_n84$BIC_MB - meanAccParticipant_n84$BIC_SS

meanAccParticipant_n84$z_TSvSS_BIC <- as.vector(scale(meanAccParticipant_n84$TSvSS_BIC,center=TRUE,scale=TRUE))
meanAccParticipant_n84$z_SASvSS_BIC <- as.vector(scale(meanAccParticipant_n84$SASvSS_BIC,center=TRUE,scale=TRUE))
meanAccParticipant_n84$z_LTSvSS_BIC <- as.vector(scale(meanAccParticipant_n84$LTSvSS_BIC,center=TRUE,scale=TRUE))
```

```{r mediation wm delta BIC SAS, eval = FALSE}
#Is there a main effect of age on delta BIC TS-SAS?
total.fit <- lm(TSvSAS_BIC ~ Age, data = test)
summary(total.fit)
#Is there a relationship between age and working memory? YES
med.fit <- lm(RawScore ~ Age, data = test)
summary(med.fit)
#Is there a relationship between working memory and delta BIC (TS-SAS), while controlling for age? NO
out.fit <- lm(TSvSAS_BIC ~ RawScore + Age, data = test)
summary(out.fit)
#Does working memory mediate that relationship? NO
#mediation model for non-parametric bootstrap with 1000 simulations
med.out <- mediate(med.fit, out.fit, treat = "Age", mediator = "RawScore",
                   boot = TRUE)
summary(med.out)
plot(med.out)
```

```{r mediation wm delta BIC SS}
#Is there a main effect of age on delta BIC TS-SS?
total.fit <- lm(z_TSvSS_BIC ~ z_Age_n84, data = meanAccParticipant_n84)
summary(total.fit)
#Is there a relationship between age and working memory? YES
med.fit <- lm(z_RawScore_n84 ~ z_Age_n84, data = meanAccParticipant_n84)
summary(med.fit)
#Is there a relationship between working memory and delta BIC (TS-SS), while controlling for age? NO BUT TRENDING
out.fit <- lm(z_TSvSS_BIC ~ z_RawScore_n84 + z_Age_n84, data = meanAccParticipant_n84)
summary(out.fit)
#Does working memory mediate that relationship? YES
#mediation model for non-parametric bootstrap with 10000 simulations
med.out <- mediate(med.fit, out.fit, treat = "z_Age_n84", mediator = "z_RawScore_n84",
                   boot = TRUE, sims = 10000)
summary(med.out)
```

```{r mediation wm LTS SAS vs SS}

#Is there a main effect of age on delta BIC TS-SS?
total.fit <- lm(z_SASvSS_BIC ~ z_Age_n84, data = meanAccParticipant_n84)
summary(total.fit)
#Is there a relationship between age and working memory? YES
med.fit <- lm(z_RawScore_n84 ~ z_Age_n84, data = meanAccParticipant_n84)
summary(med.fit)
#Is there a relationship between working memory and delta BIC (TS-SS), while controlling for age? NO BUT NEARLY (.0503)
out.fit <- lm(z_SASvSS_BIC ~ z_RawScore_n84 + z_Age_n84, data = meanAccParticipant_n84)
summary(out.fit)
#Does working memory mediate that relationship? YES
#mediation model for non-parametric bootstrap with 1000 simulations
med.out <- mediate(med.fit, out.fit, treat = "z_Age_n84", mediator = "z_RawScore_n84",
                   boot = TRUE, sims = 10000)
summary(med.out)

#Is there a main effect of age on delta BIC LTS-SS?
total.fit <- lm(z_LTSvSS_BIC ~ z_Age_n84, data = meanAccParticipant_n84)
summary(total.fit)
#Is there a relationship between age and working memory? YES
med.fit <- lm(z_RawScore_n84 ~ z_Age_n84, data = meanAccParticipant_n84)
summary(med.fit)
#Is there a relationship between working memory and delta BIC (TS-SS), while controlling for age? NO BUT NEARLY (.0503)
out.fit <- lm(z_LTSvSS_BIC ~ z_RawScore_n84 + z_Age_n84, data = meanAccParticipant_n84)
summary(out.fit)
#Does working memory mediate that relationship? YES
#mediation model for non-parametric bootstrap with 1000 simulations
med.out <- mediate(med.fit, out.fit, treat = "z_Age_n84", mediator = "z_RawScore_n84",
                   boot = TRUE, sims = 10000)
summary(med.out)

```



```{r mediation MR delta BIC SAS}
#Is there a main effect of age on delta BIC TS-SAS?
total.fit <- lm(TSvSAS_BIC ~ Age, data = test)
summary(total.fit)
#Is there a relationship between age and matrix reasoning? YES
med.fit <- lm(Raw_MR ~ Age, data = test)
summary(med.fit)
#Is there a relationship between matrix reasoning and delta BIC (TS-SAS), while controlling for age? YES
out.fit <- lm(TSvSAS_BIC ~ Raw_MR + Age, data = test)
summary(out.fit)
#Does matrix reasoning mediate that relationship? YES
#mediation model for non-parametric bootstrap with 1000 simulations
med.out <- mediate(med.fit, out.fit, treat = "Age", mediator = "Raw_MR",
                   boot = TRUE)
summary(med.out)
plot(med.out)
```

```{r mediation MR delta BIC SS}
#Is there a main effect of age on delta BIC TS-SS?
total.fit <- lm(TSvSS_BIC ~ Age, data = test)
summary(total.fit)
#Is there a relationship between age and matrix reasoning? YES
med.fit <- lm(Raw_MR ~ Age, data = test)
summary(med.fit)
#Is there a relationship between matrix reasoning and delta BIC (TS-SS), while controlling for age? YES
out.fit <- lm(TSvSS_BIC ~ Raw_MR + Age, data = test)
summary(out.fit)
#Does matrix reasoning mediate that relationship? YES
#mediation model for non-parametric bootstrap with 1000 simulations
med.out <- mediate(med.fit, out.fit, treat = "Age", mediator = "Raw_MR",
                   boot = TRUE)
summary(med.out)
plot(med.out)
```


```{r mediation analyses with new fits, eval=FALSE}
#load data from csv to create figures
df <- read.csv(file.path(baseDir, "DATA/Measures_SASSS_Dev_NewFits.csv"), header=TRUE)
df$SubjID <- df$id
df$SubjID <- factor(df$SubjID)

meanAccParticipant_n84 <- merge(meanAccParticipant_n84, df[,c("SubjID","Random","SS","SAS","MBOmega","TS")], by=c("SubjID"), all.x=TRUE)

meanAccParticipant_n84$nTSvSS_BIC <- meanAccParticipant_n84$TS - meanAccParticipant_n84$SS
meanAccParticipant_n84$nSASvSS_BIC <- meanAccParticipant_n84$SAS - meanAccParticipant_n84$SS
meanAccParticipant_n84$nLTSvSS_BIC <- meanAccParticipant_n84$MBOmega - meanAccParticipant_n84$SS
meanAccParticipant_n84$nRandvSS_BIC <- meanAccParticipant_n84$SS - meanAccParticipant_n84$Random

meanAccParticipant_n84$z_nTSvSS_BIC <- as.vector(scale(meanAccParticipant_n84$nTSvSS_BIC,center=TRUE,scale=TRUE))
meanAccParticipant_n84$z_nSASvSS_BIC <- as.vector(scale(meanAccParticipant_n84$nSASvSS_BIC,center=TRUE,scale=TRUE))
meanAccParticipant_n84$z_nLTSvSS_BIC <- as.vector(scale(meanAccParticipant_n84$nLTSvSS_BIC,center=TRUE,scale=TRUE))
meanAccParticipant_n84$z_nRandvSS_BIC <-as.vector(scale(meanAccParticipant_n84$nRandvSS_BIC,center=TRUE,scale=TRUE)) 
```

```{r mediation w/ newer fits SS to all more complex models, eval = False}
#Is there a relationship between age and working memory? YES
med.fit <- lm(z_RawScore_n84 ~ z_Age_n84, data = meanAccParticipant_n84)
summary(med.fit)

#TASK SET MEDIATION - Yes
#Is there a main effect of age on delta BIC TS-SS?
total.fit <- lm(z_nTSvSS_BIC ~ z_Age_n84, data = meanAccParticipant_n84)
summary(total.fit)

#Is there a relationship between working memory and delta BIC (TS-SS), while controlling for age? NO BUT NEARLY (.068)
out.fit <- lm(z_nTSvSS_BIC ~ z_RawScore_n84 + z_Age_n84, data = meanAccParticipant_n84)
summary(out.fit)
#Does working memory mediate that relationship? YES
#mediation model for non-parametric bootstrap with 10000 simulations
med.out <- mediate(med.fit, out.fit, treat = "z_Age_n84", mediator = "z_RawScore_n84",
                   boot = TRUE, sims = 10000)
summary(med.out)

#LEARNED TRANSITION STRUCTURE MEDIATION - Yes
#Is there a main effect of age on delta BIC LTS-SS? YES
total.fit <- lm(z_nLTSvSS_BIC ~ z_Age_n84, data = meanAccParticipant_n84)
summary(total.fit)

#Is there a relationship between working memory and delta BIC (LTS-SS), while controlling for age? NO (.08)
out.fit <- lm(z_nLTSvSS_BIC ~ z_RawScore_n84 + z_Age_n84, data = meanAccParticipant_n84)
summary(out.fit)
#Does working memory mediate that relationship? YES
#mediation model for non-parametric bootstrap with 1000 simulations
med.out <- mediate(med.fit, out.fit, treat = "z_Age_n84", mediator = "z_RawScore_n84",
                   boot = TRUE, sims = 10000)
summary(med.out)

#ACTOR MEDIATION - Yes, barely (.04)
#Is there a main effect of age on delta BIC TS-SS?
total.fit <- lm(z_nSASvSS_BIC ~ z_Age_n84, data = meanAccParticipant_n84)
summary(total.fit)

#Is there a relationship between working memory and delta BIC (TS-SS), while controlling for age? NO BUT NEARLY (.05)
out.fit <- lm(z_nSASvSS_BIC ~ z_RawScore_n84 + z_Age_n84, data = meanAccParticipant_n84)
summary(out.fit)
#Does working memory mediate that relationship? YES
#mediation model for non-parametric bootstrap with 10000 simulations
med.out <- mediate(med.fit, out.fit, treat = "z_Age_n84", mediator = "z_RawScore_n84",
                   boot = TRUE, sims = 10000)
summary(med.out)

#RANDOM MODEL MEDIATION
#Is there a main effect of age on delta BIC TS-SS?
total.fit <- lm(z_nRandvSS_BIC ~ z_Age_n84, data = meanAccParticipant_n84)
summary(total.fit)

#Is there a relationship between working memory and delta BIC (TS-SS), while controlling for age? NO
out.fit <- lm(z_nRandvSS_BIC ~ z_RawScore_n84 + z_Age_n84, data = meanAccParticipant_n84)
summary(out.fit)

#Does working memory mediate that relationship? NO, as predicted
#mediation model for non-parametric bootstrap with 10000 simulations
med.out <- mediate(med.fit, out.fit, treat = "z_Age_n84", mediator = "z_RawScore_n84",
                   boot = TRUE, sims = 10000)
summary(med.out) 
```

```{r optimal choice simulations state prediction}
df_sim <- read.csv(file.path(baseDir, "DATA/datacollection/Measures_SASSS_Dev_SimulPerf_OptiExp.csv"), header=TRUE)
#df_sim <- df_sim[-c(1001),]

df_sim <- df_sim[c("TS_opti1_acc","TS_opti0_acc","MBom_opti1_acc","MBom_opti0_acc","SAS_opti1_acc","SAS_opti0_acc","SS_opti1_acc","SS_opti0_acc")]

df_sim_long <- gather(df_sim, sim_type, acc, TS_opti1_acc:SS_opti0_acc, factor_key = TRUE)

df_sim_long <- df_sim_long %>% mutate(Model = case_when(
  sim_type == 'TS_opti1_acc' | sim_type == 'TS_opti0_acc' ~ "TS", 
  sim_type == 'MBom_opti1_acc' | sim_type == 'MBom_opti0_acc' ~ "LTS",
  sim_type == 'SAS_opti1_acc' | sim_type == 'SAS_opti0_acc' ~ "Actor",
  sim_type == 'SS_opti1_acc' | sim_type == 'SS_opti0_acc' ~ "Spectator"))

df_sim_long <- df_sim_long %>% mutate(OptChoice = case_when(
  sim_type == 'TS_opti1_acc' | sim_type == 'MBom_opti1_acc' | sim_type == 'SAS_opti1_acc' | sim_type == 'SS_opti1_acc' ~ "Optimal", 
  sim_type == 'TS_opti0_acc' | sim_type == 'MBom_opti0_acc' | sim_type == 'SAS_opti0_acc' | sim_type == 'SS_opti0_acc' ~ "Random"))

df_sim_long$sim_type <- NULL

sim_opt_choice_m <- df_sim_long %>% group_by(Model,OptChoice) %>% summarise_all(mean)
sim_opt_choice_sd <- df_sim_long %>% group_by(Model,OptChoice) %>% summarise_all(sd)
sim_opt_choice_se <- sim_opt_choice_sd$acc/(sqrt(dim(df_sim)[1]))

sim_opt_choice_m$se <- sim_opt_choice_se

#sim_opt_choice <- df_sim %>% group_by(sim_type) %>% summarise(N = n(), meanAcc = mean(SAS_opti1_acc, na.rm = TRUE), sdAcc = sd(SAS_opti1_acc, na.rm = TRUE), seAcc = sdAcc/(sqrt(N)))

#sim_opt_choice <- df_sim %>% summarise(across(),list(mean,sd))


#sim_opt_choice_m <- df_sim %>% summarise_all(mean)
#sim_opt_choice_sd <- df_sim %>% summarise_all(sd)
#sim_opt_choice_se_correct <- sim_opt_choice_sd/(sqrt(dim(df_sim)[1]))

sim_opt_choice_m$Model <- factor(sim_opt_choice_m$Model,levels= c("Spectator", "Actor", "LTS", "TS"))
```

```{r figure 4}
sim_opt_choice_fig <- ggplot(sim_opt_choice_m, aes(x = Model, y = acc, fill = OptChoice)) +
    geom_bar(stat= "identity", position=position_dodge(), color="black") +
    geom_errorbar(aes(ymin=acc-se, ymax=acc+se),width =.1,size=.75, position=position_dodge(.9)) +
    labs(x="Model",y="State Prediction Accuracy") +
    theme_classic() + #scale_fill_brewer(palette="PuBuGn") +
    guides(fill=guide_legend(title="Interventions")) +
    ylim(0,1) + #scale_fill_brewer(palette="Paired")
    #theme_classic(base_size = 20)
    scale_fill_manual(values=c('gray50', 'white'))
    #scale_fill_manual(values=c('slategray3', 'slategray'))
    plot(sim_opt_choice_fig)
#ggsave(filename="/Users/hillaryraab/Box Sync/HartleyLab_SHARED/1_STUDIES/MonCon_HillaryKaterina/Analyses/Hillary/figures/manuscript/Fig_4_simulations_gray.png", plot=sim_opt_choice_fig, dpi=300, height = 4, width = 5, units="in")
    
    
 sim_opt_choice_fig <- ggplot(sim_opt_choice_m, aes(x = Model, y = acc, fill = OptChoice)) +
    geom_violin(data=df_sim_long, stat= "ydensity") +
    geom_point(stat= "identity", position=position_dodge(width = .9), color="black") +
    #geom_errorbar(aes(ymin=acc-se, ymax=acc+se),width =.1,size=.75, position=position_dodge(.9)) +
    labs(x="Model",y="State Prediction Accuracy") +
    theme_classic() + #scale_fill_brewer(palette="PuBuGn") +
    guides(fill=guide_legend(title="Interventions")) +
    ylim(0,1)   
    plot(sim_opt_choice_fig)

```


```{r optimal choice simulations condition prediction}
df_sim_pilot <- read.csv(file.path(baseDir, "DATA/datacollection/Measures_SASSS_Dev_SimulPerf_OptiExp.csv"), header=TRUE)

#select trials
df_sim_pilot <- df_sim_pilot[c("TS_opti1_condacc","TS_opti0_condacc","MBom_opti1_condacc","MBom_opti0_condacc","SAS_opti1_condacc","SAS_opti0_condacc","SS_opti1_condacc","SS_opti0_condacc")]

#convert to long format
df_sim_pilot_long <- gather(df_sim_pilot, sim_type, acc, TS_opti1_condacc:SS_opti0_condacc, factor_key = TRUE)

df_sim_pilot_long <- df_sim_pilot_long %>% mutate(Model = case_when(
  sim_type == 'TS_opti1_condacc' | sim_type == 'TS_opti0_condacc' ~ "TS", 
  sim_type == 'MBom_opti1_condacc' | sim_type == 'MBom_opti0_condacc' ~ "LTS",
  sim_type == 'SAS_opti1_condacc' | sim_type == 'SAS_opti0_condacc' ~ "Actor",
  sim_type == 'SS_opti1_condacc' | sim_type == 'SS_opti0_condacc' ~ "Spectator"))

df_sim_pilot_long <- df_sim_pilot_long %>% mutate(OptChoice = case_when(
  sim_type == 'TS_opti1_condacc' | sim_type == 'MBom_opti1_condacc' | sim_type == 'SAS_opti1_condacc' | sim_type == 'SS_opti1_condacc' ~ "Optimal", 
  sim_type == 'TS_opti0_condacc' | sim_type == 'MBom_opti0_condacc' | sim_type == 'SAS_opti0_condacc' | sim_type == 'SS_opti0_condacc' ~ "Random"))


df_sim_pilot_long$sim_type <- NULL

sim_pilot_opt_choice_m <- df_sim_pilot_long %>% group_by(Model,OptChoice) %>% summarise_all(mean)
sim_pilot_opt_choice_sd <- df_sim_pilot_long %>% group_by(Model,OptChoice) %>% summarise_all(sd)
sim_pilot_opt_choice_se <- sim_pilot_opt_choice_sd$acc/(sqrt(dim(df_sim)[1]))

sim_pilot_opt_choice_m$se <- sim_pilot_opt_choice_se

sim_pilot_opt_choice_m$Model <- factor(sim_pilot_opt_choice_m$Model,levels= c("Spectator", "Actor", "LTS", "TS"))

sim_pilot_opt_choice_fig <- ggplot(sim_pilot_opt_choice_m, aes(x = Model, y = acc, fill = OptChoice)) +
    geom_bar(stat= "identity", position=position_dodge()) +
    geom_errorbar(aes(ymin=acc-se, ymax=acc+se),width =.1,size=.75, position=position_dodge(.9)) +
    labs(x="Model",y="Condition Prediction Accuracy") +
    theme_classic() + #scale_fill_brewer(palette="PuBuGn") +
    guides(fill=guide_legend(title="Optimal Interventions")) +
    ylim(0,1) + scale_fill_brewer(palette="Paired")
    #theme_classic(base_size = 20)
   #scale_fill_manual(values=c("#D2B1C0","#9B5977","#B0CEE2", "#1C5BA6"))
    plot(sim_pilot_opt_choice_fig)
```

```{r human behavior matches simulations}
#state predictions
par_opt_choice_m <- meanAccParticipant %>% group_by(AgeGroup_sorted,optimalChoice_group) %>% summarise(N = n(), acc = mean(stateMeanAcc), sdAcc = sd(stateMeanAcc, na.rm = TRUE), seAcc = sdAcc/(sqrt(N)))

par_opt_choice_fig <- ggplot(par_opt_choice_m, aes(x = AgeGroup_sorted, y = acc, fill = optimalChoice_group)) +
    geom_bar(stat= "identity", position=position_dodge()) +
    geom_errorbar(aes(ymin=acc-seAcc, ymax=acc+seAcc),width =.1,size=.75, position=position_dodge(.9)) +
    labs(x="Model",y="State Prediction Accuracy") +
    theme_classic() + #scale_fill_brewer(palette="PuBuGn") +
    guides(fill=guide_legend(title="Optimal Interventions")) +
    ylim(0,1) 
    #theme_classic(base_size = 20)
   #scale_fill_manual(values=c("#D2B1C0","#9B5977","#B0CEE2", "#1C5BA6"))
    plot(par_opt_choice_fig)
    
#Pilot predictions
par_pilot_opt_choice_m <- meanAccParticipant %>% group_by(AgeGroup_sorted,optimalChoice_group) %>% summarise(N = n(), acc = mean(pilotMeanAcc), sdAcc = sd(pilotMeanAcc, na.rm = TRUE), seAcc = sdAcc/(sqrt(N)))

par_pilot_opt_choice_fig <- ggplot(par_pilot_opt_choice_m, aes(x = AgeGroup_sorted, y = acc, fill = optimalChoice_group)) +
    geom_bar(stat= "identity", position=position_dodge()) +
    geom_errorbar(aes(ymin=acc-seAcc, ymax=acc+seAcc),width =.1,size=.75, position=position_dodge(.9)) +
    labs(x="Model",y="Condition Prediction Accuracy") +
    theme_classic() + #scale_fill_brewer(palette="PuBuGn") +
    guides(fill=guide_legend(title="Optimal Interventions")) +
    ylim(0,1) 
    #theme_classic(base_size = 20)
   #scale_fill_manual(values=c("#D2B1C0","#9B5977","#B0CEE2", "#1C5BA6"))
    plot(par_pilot_opt_choice_fig)    
```


```{r model-based linear regressions}
#alpha_omega
#cor.test(df$Mean.Omega,df$age)
#estimate_age.m <- lm(Mean.Arb~age,data=df)
#summary(estimate_age.m)



#alpha omega
estimate_alpha_age.m <- lm(AlphaOM~z_age,data=meanAccParticipant)
estimate_alpha_ageSq.m <- lm(AlphaOM~(z_age + z_ageSq),data=meanAccParticipant)
anova(estimate_alpha_age.m,estimate_alpha_ageSq.m)
summary(estimate_alpha_age.m)


#Inverse Temperature
estimate_InvTemp_age.m <- lm(InvTemp~z_age,data=meanAccParticipant)
estimate_InvTemp_ageSq.m <- lm(InvTemp~(z_age + z_ageSq),data=meanAccParticipant)
anova(estimate_InvTemp_age.m,estimate_InvTemp_ageSq.m)
summary(estimate_InvTemp_age.m)

#Slope of sigmoidal
estimate_slope_age.m <- lm(SlopeOM~z_age,data=meanAccParticipant)
estimate_slope_ageSq.m <- lm(SlopeOM~(z_age + z_ageSq),data=meanAccParticipant)
anova(estimate_slope_age.m,estimate_slope_ageSq.m)
summary(estimate_slope_age.m)

#Bias omega
estimate_bias_age.m <- lm(BiasOM~z_age,data=meanAccParticipant)
estimate_bias_ageSq.m <- lm(BiasOM~(z_age + z_ageSq),data=meanAccParticipant)
anova(estimate_bias_age.m,estimate_bias_ageSq.m)
summary(estimate_bias_age.m)

#arbitration
estimate_arb_age.m <- lm(Mean.Arb~z_age,data=meanAccParticipant)
estimate_arb_ageSq.m <- lm(Mean.Arb~(z_age + z_ageSq),data=meanAccParticipant)
anova(estimate_arb_age.m,estimate_arb_ageSq.m)
summary(estimate_arb_age.m)
```


```{r Cohen's f^2 local effect size for all model-derived estimates}
meanAccParticipant$z_AlphaOM<-scale(meanAccParticipant$AlphaOM,center=TRUE,scale=TRUE)
meanAccParticipant$z_InvTemp<-scale(meanAccParticipant$InvTemp,center=TRUE,scale=TRUE)
meanAccParticipant$z_SlopeOM<-scale(meanAccParticipant$SlopeOM,center=TRUE,scale=TRUE)
meanAccParticipant$z_BiasOM<-scale(meanAccParticipant$BiasOM,center=TRUE,scale=TRUE)
meanAccParticipant$z_Mean.Arb<-scale(meanAccParticipant$Mean.Arb,center=TRUE,scale=TRUE)
```

```{r alpha effect size}
#calculate f^2 for age using the formula R^2/(1-R^2)
standardized_alpha.m<-lm(z_AlphaOM~z_age,data=meanAccParticipant)
Rsq1 = summary(standardized_alpha.m) $r.squared
```
Cohen's f^2 local effect size for age on alpha: `r (Rsq1)/(1-Rsq1)` 

```{r InvTemp effect size}
#calculate f^2 for age using the formula R^2/(1-R^2)
remove(Rsq1)
standardized_InvTemp.m<-lm(z_InvTemp~z_age,data=meanAccParticipant)
Rsq1 = summary(standardized_InvTemp.m) $r.squared
```
Cohen's f^2 local effect size for age on Inverse Temperature: `r (Rsq1)/(1-Rsq1)` 

```{r slope effect size}
#calculate f^2 for age using the formula R^2/(1-R^2)
remove(Rsq1)
standardized_SlopeOM.m<-lm(z_SlopeOM~z_age,data=meanAccParticipant)
Rsq1 = summary(standardized_SlopeOM.m) $r.squared
```
Cohen's f^2 local effect size for age on Slope: `r (Rsq1)/(1-Rsq1)` 


```{r bias effect size}
#calculate f^2 for age using the formula R^2/(1-R^2)
remove(Rsq1)
standardized_BiasOM.m<-lm(z_BiasOM~z_age,data=meanAccParticipant)
Rsq1 = summary(standardized_BiasOM.m) $r.squared
```
Cohen's f^2 local effect size for age on Bias: `r (Rsq1)/(1-Rsq1)` 

```{r arbitrator effect size}
#calculate f^2 for age using the formula R^2/(1-R^2)
remove(Rsq1)
standardized_Arb.m<-lm(z_Mean.Arb~z_age,data=meanAccParticipant)
Rsq1 = summary(standardized_Arb.m) $r.squared
```
Cohen's f^2 local effect size for age on Arbitrator: `r (Rsq1)/(1-Rsq1)` 


```{r histogram best model}
#rename and reorder
levels(df$ModelAttribStr) <- c("SAS","SS","MB Omega","Task Set") #rename
df$ModelAttribStr <- factor(df$ModelAttribStr, levels=c('SS','SAS','MB Omega','Task Set')) #order
levels(df$ModelAttribStr) <- c("Spectator","Actor","LTS","TS")

best_model_fig <- ggplot(df, aes(x = factor(as.integer(age)),fill=ModelAttribStr)) +
    geom_bar() +
    labs(x="Age",y="Count") +
    #theme_classic() + #scale_fill_brewer(palette="PuBuGn") +
    guides(fill=guide_legend(title="Model")) +
    theme_classic(base_size = 10) + 
  scale_fill_manual(values=c("#D2B1C0","#9B5977","#B0CEE2", "#1C5BA6")) +
scale_x_discrete(labels=c("8" = "8", "9" = "", "10" = "10","11"="","12"="12","13"="","14"="14","15"="","16"="16","17"="",
                          "18"="18","19"="","20"="20","21"="","22"="22","23"="","24"="24","25"="")) #scale_fill_manual(values=c("thistle","thistle4","#B0CEE2", "#1C5BA6"))
  #scale_fill_manual(values=c("thistle","thistle4","lightsteelblue2", "lightsteelblue3"))
plot(best_model_fig)


#green + blue:scale_fill_manual(values=c("#C2DB95","#8CB63E","#B0CEE2", "#1C5BA6"))
# green + blue: scale_fill_manual(values=c("#5BC658","#32892F","#18A7B4", "#106F77"))


#ggsave(filename="/Users/hillaryraab/Box Sync/HartleyLab_SHARED/1_STUDIES/MonCon_HillaryKaterina/Analyses/Hillary/figures/manuscript/best_model_fig.png", plot=best_model_fig, dpi=300)


alpha_plot <- ggplot(meanAccParticipant, aes(x = Age,y=AlphaOM)) +
    geom_point(size=.5) + 
    geom_smooth(method="lm",color = "black",alpha=.4) +
    labs(x="Age",y="Estimates (a.u.)") + 
    #ggtitle(expression("Alpha "*Omega))
    theme_classic(base_size = 14) + theme(plot.title = element_text(hjust = 0.5)) +
    ggtitle(expression("Alpha"[Omega]))

#    dev.new(width = 2, height = 3, unit = "in")
plot(alpha_plot)

Slope_plot <- ggplot(meanAccParticipant, aes(x = Age,y=SlopeOM)) +
    geom_point(size=.5) +
    geom_smooth(method="lm",color = "black",alpha=.4) +
    labs(x="Age",y="Estimates (a.u.)") +
    theme_classic(base_size = 14) + theme(plot.title = element_text(hjust = 0.5),axis.title.y=element_blank()) +
    ggtitle("Slope") 
#    dev.new(width = 2, height = 3, unit = "in")

Bias_plot <- ggplot(meanAccParticipant, aes(x = Age,y=BiasOM)) +
    geom_point(size=.5) +
    geom_smooth(method="lm",color = "black",alpha=.4) +
    labs(x="Age",y="Estimates (a.u.)") +
    theme_classic(base_size = 14) + theme(plot.title = element_text(hjust = 0.5),axis.title.y=element_blank()) +
    ggtitle("Bias")

Consistency_plot <- ggplot(meanAccParticipant, aes(x = Age,y=InvTemp)) +
    geom_point(size=.5) +
    geom_smooth(method="lm",color = "black",alpha=.4) +
    labs(x="Age",y="Estimates (a.u.)") +
    theme_classic(base_size = 14) + theme(plot.title = element_text(hjust = 0.5),axis.title.y=element_blank()) +
    ggtitle("Inverse Temperature")

ggplot(meanAccParticipant, aes(x = Age,y=Mean.Omega)) +
    geom_point(size=.5) +
    geom_smooth(method="lm",color = "black",alpha=.4) +
    labs(x="Age",y="Values (a.u.)") +
    theme_classic(base_size = 14) + theme(plot.title = element_text(hjust = 0.5),axis.title.y=element_blank())

Arbitrator_plot <- ggplot(meanAccParticipant, aes(x = Age,y=Mean.Arb)) +
    geom_point(size=.5) +
    geom_smooth(method="lm",color = "black",alpha=.4) +
    labs(x="Age",y="Values (a.u.)") +
    ggtitle("Mean Arbitrator") +
    theme_classic(base_size = 14) + theme(plot.title = element_text(hjust = 0.5),axis.title.y=element_blank())

require(gridExtra)
library(cowplot)
#model_parms <- grid.arrange(alpha_plot, Slope_plot, Bias_plot, Consistency_plot, Arbitrator_plot, ncol=5)
#plot(model_parms)
#model_plots <- plot_grid(alpha_plot, Slope_plot, Bias_plot, Consistency_plot, Arbitrator_plot, ncol=5, align = "v")
#plot(model_plots)
SFig3 <- plot_grid(Arbitrator_plot, alpha_plot, Slope_plot, Bias_plot, Consistency_plot, labels = c('a', 'b','c','d','e'), align="v",nrow=1)
plot(SFig3)

##SUPPLEMENTARY FIGURE 3
#ggsave(filename="/Users/hillaryraab/Box Sync/HartleyLab_SHARED/1_STUDIES/MonCon_HillaryKaterina/Analyses/Hillary/figures/manuscript/model_parms.png", plot=SFig3, dpi=300, height = 3, width = 14, units="in")


TS_MB_plot <- ggplot(df, aes(x = age,y=((-2*BIC_MB)-(-2*BIC_TS)))) +
    geom_point() +
    geom_smooth(method="lm",color = "black",alpha=.4) +
    labs(x="Age",y=expression(BIC[LTS] - BIC[TS]))
plot(TS_MB_plot)

#ggsave(filename="/Users/hillaryraab/Box Sync/HartleyLab_SHARED/1_STUDIES/MonCon_HillaryKaterina/Analyses/Hillary/figures/manuscript/Fig_TS_MB_Plot.png", plot=TS_MB_plot, dpi=300, height = 4, width = 5, units="in")


SS_SAS_plot <- ggplot(df, aes(x = age,y=((-2*BIC_SS)-(-2*BIC_SAS)))) +
    geom_point() +
    geom_smooth(method="lm",color = "black",alpha=.4) +
    labs(x="Age",y=expression(BIC[Spectator] - BIC[Actor]))
plot(SS_SAS_plot)

BIC_diff_plot <- plot_grid(SS_SAS_plot,TS_MB_plot, align="h", axis = "bt",labels = c('a','b'))
#Supplmentary Fig. 1
#ggsave(filename="/Users/hillaryraab/Box Sync/HartleyLab_SHARED/1_STUDIES/MonCon_HillaryKaterina/Analyses/Hillary/figures/manuscript/BIC_diff_plot.png", plot=BIC_diff_plot, dpi=300, height = 4, width = 9, units="in")

```

```{r relationship between optimal choice and model selection}
meanAccParticipant <- merge(meanAccParticipant, df[, c("SubjID","ModelAttribStr")], by ="SubjID", all.x=TRUE)
optChoice_by_Model <- meanAccParticipant %>% group_by(ModelAttribStr) %>% summarise(N = n(), meanOpt = mean(optimalChoice, na.rm = TRUE), sdOpt = sd(optimalChoice, na.rm = TRUE), seOpt = sdOpt/(sqrt(N)),mean_wm = mean(Age.Corrected.Standard.Score, na.rm = TRUE), sd_wm = sd(Age.Corrected.Standard.Score, na.rm = TRUE), se_wm = sd_wm/(sqrt(N)))


model_explo_plot <- ggplot(optChoice_by_Model, aes(x = ModelAttribStr,y=meanOpt,color=ModelAttribStr)) +
    geom_errorbar(aes(ymin=meanOpt-seOpt, ymax=meanOpt+seOpt),width =.1,size=.75) +
    geom_quasirandom(width = .2, aes(x=ModelAttribStr,y=optimalChoice),alpha =.8, data = meanAccParticipant) +
    geom_point(aes(), stat="identity", size=2.5) +
    scale_color_manual(values=c("#D2B1C0","#9B5977","#B0CEE2", "#1C5BA6")) +
    theme_classic(base_size = 16) + theme(legend.position = "none",axis.title.x = element_blank()) +
    labs(y="Optimal Exploratory Choice")
plot(model_explo_plot)

#ggsave(filename="/Users/hillaryraab/Box Sync/HartleyLab_SHARED/1_STUDIES/MonCon_HillaryKaterina/Analyses/Hillary/figures/manuscript/Fig_Model_ExploChoice_Plot.png", plot=model_explo_plot, dpi=300, height = 5, width = 9, units="in")
```

```{r relationship between working memory and model selection}
optChoice_by_Model <- meanAccParticipant %>% group_by(ModelAttribStr) %>% summarise(N = n(), mean_wm = mean(Age.Corrected.Standard.Score, na.rm = TRUE), sd_wm = sd(Age.Corrected.Standard.Score, na.rm = TRUE), se_wm = sd_wm/(sqrt(N)))


model_wm_plot <- ggplot(optChoice_by_Model, aes(x = ModelAttribStr,y=mean_wm,color=ModelAttribStr)) +
    geom_errorbar(aes(ymin=mean_wm-se_wm, ymax=mean_wm+se_wm),width =.1,size=.75) +
    geom_quasirandom(width = .2, aes(x=ModelAttribStr,y=Age.Corrected.Standard.Score),alpha =.8, data = meanAccParticipant) +
    geom_point(aes(), stat="identity", size=2.5) +
    scale_color_manual(values=c("#D2B1C0","#9B5977","#B0CEE2", "#1C5BA6")) +
    theme_classic(base_size = 16) + theme(legend.position = "none",axis.title.x = element_blank()) +
    labs(y="Working Memory")
plot(model_wm_plot)
```

```{r best model & bias parameter}
model_bias_plot <- ggplot(df, aes(x = ModelAttribStr,y=BiasOM,color=ModelAttribStr)) +
    geom_quasirandom(width = .2, alpha =.8) +
    scale_color_manual(values=c("#D2B1C0","#9B5977","#B0CEE2", "#1C5BA6")) +
    theme_classic(base_size = 16) + theme(legend.position = "none",axis.title.x = element_blank()) +
    labs(y="Bias Omega")
plot(model_bias_plot)
```


```{r load example subject to plot arbitrator across task}
#load data from csv to create figures, moncon subj1
ex <- read.csv(file.path(baseDir, "Analyses/CompModeling/RomainFit/o_TStype1_2rules_bOM0_bDEC1_e_TStype1_2rules_aOM1_eOM1_biasOM1_29-Apr-2020_5/exampleSubj1.csv"), header=FALSE)

colnames(ex)<- c("Arb","Condition")

ex$trial <- (1:480)

#conditions represented below, shaded is controllable
d=data.frame(x1=c(40, 112, 200, 280, 344, 432), x2=c(64, 168, 240, 320, 376,480))

arb_plot <- ggplot() +
  geom_rect(data=d,aes(xmin=x1,xmax=x2,ymin=-Inf,ymax=Inf),fill="grey90") +
  geom_line(data=ex,aes(x=trial,y=Arb),color ="#2171B5") +
  labs(x="Trial",y="Arbitrator") +
  theme_classic(base_size = 10) + theme(plot.title = element_text(hjust = 0.5)) + coord_cartesian(ylim = c(0, 1))
plot(arb_plot)

#load data from csv to create figures, moncon subj119
ex_2 <- read.csv(file.path(baseDir, "Analyses/CompModeling/RomainFit/o_TStype1_2rules_bOM0_bDEC1_e_TStype1_2rules_aOM1_eOM1_biasOM1_29-Apr-2020_5/exampleSubj119.csv"), header=FALSE)

colnames(ex_2)<- c("Arb","Condition")

ex_2$trial <- (1:480)

#conditions represented below, shaded is controllable
d2=data.frame(x1=c(0, 88, 152, 224, 312, 392), x2=c(56, 112, 200, 256, 352,432))


arb_plot2 <- ggplot() +
  geom_rect(data=d2,aes(xmin=x1,xmax=x2,ymin=-Inf,ymax=Inf),fill="grey90") +
  geom_line(data=ex_2,aes(x=trial,y=Arb),color ="#2171B5") +
  labs(x="Trial",y="Arbitrator") +
  theme_classic(base_size = 10) + theme(plot.title = element_text(hjust = 0.5)) + coord_cartesian(ylim = c(0, 1))
plot(arb_plot2)

#top_row <- plot_grid(ex_plot,best_model_fig,align="h", axis = "bt",labels = c('a','b'), rel_widths = c(1, 1.5))
#plot_grid(top_row,model_plots, nrow= 2)




model_schematic <- cowplot::ggdraw() + cowplot::draw_image("/Users/hillaryraab/Box Sync/Hartley Lab/MonCon/MonCon_manuscript/fig2_model_schematic.png", scale =.9)
mediation_schematic <- cowplot::ggdraw() + cowplot::draw_image("/Users/hillaryraab/Box Sync/Hartley Lab/MonCon/MonCon_manuscript/mediation_fig.png")
row_1 <- plot_grid(model_schematic,best_model_fig,labels = c('a','b'), rel_widths = c(1,1))
row_2 <- plot_grid(arb_plot,arb_plot2,align="h", axis = "bt", labels = c('c','d'))
row_3 <- plot_grid(mediation_schematic, labels = c('e'))
fig3 <- plot_grid(row_1,row_2,row_3,nrow=3, rel_heights = c(.75,.5,1))
plot(fig3)

#row_2 <- plot_grid(arb_plot,arb_plot2,Arbitrator_plot,align="h", axis = "bt",ncol=3, labels = c('c','d','e'), rel_widths = c(1,1,1))
#row_3 <- plot_grid(alpha_plot, Slope_plot, Bias_plot, Consistency_plot, ncol=4, labels = c('f','g','h','i'))
#fig3 <- plot_grid(row_1,row_2,row_3,nrow=3)
#plot(fig3)


#ggsave(filename="/Users/hillaryraab/Box Sync/HartleyLab_SHARED/1_STUDIES/MonCon_HillaryKaterina/Analyses/Hillary/figures/manuscript/Raab_etal_Fig3_mediation.png", plot=fig3, dpi=300)
```

#Mixed Effects Models
```{r set up data frame for generalized linear mixed effects model}
trialwiseDataset <- as.data.frame(dataAllSubjs[c("SubjID","globalPredictivePairNum","Condition", "resp_acc", "Gender","Age","AgeGroup","z_age","z_ageSq","z_globalPredictiveTrialNum")])

difficulty <- ifelse((dataAllSubjs$Run == 1) | (dataAllSubjs$Run == 3), 'easy', 
                     ifelse((dataAllSubjs$Run == 2) | (dataAllSubjs$Run == 4), 'hard', NA))

trialwiseDataset <- data.frame(trialwiseDataset,difficulty)

# adding optimal choice correctly for each participant
test <- as.data.frame(colMeans(matrix(exploreAllSubjs$optimalChoice, nrow=6)))
test2 <- test[rep(seq_len(nrow(test)), each = 2), ]
trialwiseDataset$propOptimalChoice_updated <- test2
trialwiseDataset$z_propOptimalChoice_updated <-scale(trialwiseDataset$propOptimalChoice_updated,center=TRUE,scale=TRUE) # continuous variable, mean centered and scaled


#proportion optimal choice
trialwiseDataset$propOptimalChoice <- colMeans(matrix(exploreAllSubjs$optimalChoice, nrow=6))
trialwiseDataset$z_propOptimalChoice<-scale(trialwiseDataset$propOptimalChoice,center=TRUE,scale=TRUE) # continuous variable, mean centered and scaled

#add wm score
trialwiseDataset  <- merge(trialwiseDataset,meanAccs[ which(meanAccs$Condition=='Controllable'), c("SubjID","z_wm_score")],by=c("SubjID"))

#rename condition as controllable and uncontrollable
levels(trialwiseDataset$Condition) <- c("Uncontrollable","Controllable") #rename
```

```{r 10.28.20 Final Model for Paper with updated optimal choice}

#remove three-way interaction b/c accounts for least amount of variance
model_age_take4a_wm_updated <- mixed(resp_acc~Condition*z_age*z_globalPredictiveTrialNum*(z_propOptimalChoice_updated+z_wm_score)+(1+(z_propOptimalChoice_updated+z_globalPredictiveTrialNum+Condition)^2||SubjID),data=trialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT", expand_re = TRUE)
```

```{r transition probabilities & performance}
#Does performance decrease when transition structure becomes more probabilistic? 
model_difficulty <- mixed(resp_acc~z_age*difficulty+(1+difficulty|SubjID),data=trialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT")
```


```{r resubmission glmer all intxns}
#response to criticism - allow all intxns
#singular fit
model_age_take4a_wm_updated_allintxn <- mixed(resp_acc~Condition*z_age*z_globalPredictiveTrialNum*z_propOptimalChoice_updated*z_wm_score+(1+(z_propOptimalChoice_updated+z_globalPredictiveTrialNum+Condition)^2||SubjID),data=trialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT", expand_re = TRUE)


#try a model with RE structure so 2-way intxns b/n all but optimal choice and trial
#sig: condition, age, trial, optimal choice, condition*optimal choice, age*optimal choice, condition*trial*optimal choice* wm
#trending: wm, trial*optimal choice*w
model_age_take4a_wm_updated_allintxn2 <- mixed(resp_acc~Condition*z_age*z_globalPredictiveTrialNum*z_propOptimalChoice_updated*z_wm_score+(1+Condition *(z_globalPredictiveTrialNum+z_propOptimalChoice_updated)||SubjID),data=trialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT", expand_re = TRUE)
```


```{r plots for age & condition influencing the rlnsp b/n opt choice and state predictions}
acc_ageOptChoice <- ggplot(meanAccParticipant, aes(x = optimalChoice, y=stateMeanAcc)) +
  geom_point() +
  geom_smooth(method="lm", color = 'black') +
  facet_wrap(~AgeGroup_sorted) +
  geom_hline(yintercept=.33, linetype="dashed", color = "black") + #line at chance
  theme_classic() +
  scale_color_manual(values = c("steelblue4", "steelblue2", "steelblue3"))
plot(acc_ageOptChoice)

acc_conditionOptChoice <- ggplot(meanAccs, aes(x = optimalChoiceByCondition, y=meanAcc)) +
  geom_point() +
  geom_smooth(method="lm", color = 'black') +
  facet_wrap(~Condition) +
  geom_hline(yintercept=.33, linetype="dashed", color = "black") + #line at chance
  theme_classic() 
plot(acc_conditionOptChoice)

pilotacc_ageOptChoice <- ggplot(meanAccParticipant, aes(x = optimalChoice, y=pilotMeanAcc)) +
  geom_point() +
  geom_smooth(method="lm", color = 'black') +
  facet_wrap(~AgeGroup_sorted) +
  geom_hline(yintercept=.33, linetype="dashed", color = "black") + #line at chance
  theme_classic() +
  scale_color_manual(values = c("steelblue4", "steelblue2", "steelblue3")) + 
  labs(x="Optimal Choice",y="Condition prediction accuracy") 
plot(pilotacc_ageOptChoice)
```



```{r glmer 10.26.20 Final Model for Paper}

#still need to run but assuming it doesn't converge
model_age <- mixed(resp_acc~Condition*z_age*z_globalPredictiveTrialNum*(z_propOptimalChoice+z_wm_score)+(1+Condition*z_globalPredictiveTrialNum*z_propOptimalChoice|SubjID),data=trialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT")


#remove correlation first, hence the || 
#age, trial, condition sig.
#converged but below model w/ less complex model didn't converge
model_age_take2_max <- mixed(resp_acc~Condition*z_age*z_globalPredictiveTrialNum*(z_propOptimalChoice+z_wm_score)+(1+Condition*z_globalPredictiveTrialNum*z_propOptimalChoice||SubjID),data=trialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT", expand_re = TRUE)


#SAME MODEL AS ABOVE WITHOUT WM
#get singular fit for one of the periods when fitting
#did not converge
model2_age_take2 <- mixed(resp_acc~Condition*z_age*z_globalPredictiveTrialNum*z_propOptimalChoice+(1+Condition*z_globalPredictiveTrialNum*z_propOptimalChoice||SubjID),data=trialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT", expand_re = TRUE)


#remove three-way interaction b/c accounts for least amount of variance
model_age_take4a_wm <- mixed(resp_acc~Condition*z_age*z_globalPredictiveTrialNum*(z_propOptimalChoice+z_wm_score)+(1+(z_propOptimalChoice+z_globalPredictiveTrialNum+Condition)^2||SubjID),data=trialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT", expand_re = TRUE)

model_ageSq_take4a_wm <- mixed(resp_acc~Condition*(z_age+z_ageSq)*z_globalPredictiveTrialNum*(z_propOptimalChoice+z_wm_score)+(1+(z_propOptimalChoice+z_globalPredictiveTrialNum+Condition)^2||SubjID),data=trialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT", expand_re = TRUE)

anova(model_age_take4a_wm,model_ageSq_take4a_wm)
nice(model_age_take4a_wm)
summary(model_age_take4a_wm)

#w/out working memory
model_age_take4a <- mixed(resp_acc~Condition*z_age*z_globalPredictiveTrialNum*z_propOptimalChoice+(1+(z_propOptimalChoice+z_globalPredictiveTrialNum+Condition)^2||SubjID),data=trialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT", expand_re = TRUE)

model_ageSq_take4a <- mixed(resp_acc~Condition*(z_age +z_ageSq)*z_globalPredictiveTrialNum*z_propOptimalChoice+(1+(z_propOptimalChoice+z_globalPredictiveTrialNum+Condition)^2||SubjID),data=trialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT", expand_re = TRUE)

anova(model_age_take4a,model_ageSq_take4a)
nice(model_age_take4a)
summary(model_age_take4a)
```



```{r set up data frame for generalized linear mixed effects model on CONDITION PREDICTIONS}
pilotTrialwiseDataset <- as.data.frame(pilotPredictionAllSubjs[c("SubjID","globalPredictiveTrialNum","Condition", "resp_acc", "Gender","Age","AgeGroup","z_age","z_ageSq","z_globalPredictiveTrialNum")])

#proportion optimal choice
pilotTrialwiseDataset$propOptimalChoice <- colMeans(matrix(exploreAllSubjs$optimalChoice, nrow=6))
pilotTrialwiseDataset$z_propOptimalChoice<-scale(pilotTrialwiseDataset$propOptimalChoice,center=TRUE,scale=TRUE) # continuous variable, mean centered and scaled

difficulty <- ifelse((pilotPredictionAllSubjs$Run == 1) | (pilotPredictionAllSubjs$Run == 3), 'easy', 
                     ifelse((pilotPredictionAllSubjs$Run == 2) | (pilotPredictionAllSubjs$Run == 4), 'hard', NA))

pilotTrialwiseDataset <- data.frame(pilotTrialwiseDataset,difficulty)


#add wm score
pilotTrialwiseDataset  <- merge(pilotTrialwiseDataset,meanAccs[ which(meanAccs$Condition=='Controllable'), c("SubjID","z_wm_score")],by=c("SubjID"))
```


```{r glmer predicting condition accuracy}
#This model did not converge.
pilot_model_age <- mixed(resp_acc~Condition*z_age*z_globalPredictiveTrialNum*(z_propOptimalChoice+z_wm_score)+(1+Condition*z_globalPredictiveTrialNum*z_propOptimalChoice|SubjID),data=pilotTrialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT")

#Next, I'll try a model removing the correlation between random intercepts and slope.
#did not converge
pilot_model_age_take2 <- mixed(resp_acc~Condition*z_age*z_globalPredictiveTrialNum*(z_propOptimalChoice+z_wm_score)+(1+Condition*z_globalPredictiveTrialNum*z_propOptimalChoice||SubjID),data=pilotTrialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT", expand_re = TRUE)


#remove correlation first, hence the ||, then remove interaction b/n trial & optimal choice
#need to re-run w/ pilot dataframe
#age model
pilot_model_age_take3 <- mixed(resp_acc~Condition*z_age*z_globalPredictiveTrialNum*(z_propOptimalChoice+z_wm_score)+(1+(z_globalPredictiveTrialNum+z_propOptimalChoice)*Condition||SubjID),data=pilotTrialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT", expand_re = TRUE)

#age-squared model
#need to re-run w/ pilot dataframe
pilot_model_ageSq_take3 <- mixed(resp_acc~Condition*(z_age+z_ageSq)*z_globalPredictiveTrialNum*(z_propOptimalChoice+z_wm_score)+(1+(z_globalPredictiveTrialNum+z_propOptimalChoice)*Condition||SubjID),data=pilotTrialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT", expand_re = TRUE)

anova(pilot_model_age_take3,pilot_model_ageSq_take3)
tab_model(pilot_model_age_take3,show.se = TRUE, show.stat = TRUE)

#SAME MODEL AS ABOVE WITHOUT WORKING MEMORY
#age model
#need to re-run w/ pilot dataframe
pilot_model_nowm_take4 <- mixed(resp_acc~Condition*z_age*z_globalPredictiveTrialNum*z_propOptimalChoice+(1+(z_globalPredictiveTrialNum+z_propOptimalChoice)*Condition||SubjID),data=pilotTrialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT", expand_re = TRUE)

#age-squared model
#need to re-run w/ pilot dataframe
pilot_model_nowm_ageSq_take4 <- mixed(resp_acc~Condition*(z_age+z_ageSq)*z_globalPredictiveTrialNum*z_propOptimalChoice+(1+(z_globalPredictiveTrialNum+z_propOptimalChoice)*Condition||SubjID),data=pilotTrialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT", expand_re = TRUE)

anova(pilot_model_nowm_take4,pilot_model_nowm_ageSq_take4)
tab_model(pilot_model_nowm_take4,show.se = TRUE, show.stat = TRUE)
```


```{r transition probabilities condition prediction}
#Does performance decrease when transition structure becomes more probabilistic? 
#does not converge
model_difficulty_pilot <- mixed(resp_acc~z_age*difficulty+(1+difficulty|SubjID),data=pilotTrialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT")

#does not converge
model_difficulty_pilot_2 <- mixed(resp_acc~z_age*difficulty+(1+difficulty||SubjID),data=pilotTrialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT", expand_re = TRUE)

model_difficulty_pilot_3 <- mixed(resp_acc~z_age*difficulty+(1 |SubjID),data=pilotTrialwiseDataset,control=glmerControl(optimizer = "bobyqa",optCtrl=list(maxfun=1e6)),family="binomial",method="LRT")

nice(model_difficulty_pilot_3)
```

```{r histogram of explicit knowledge for best model fit}
explicitKnow_model <- ggplot(meanAccParticipant, aes(x = Total_explicitKnowledge, fill = ModelAttribStr)) + geom_bar() +
  ylab("Participant Count") + xlab("Explicit Knowledge") 
plot(explicitKnow_model)
```

